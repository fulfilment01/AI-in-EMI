{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd7bbd2-0664-443c-83b6-2bbebfc38fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting: .\\anonymisedData.zip -> .\\anonymisedData\n",
      "Extracting: .\\student+performance.zip -> .\\student+performance\n",
      "Extracting: .\\anonymisedData.zip -> .\\anonymisedData\n",
      "Extracting: .\\student+performance.zip -> .\\student+performance\n",
      "Extracting: .\\student+performance\\student.zip -> .\\student+performance\\student\n",
      "Extracting: .\\anonymisedData.zip -> .\\anonymisedData\n",
      "Extracting: .\\student+performance.zip -> .\\student+performance\n",
      "Extracting: .\\student+performance\\student.zip -> .\\student+performance\\student\n",
      "Extracting: .\\anonymisedData.zip -> .\\anonymisedData\n",
      "Extracting: .\\student+performance.zip -> .\\student+performance\n",
      "Extracting: .\\student+performance\\student.zip -> .\\student+performance\\student\n",
      "Extracting: .\\anonymisedData.zip -> .\\anonymisedData\n",
      "Extracting: .\\student+performance.zip -> .\\student+performance\n",
      "Extracting: .\\student+performance\\student.zip -> .\\student+performance\\student\n",
      "Extracting: .\\anonymisedData.zip -> .\\anonymisedData\n",
      "Extracting: .\\student+performance.zip -> .\\student+performance\n",
      "Extracting: .\\student+performance\\student.zip -> .\\student+performance\\student\n",
      "Extracting: .\\anonymisedData.zip -> .\\anonymisedData\n",
      "Extracting: .\\student+performance.zip -> .\\student+performance\n",
      "Extracting: .\\student+performance\\student.zip -> .\\student+performance\\student\n",
      "Extracting: .\\anonymisedData.zip -> .\\anonymisedData\n",
      "Extracting: .\\student+performance.zip -> .\\student+performance\n",
      "Extracting: .\\student+performance\\student.zip -> .\\student+performance\\student\n",
      "Extracting: .\\anonymisedData.zip -> .\\anonymisedData\n",
      "Extracting: .\\student+performance.zip -> .\\student+performance\n",
      "Extracting: .\\student+performance\\student.zip -> .\\student+performance\\student\n",
      "Extracting: .\\anonymisedData.zip -> .\\anonymisedData\n",
      "Extracting: .\\student+performance.zip -> .\\student+performance\n",
      "Extracting: .\\student+performance\\student.zip -> .\\student+performance\\student\n",
      "Done. Extraction loops: 10\n"
     ]
    }
   ],
   "source": [
    "# STEP: Recursively unzip any .zip files inside data_dir (handles nested zips)\n",
    "import os, zipfile\n",
    "\n",
    "data_dir = \".\"   # <- change this to your folder if different\n",
    "\n",
    "def extract_all_zips(root):\n",
    "    found = False\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        for fname in filenames:\n",
    "            if fname.lower().endswith('.zip'):\n",
    "                found = True\n",
    "                zip_path = os.path.join(dirpath, fname)\n",
    "                target_dir = os.path.join(dirpath, os.path.splitext(fname)[0])\n",
    "                os.makedirs(target_dir, exist_ok=True)\n",
    "                print(\"Extracting:\", zip_path, \"->\", target_dir)\n",
    "                try:\n",
    "                    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                        z.extractall(target_dir)\n",
    "                except Exception as e:\n",
    "                    print(\"  Failed to extract\", zip_path, \":\", e)\n",
    "    return found\n",
    "\n",
    "# Run extraction repeatedly until no .zip files remain (or up to 10 loops to be safe)\n",
    "loops = 0\n",
    "while loops < 10:\n",
    "    loops += 1\n",
    "    more = extract_all_zips(data_dir)\n",
    "    if not more:\n",
    "        break\n",
    "\n",
    "print(\"Done. Extraction loops:\", loops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c2ec26-3ae4-4c90-a6ca-3e3094cf2809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.9.0\n",
      "  latest version: 25.7.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.7.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pandas -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c82453-34e2-40f7-a781-3b1cc999dfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 CSV files. Showing first 30 paths:\n",
      ".\\anonymisedData\\assessments.csv\n",
      ".\\anonymisedData\\courses.csv\n",
      ".\\anonymisedData\\studentAssessment.csv\n",
      ".\\anonymisedData\\studentInfo.csv\n",
      ".\\anonymisedData\\studentRegistration.csv\n",
      ".\\anonymisedData\\studentVle.csv\n",
      ".\\anonymisedData\\vle.csv\n",
      ".\\student+performance\\student\\student-mat.csv\n",
      ".\\student+performance\\student\\student-por.csv\n",
      "\n",
      "--- Previewing: .\\anonymisedData\\assessments.csv\n",
      "  code_module code_presentation  id_assessment assessment_type  date  weight\n",
      "0         AAA             2013J           1752             TMA    19      10\n",
      "1         AAA             2013J           1753             TMA    54      20\n",
      "2         AAA             2013J           1754             TMA   117      20\n",
      "3         AAA             2013J           1755             TMA   166      20\n",
      "4         AAA             2013J           1756             TMA   215      30\n",
      "\n",
      "--- Previewing: .\\anonymisedData\\courses.csv\n",
      "  code_module code_presentation  module_presentation_length\n",
      "0         AAA             2013J                         268\n",
      "1         AAA             2014J                         269\n",
      "2         BBB             2013J                         268\n",
      "3         BBB             2014J                         262\n",
      "4         BBB             2013B                         240\n"
     ]
    }
   ],
   "source": [
    "# Run this to list all CSV files under the current folder and preview up to 2 of them\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "root = \".\"   # change to \"data\" if you extracted into a data/ folder\n",
    "csv_paths = []\n",
    "for dirpath, dirnames, filenames in os.walk(root):\n",
    "    for fname in filenames:\n",
    "        if fname.lower().endswith('.csv'):\n",
    "            csv_paths.append(os.path.join(dirpath, fname))\n",
    "csv_paths = sorted(csv_paths)\n",
    "\n",
    "print(\"Found\", len(csv_paths), \"CSV files. Showing first 30 paths:\")\n",
    "for p in csv_paths[:30]:\n",
    "    print(p)\n",
    "\n",
    "# Preview first two CSV files (first 5 rows each)\n",
    "for p in csv_paths[:2]:\n",
    "    print(\"\\n--- Previewing:\", p)\n",
    "    try:\n",
    "        df = pd.read_csv(p, nrows=5)\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        print(\"  Could not read file (error):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3106dd83-feda-4102-9e41-0868625b6324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file: .\\anonymisedData\\studentVle.csv\n",
      "Preview shape (rows shown): (10, 6)\n",
      "Columns: ['code_module', 'code_presentation', 'id_student', 'id_site', 'date', 'sum_click']\n",
      "  code_module code_presentation  id_student  id_site  date  sum_click\n",
      "0         AAA             2013J       28400   546652   -10          4\n",
      "1         AAA             2013J       28400   546652   -10          1\n",
      "2         AAA             2013J       28400   546652   -10          1\n",
      "3         AAA             2013J       28400   546614   -10         11\n",
      "4         AAA             2013J       28400   546714   -10          1\n",
      "5         AAA             2013J       28400   546652   -10          8\n",
      "6         AAA             2013J       28400   546876   -10          2\n",
      "7         AAA             2013J       28400   546688   -10         15\n",
      "8         AAA             2013J       28400   546662   -10         17\n",
      "9         AAA             2013J       28400   546890   -10          1\n",
      "Detected time-like columns: ['date']\n"
     ]
    }
   ],
   "source": [
    "# Inspect VLE.csv (or fall back to studentvle.csv)\n",
    "import os, pandas as pd\n",
    "\n",
    "# find VLE or studentvle automatically from csv_paths\n",
    "vle_path = None\n",
    "for p in csv_paths:\n",
    "    name = os.path.basename(p).lower()\n",
    "    if name == 'vle.csv' or 'vle.csv' in name:\n",
    "        vle_path = p; break\n",
    "if not vle_path:\n",
    "    for p in csv_paths:\n",
    "        if 'studentvle' in os.path.basename(p).lower():\n",
    "            vle_path = p; break\n",
    "\n",
    "print(\"Using file:\", vle_path)\n",
    "df = pd.read_csv(vle_path, nrows=10)\n",
    "print(\"Preview shape (rows shown):\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(df.head(10))\n",
    "\n",
    "# detect likely timestamp columns\n",
    "time_cols = [c for c in df.columns if any(k in c.lower() for k in ('date','time','timestamp','ts'))]\n",
    "print(\"Detected time-like columns:\", time_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5141bc-e8ea-4610-b53e-f78257bb11f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file: .\\anonymisedData\\vle.csv\n",
      "\n",
      "Columns:\n",
      "['id_site', 'code_module', 'code_presentation', 'activity_type', 'week_from', 'week_to']\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_site</th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>week_from</th>\n",
       "      <th>week_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>546943</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>resource</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>546712</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>oucontent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>546998</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>resource</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>546888</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>url</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>547035</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>resource</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_site code_module code_presentation activity_type  week_from  week_to\n",
       "0   546943         AAA             2013J      resource        NaN      NaN\n",
       "1   546712         AAA             2013J     oucontent        NaN      NaN\n",
       "2   546998         AAA             2013J      resource        NaN      NaN\n",
       "3   546888         AAA             2013J           url        NaN      NaN\n",
       "4   547035         AAA             2013J      resource        NaN      NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dtypes:\n",
      "id_site                int64\n",
      "code_module           object\n",
      "code_presentation     object\n",
      "activity_type         object\n",
      "week_from            float64\n",
      "week_to              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect VLE file columns & sample rows so we can adapt to the real names\n",
    "import os, pandas as pd\n",
    "\n",
    "# find a VLE file in csv_paths (uses the csv_paths variable from before)\n",
    "vle_list = [p for p in csv_paths if os.path.basename(p).lower().startswith('vle')]\n",
    "if not vle_list:\n",
    "    vle_list = [p for p in csv_paths if 'vle' in os.path.basename(p).lower()]\n",
    "if not vle_list:\n",
    "    raise FileNotFoundError(\"Couldn't find a VLE file in csv_paths. Print csv_paths and check.\")\n",
    "\n",
    "vle_path = vle_list[0]\n",
    "print(\"Using file:\", vle_path)\n",
    "df = pd.read_csv(vle_path, nrows=5)\n",
    "print(\"\\nColumns:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df)\n",
    "print(\"\\nDtypes:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da593142-6e5b-4b6a-811a-5a000ed85306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: .\\anonymisedData\\studentVle.csv\n",
      "Columns: ['code_module', 'code_presentation', 'id_student', 'id_site', 'date', 'sum_click']\n",
      "\n",
      "Sample rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>id_student</th>\n",
       "      <th>id_site</th>\n",
       "      <th>date</th>\n",
       "      <th>sum_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>546652</td>\n",
       "      <td>-10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>546652</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>546652</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>546614</td>\n",
       "      <td>-10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>546714</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>546652</td>\n",
       "      <td>-10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>546876</td>\n",
       "      <td>-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>546688</td>\n",
       "      <td>-10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_module code_presentation  id_student  id_site  date  sum_click\n",
       "0         AAA             2013J       28400   546652   -10          4\n",
       "1         AAA             2013J       28400   546652   -10          1\n",
       "2         AAA             2013J       28400   546652   -10          1\n",
       "3         AAA             2013J       28400   546614   -10         11\n",
       "4         AAA             2013J       28400   546714   -10          1\n",
       "5         AAA             2013J       28400   546652   -10          8\n",
       "6         AAA             2013J       28400   546876   -10          2\n",
       "7         AAA             2013J       28400   546688   -10         15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dtypes:\n",
      "code_module          object\n",
      "code_presentation    object\n",
      "id_student            int64\n",
      "id_site               int64\n",
      "date                  int64\n",
      "sum_click             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect studentVle.csv (find and show columns + sample rows)\n",
    "import os, pandas as pd\n",
    "\n",
    "# find studentvle file in csv_paths\n",
    "sv_list = [p for p in csv_paths if os.path.basename(p).lower().startswith('studentvle') or 'studentvle' in os.path.basename(p).lower()]\n",
    "if not sv_list:\n",
    "    raise FileNotFoundError(\"studentVle.csv not found in csv_paths. Print csv_paths to check.\")\n",
    "sv_path = sv_list[0]\n",
    "print(\"Using:\", sv_path)\n",
    "df = pd.read_csv(sv_path, nrows=8)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nSample rows:\")\n",
    "display(df)\n",
    "print(\"\\nDtypes:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c9902fb-049c-49ae-aa2d-c01e94f33b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studentVle rows: 10655280\n",
      "courses.csv candidate date cols: ['code_presentation', 'module_presentation_length']\n",
      "Could not parse courses.csv: The column label 'code_presentation' is not unique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SLEEMTEECH\\AppData\\Local\\Temp\\ipykernel_1264\\1389594043.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  courses[start_col] = pd.to_datetime(courses[start_col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fallback start date 2013-01-01 for timestamps.\n",
      "Saved workload.csv -> ./anonymisedData\\workload.csv rows: 295\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec</th>\n",
       "      <th>arrivals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86400</td>\n",
       "      <td>3887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172800</td>\n",
       "      <td>2618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259200</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345600</td>\n",
       "      <td>1283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sec  arrivals\n",
       "0       0      4291\n",
       "1   86400      3887\n",
       "2  172800      2618\n",
       "3  259200      1728\n",
       "4  345600      1283"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create workload.csv from studentVle.csv (use courses.csv start dates if available, else fallback)\n",
    "import os, pandas as pd\n",
    "\n",
    "root = \"./anonymisedData\"   # change if your folder is different\n",
    "sv_path = os.path.join(root, \"studentVle.csv\")\n",
    "courses_path = os.path.join(root, \"courses.csv\")  # we'll look here for a start date if present\n",
    "\n",
    "# load studentVle (only needed cols)\n",
    "sv = pd.read_csv(sv_path, usecols=['code_module','code_presentation','id_student','date','sum_click'])\n",
    "print(\"studentVle rows:\", len(sv))\n",
    "\n",
    "start_col = None\n",
    "if os.path.exists(courses_path):\n",
    "    try:\n",
    "        courses = pd.read_csv(courses_path)\n",
    "        # find any column with 'start' or 'date' in the name\n",
    "        cand = [c for c in courses.columns if any(k in c.lower() for k in ('start','date','begin','presentation'))]\n",
    "        print(\"courses.csv candidate date cols:\", cand)\n",
    "        if cand:\n",
    "            start_col = cand[0]\n",
    "            courses[start_col] = pd.to_datetime(courses[start_col], errors='coerce')\n",
    "            # keep only module+presentation+start\n",
    "            if {'code_module','code_presentation', start_col}.issubset(courses.columns):\n",
    "                ref = courses[['code_module','code_presentation', start_col]].drop_duplicates()\n",
    "                sv = sv.merge(ref, on=['code_module','code_presentation'], how='left')\n",
    "                # if merge failed for most rows, ignore start_col\n",
    "                if sv[start_col].notna().mean() < 0.05:\n",
    "                    print(\"Too few parsed start dates from courses -> falling back.\")\n",
    "                    start_col = None\n",
    "            else:\n",
    "                start_col = None\n",
    "    except Exception as e:\n",
    "        print(\"Could not parse courses.csv:\", e)\n",
    "        start_col = None\n",
    "\n",
    "# create timestamp: either using course start + date days, or fixed fallback\n",
    "if start_col:\n",
    "    sv['timestamp'] = sv[start_col] + pd.to_timedelta(sv['date'], unit='D')\n",
    "    print(\"Using courses start dates to build timestamps.\")\n",
    "else:\n",
    "    start0 = pd.to_datetime('2013-01-01')\n",
    "    sv['timestamp'] = start0 + pd.to_timedelta(sv['date'], unit='D')\n",
    "    print(\"Using fallback start date 2013-01-01 for timestamps.\")\n",
    "\n",
    "# convert to seconds since start and make workload (arrivals per second)\n",
    "sv['sec'] = (sv['timestamp'] - sv['timestamp'].min()).dt.total_seconds().astype(int)\n",
    "trace = sv.groupby('sec').size().reset_index(name='arrivals').sort_values('sec').reset_index(drop=True)\n",
    "\n",
    "out_path = os.path.join(root, 'workload.csv')\n",
    "trace.to_csv(out_path, index=False)\n",
    "print(\"Saved workload.csv ->\", out_path, \"rows:\", len(trace))\n",
    "trace.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4179640a-58c2-406c-8e82-405fe6c2d59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events in workload.csv: 10655280\n",
      "Total events (10655280) > 200000. Downsampling proportionally.\n",
      "Total requests after sampling: 199997\n",
      "Expanded requests shape: (199997, 2)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No UCI student file (student-mat/por) found under ./anonymisedData",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m uci_path \u001b[38;5;241m=\u001b[39m csvs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m csvs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m uci_path:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo UCI student file (student-mat/por) found under \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m root)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# detect delimiter and load UCI\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(uci_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No UCI student file (student-mat/por) found under ./anonymisedData"
     ]
    }
   ],
   "source": [
    "# Expand workload -> requests and attach UCI demographics (safe sampling)\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "root = \"./anonymisedData\"   # folder with workload.csv and UCI files\n",
    "work_path = os.path.join(root, \"workload.csv\")\n",
    "if not os.path.exists(work_path):\n",
    "    raise FileNotFoundError(\"workload.csv not found at \" + work_path)\n",
    "\n",
    "# load workload (sec, arrivals)\n",
    "work = pd.read_csv(work_path)\n",
    "total_events = int(work['arrivals'].sum())\n",
    "print(\"Total events in workload.csv:\", total_events)\n",
    "\n",
    "# safety cap: scale down proportionally if too large\n",
    "max_requests = 200000\n",
    "if total_events > max_requests:\n",
    "    print(f\"Total events ({total_events}) > {max_requests}. Downsampling proportionally.\")\n",
    "    scale = max_requests / total_events\n",
    "    work['sampled'] = (work['arrivals'] * scale).round().astype(int)\n",
    "    work.loc[(work['arrivals']>0) & (work['sampled']==0), 'sampled'] = 1\n",
    "else:\n",
    "    work['sampled'] = work['arrivals'].astype(int)\n",
    "\n",
    "print(\"Total requests after sampling:\", int(work['sampled'].sum()))\n",
    "\n",
    "# Expand sampled counts into per-request seconds, spreading events uniformly within each day\n",
    "rows = []\n",
    "for _, r in work.iterrows():\n",
    "    sec0 = int(r['sec'])\n",
    "    n = int(r['sampled'])\n",
    "    if n <= 0:\n",
    "        continue\n",
    "    start = sec0\n",
    "    end = sec0 + 86400\n",
    "    chosen = np.random.randint(start, end, size=n)\n",
    "    rows.extend(chosen.tolist())\n",
    "\n",
    "requests = pd.DataFrame({'sec': rows})\n",
    "requests = requests.sort_values('sec').reset_index(drop=True)\n",
    "requests['request_id'] = range(1, len(requests)+1)\n",
    "print(\"Expanded requests shape:\", requests.shape)\n",
    "\n",
    "# Find UCI student file automatically\n",
    "csvs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root):\n",
    "    for fname in filenames:\n",
    "        if fname.lower().startswith('student-mat') or fname.lower().startswith('student-por') or 'student-mat' in fname.lower() or 'student-por' in fname.lower():\n",
    "            csvs.append(os.path.join(dirpath, fname))\n",
    "uci_path = csvs[0] if csvs else None\n",
    "if not uci_path:\n",
    "    raise FileNotFoundError(\"No UCI student file (student-mat/por) found under \" + root)\n",
    "\n",
    "# detect delimiter and load UCI\n",
    "with open(uci_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    first = f.readline()\n",
    "sep = ';' if ';' in first else ','\n",
    "uci = pd.read_csv(uci_path, sep=sep)\n",
    "print(\"Loaded UCI:\", os.path.basename(uci_path), \"shape:\", uci.shape)\n",
    "\n",
    "# select demographic columns (fallback to whatever exists)\n",
    "keep = ['sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob','Fjob','studytime','failures','schoolsup','famsup','internet','G3']\n",
    "keep_present = [c for c in keep if c in uci.columns]\n",
    "if not keep_present:\n",
    "    keep_present = list(uci.columns)\n",
    "print(\"UCI columns used for sampling:\", keep_present)\n",
    "\n",
    "# sample demographics WITH replacement to match requests length\n",
    "sampled = uci[keep_present].sample(n=len(requests), replace=True, random_state=42).reset_index(drop=True)\n",
    "requests = pd.concat([requests.reset_index(drop=True), sampled.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# save requests.csv\n",
    "out = os.path.join(root, 'requests.csv')\n",
    "requests.to_csv(out, index=False)\n",
    "print(\"Saved requests.csv ->\", out, \"rows:\", len(requests))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08862c29-b35e-45ee-8399-221da27c4f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI candidates found: ['.\\\\student+performance\\\\student\\\\student-mat.csv', '.\\\\student+performance\\\\student\\\\student-por.csv']\n",
      "Using UCI file: .\\student+performance\\student\\student-mat.csv\n",
      "Loaded UCI shape: (395, 33)\n",
      "Columns used for sampling: ['sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'studytime', 'failures', 'schoolsup', 'famsup', 'internet', 'G3']\n",
      "Saved final requests.csv -> ./anonymisedData/requests.csv rows: 199997\n"
     ]
    }
   ],
   "source": [
    "# FIXED: find UCI anywhere, attach demographics to existing requests (safe)\n",
    "import os, pandas as pd\n",
    "\n",
    "# 1) search workspace for UCI student files\n",
    "uci_paths = []\n",
    "for dirpath, dirnames, filenames in os.walk(\".\"):\n",
    "    for fname in filenames:\n",
    "        n = fname.lower()\n",
    "        if n.startswith('student-mat') or n.startswith('student-por') or 'student-mat' in n or 'student-por' in n:\n",
    "            uci_paths.append(os.path.join(dirpath, fname))\n",
    "uci_paths = sorted(set(uci_paths))\n",
    "print(\"UCI candidates found:\", uci_paths)\n",
    "\n",
    "if not uci_paths:\n",
    "    raise FileNotFoundError(\"No UCI student-mat/por files found under notebook folder. Move them into project or provide path.\")\n",
    "\n",
    "# 2) pick the first match (change index if you want the other file)\n",
    "uci_path = uci_paths[0]\n",
    "print(\"Using UCI file:\", uci_path)\n",
    "\n",
    "# 3) read UCI (auto-detect ; or ,)\n",
    "with open(uci_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    first = f.readline()\n",
    "sep = ';' if ';' in first else ','\n",
    "uci = pd.read_csv(uci_path, sep=sep)\n",
    "print(\"Loaded UCI shape:\", uci.shape)\n",
    "\n",
    "# 4) columns we'll try to use (fallback to all present columns)\n",
    "keep = ['sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob','Fjob','studytime','failures','schoolsup','famsup','internet','G3']\n",
    "keep_present = [c for c in keep if c in uci.columns]\n",
    "if not keep_present:\n",
    "    keep_present = list(uci.columns)\n",
    "print(\"Columns used for sampling:\", keep_present)\n",
    "\n",
    "# 5) ensure 'requests' DataFrame exists (from previous expansion) or load requests_oulad.csv\n",
    "if 'requests' not in globals():\n",
    "    cand_paths = ['./anonymisedData/requests_oulad.csv', './requests_oulad.csv', './anonymisedData/requests.csv', './requests.csv']\n",
    "    found = None\n",
    "    for p in cand_paths:\n",
    "        if os.path.exists(p):\n",
    "            found = p; break\n",
    "    if found:\n",
    "        requests = pd.read_csv(found)\n",
    "        print(\"Loaded requests from:\", found, \"shape:\", requests.shape)\n",
    "    else:\n",
    "        raise NameError(\"`requests` not in memory and no requests_oulad.csv found. Re-run expansion step first.\")\n",
    "\n",
    "# 6) attach sampled demographics (with replacement) and save\n",
    "sampled = uci[keep_present].sample(n=len(requests), replace=True, random_state=42).reset_index(drop=True)\n",
    "requests = requests.reset_index(drop=True).copy()\n",
    "requests = pd.concat([requests, sampled], axis=1)\n",
    "\n",
    "out = './anonymisedData/requests.csv'\n",
    "os.makedirs(os.path.dirname(out), exist_ok=True)\n",
    "requests.to_csv(out, index=False)\n",
    "print(\"Saved final requests.csv ->\", out, \"rows:\", len(requests))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "521e6c73-fff3-40bf-bc00-78413846fb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading requests from: ./anonymisedData/requests.csv\n",
      "Running baselines... (this may take a moment)\n",
      "Simulator: baseline_random  | servers: 6 | requests: 199997\n",
      " Time to simulate (wall): 33.81s\n",
      " Avg response time: 1.301 s | 95th pct: 2.306 s | Throughput: 0.008 req/s\n",
      " % SLA (> 2.0s): 9.16%\n",
      " Server total busy-time (s): [43384.67, 43577.44, 42877.65, 43547.57, 43400.36, 43088.39]\n",
      " Saved per-request results to: ./anonymisedData/sim_results\\baseline_random_results.csv\n",
      "Simulator: baseline_roundrobin  | servers: 6 | requests: 199997\n",
      " Time to simulate (wall): 32.23s\n",
      " Avg response time: 1.300 s | 95th pct: 2.298 s | Throughput: 0.008 req/s\n",
      " % SLA (> 2.0s): 9.03%\n",
      " Server total busy-time (s): [43365.91, 43449.92, 43235.82, 43290.25, 43358.1, 43279.08]\n",
      " Saved per-request results to: ./anonymisedData/sim_results\\baseline_roundrobin_results.csv\n",
      "Saved baseline summary to: ./anonymisedData/sim_results\\baseline_summary.csv\n",
      "\n",
      "Baseline summary:\n",
      "         policy  avg_rt_s     p95_s  throughput_rps  sla_viol_pct\n",
      "0       random  1.301273  2.305846        0.007849      9.164137\n",
      "1  round-robin  1.299915  2.298005        0.007849      9.032135\n"
     ]
    }
   ],
   "source": [
    "# Simulator skeleton + two baseline schedulers (random & round-robin)\n",
    "import os, math, numpy as np, pandas as pd, random, time\n",
    "from statistics import mean\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# --------- Config (change these if you want) ----------\n",
    "REQUESTS_PATH = './anonymisedData/requests.csv'   # input produced earlier\n",
    "OUT_DIR = './anonymisedData/sim_results'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "NUM_SERVERS = 6            # number of fog nodes / servers to simulate\n",
    "BASE_SERVICE = 0.8         # base service time in seconds (deterministic part)\n",
    "SERVICE_EXP_SCALE = 0.5    # exponential jitter scale (so service_time = BASE + Exp(scale))\n",
    "SLA_SECONDS = 2.0          # SLA threshold in seconds (for % violations)\n",
    "MAX_EVENTS = None          # set to an int to limit processed requests for quick tests\n",
    "\n",
    "# --------- Helper classes / schedulers ----------\n",
    "class Server:\n",
    "    def __init__(self, sid):\n",
    "        self.id = sid\n",
    "        self.next_free = 0.0   # next time (seconds) when server is free\n",
    "\n",
    "def random_scheduler(request_row, servers, state):\n",
    "    \"\"\"Choose a server uniformly at random.\"\"\"\n",
    "    return random.randrange(len(servers))\n",
    "\n",
    "def make_round_robin():\n",
    "    idx = {'i': 0}\n",
    "    def rr(request_row, servers, state):\n",
    "        i = idx['i'] % len(servers)\n",
    "        idx['i'] += 1\n",
    "        return i\n",
    "    return rr\n",
    "\n",
    "# --------- Core simulator ----------\n",
    "def run_simulator(scheduler_fn, sim_name='sim', num_servers=NUM_SERVERS,\n",
    "                  base_service=BASE_SERVICE, exp_scale=SERVICE_EXP_SCALE, sla=SLA_SECONDS,\n",
    "                  max_events=MAX_EVENTS):\n",
    "    # load requests\n",
    "    reqs = pd.read_csv(REQUESTS_PATH)\n",
    "    reqs = reqs.sort_values('sec').reset_index(drop=True)\n",
    "    if max_events:\n",
    "        reqs = reqs.iloc[:max_events].copy()\n",
    "    # convert sec -> float arrival time (seconds)\n",
    "    reqs['arrival'] = reqs['sec'].astype(float)\n",
    "\n",
    "    # init servers\n",
    "    servers = [Server(i) for i in range(num_servers)]\n",
    "\n",
    "    # storage for results\n",
    "    results = []\n",
    "    state = {}  # scheduler state (if needed)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for idx, row in reqs.iterrows():\n",
    "        arrival = float(row['arrival'])\n",
    "        # pick server\n",
    "        sid = scheduler_fn(row, servers, state)\n",
    "        server = servers[sid]\n",
    "\n",
    "        # sample service time (BASE + exponential jitter)\n",
    "        service_time = base_service + np.random.exponential(scale=exp_scale)\n",
    "\n",
    "        # when service starts is either arrival or when server becomes free\n",
    "        start = max(arrival, server.next_free)\n",
    "        finish = start + service_time\n",
    "        response_time = finish - arrival\n",
    "\n",
    "        # update server availability\n",
    "        server.next_free = finish\n",
    "\n",
    "        # store per-request info\n",
    "        rec = {\n",
    "            'request_idx': int(idx),\n",
    "            'arrival': arrival,\n",
    "            'server_id': sid,\n",
    "            'start': start,\n",
    "            'finish': finish,\n",
    "            'service_time': service_time,\n",
    "            'response_time': response_time\n",
    "        }\n",
    "        results.append(rec)\n",
    "\n",
    "    duration = time.time() - t0\n",
    "    df = pd.DataFrame(results)\n",
    "    # metrics\n",
    "    avg_rt = df['response_time'].mean()\n",
    "    p95 = df['response_time'].quantile(0.95)\n",
    "    throughput = len(df) / ( (df['finish'].max() - df['arrival'].min()) if len(df)>0 else 1 )\n",
    "    sla_viol = (df['response_time'] > sla).mean() * 100.0\n",
    "\n",
    "    # per-server load stats\n",
    "    server_loads = df.groupby('server_id')['service_time'].sum().to_dict()\n",
    "    loads = [server_loads.get(i, 0.0) for i in range(num_servers)]\n",
    "\n",
    "    # save results\n",
    "    out_csv = os.path.join(OUT_DIR, f'{sim_name}_results.csv')\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    # print summary\n",
    "    print(f\"Simulator: {sim_name}  | servers: {num_servers} | requests: {len(df)}\")\n",
    "    print(f\" Time to simulate (wall): {duration:.2f}s\")\n",
    "    print(f\" Avg response time: {avg_rt:.3f} s | 95th pct: {p95:.3f} s | Throughput: {throughput:.3f} req/s\")\n",
    "    print(f\" % SLA (> {sla}s): {sla_viol:.2f}%\")\n",
    "    print(\" Server total busy-time (s):\", [round(x,2) for x in loads])\n",
    "    print(\" Saved per-request results to:\", out_csv)\n",
    "    return df, {\n",
    "        'avg_rt': avg_rt, 'p95': p95, 'throughput': throughput,\n",
    "        'sla_viol_pct': sla_viol, 'server_loads': loads\n",
    "    }\n",
    "\n",
    "# --------- Run baselines ----------\n",
    "print(\"Loading requests from:\", REQUESTS_PATH)\n",
    "print(\"Running baselines... (this may take a moment)\")\n",
    "\n",
    "# Random baseline\n",
    "df_rand, stats_rand = run_simulator(random_scheduler, sim_name='baseline_random', num_servers=NUM_SERVERS)\n",
    "\n",
    "# Round-robin baseline\n",
    "rr_fn = make_round_robin()\n",
    "df_rr, stats_rr = run_simulator(rr_fn, sim_name='baseline_roundrobin', num_servers=NUM_SERVERS)\n",
    "\n",
    "# Save summary comparison\n",
    "summary = pd.DataFrame({\n",
    "    'policy': ['random', 'round-robin'],\n",
    "    'avg_rt_s': [stats_rand['avg_rt'], stats_rr['avg_rt']],\n",
    "    'p95_s': [stats_rand['p95'], stats_rr['p95']],\n",
    "    'throughput_rps': [stats_rand['throughput'], stats_rr['throughput']],\n",
    "    'sla_viol_pct': [stats_rand['sla_viol_pct'], stats_rr['sla_viol_pct']]\n",
    "})\n",
    "summary_path = os.path.join(OUT_DIR, 'baseline_summary.csv')\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print(\"Saved baseline summary to:\", summary_path)\n",
    "print(\"\\nBaseline summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fe4fbaa-51dd-4da0-b197-49cbcd62688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests available: 199997\n",
      "Training on: 50000 requests per episode\n",
      "Episode 1/10  avg_reward=-1.3031  eps=0.895\n",
      "Episode 2/10  avg_reward=-1.3018  eps=0.891\n",
      "Episode 3/10  avg_reward=-1.3016  eps=0.887\n",
      "Episode 4/10  avg_reward=-1.3054  eps=0.882\n",
      "Episode 5/10  avg_reward=-1.3040  eps=0.878\n",
      "Episode 6/10  avg_reward=-1.3009  eps=0.873\n",
      "Episode 7/10  avg_reward=-1.3045  eps=0.869\n",
      "Episode 8/10  avg_reward=-1.3020  eps=0.865\n",
      "Episode 9/10  avg_reward=-1.3056  eps=0.860\n",
      "Episode 10/10  avg_reward=-1.2993  eps=0.856\n",
      "Training finished in 73.22 s\n",
      "\n",
      "RL evaluation results:\n",
      " Avg RT: 1.310 s  | 95th: 2.333 s | Throughput: 0.008 req/s | SLA%: 9.57%\n",
      " Server loads (s): [0.0, 90613.1, 0.0, 0.0, 1.05, 171477.12]\n",
      "Saved RL per-request results to: ./anonymisedData/sim_results\\rl_policy_results.csv\n",
      "Loaded baseline summary for comparison.\n",
      "\n",
      "Comparison summary saved to: ./anonymisedData/sim_results\\comparison_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Modified Hierarchical tabular Q-learning scheduler (with wait-penalty + imbalance state)\n",
    "import os, math, random, time\n",
    "import numpy as np, pandas as pd\n",
    "from collections import defaultdict\n",
    "random.seed(123); np.random.seed(123)\n",
    "\n",
    "REQUESTS_PATH = './anonymisedData/requests.csv'\n",
    "OUT_DIR = './anonymisedData/sim_results'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Simulation parameters (tweak)\n",
    "NUM_SERVERS = 6\n",
    "GROUPS = 2                        # high-level chooses group index 0..GROUPS-1 (simple split)\n",
    "SERVERS_PER_GROUP = NUM_SERVERS // GROUPS\n",
    "BASE_SERVICE = 0.8\n",
    "SERVICE_EXP_SCALE = 0.5\n",
    "SLA_SECONDS = 2.0\n",
    "\n",
    "# Q-learning hyperparams (tune these if needed)\n",
    "ALPHA = 0.1\n",
    "GAMMA = 0.8\n",
    "EPS_START = 0.9\n",
    "EPS_MIN = 0.1\n",
    "EPS_DECAY = 0.995\n",
    "\n",
    "EPISODES = 10                     # reduce to 2-3 for a quick test\n",
    "max_train_requests = 50000        # set smaller for faster training; must be <= total requests\n",
    "\n",
    "# Discretization helpers (make state small for tabular Q)\n",
    "def bucket_load(load, bins=(0,5,10,20,50,100,999999)):\n",
    "    # load in seconds -> bucket index\n",
    "    for i,b in enumerate(bins):\n",
    "        if load <= b:\n",
    "            return i\n",
    "    return len(bins)\n",
    "\n",
    "def make_state(servers, arrival_rate_bucket=0):\n",
    "    \"\"\"\n",
    "    NEW: enriched state includes imbalance bucket\n",
    "    state = (avg_load_bucket, imbalance_bucket)\n",
    "    imbalance = floor((max_load - avg_load) / 10) clipped to 0..9\n",
    "    \"\"\"\n",
    "    loads = [s.next_free for s in servers]\n",
    "    avg_load = sum(loads)/len(loads) if loads else 0.0\n",
    "    max_load = max(loads) if loads else 0.0\n",
    "    imbalance = int((max_load - avg_load) // 10)\n",
    "    if imbalance < 0:\n",
    "        imbalance = 0\n",
    "    if imbalance > 9:\n",
    "        imbalance = 9\n",
    "    return (bucket_load(avg_load), imbalance)\n",
    "\n",
    "# Simple environment (similar to previous simulator)\n",
    "class Server:\n",
    "    def __init__(self, sid):\n",
    "        self.id = sid\n",
    "        self.next_free = 0.0\n",
    "\n",
    "def reset_servers(num_servers):\n",
    "    return [Server(i) for i in range(num_servers)]\n",
    "\n",
    "def sample_service_time():\n",
    "    return BASE_SERVICE + np.random.exponential(SERVICE_EXP_SCALE)\n",
    "\n",
    "# Hierarchical Q structures (re-initialize before training)\n",
    "def make_Q_structures():\n",
    "    Q_high = defaultdict(lambda: np.zeros(GROUPS))   # maps state -> vector of group-values\n",
    "    Q_low = defaultdict(lambda: np.zeros(SERVERS_PER_GROUP))  # maps (state,group) -> vector for servers in that group\n",
    "    return Q_high, Q_low\n",
    "\n",
    "def choose_action_hierarchical(state, servers, eps, Q_high, Q_low):\n",
    "    # high-level: pick group via epsilon-greedy on Q_high[state]\n",
    "    qh = Q_high[state]\n",
    "    if random.random() < eps:\n",
    "        group = random.randrange(GROUPS)\n",
    "    else:\n",
    "        group = int(np.argmax(qh))\n",
    "    # low-level: pick server index within group\n",
    "    ql = Q_low[(state, group)]\n",
    "    if random.random() < eps:\n",
    "        choice = random.randrange(SERVERS_PER_GROUP)\n",
    "    else:\n",
    "        choice = int(np.argmax(ql))\n",
    "    # map to global server id\n",
    "    server_id = group*SERVERS_PER_GROUP + choice\n",
    "    if server_id >= NUM_SERVERS:  # safety if split uneven\n",
    "        server_id = NUM_SERVERS-1\n",
    "    return group, choice, server_id\n",
    "\n",
    "# single-episode run that also performs online Q updates (returns avg reward)\n",
    "def run_episode_and_train(requests_df, eps, Q_high, Q_low, alpha=ALPHA, gamma=GAMMA):\n",
    "    servers = reset_servers(NUM_SERVERS)\n",
    "    total_reward = 0.0\n",
    "    steps = 0\n",
    "    for idx, row in requests_df.iterrows():\n",
    "        arrival = float(row['sec'])\n",
    "        # state before action\n",
    "        state = make_state(servers, arrival_rate_bucket=0)\n",
    "        group, low_choice, sid = choose_action_hierarchical(state, servers, eps, Q_high, Q_low)\n",
    "        server = servers[sid]\n",
    "        service_time = sample_service_time()\n",
    "        # compute wait and reward (NEW: include wait penalty)\n",
    "        wait = max(0.0, server.next_free - arrival)                        # seconds waiting before service\n",
    "        start = max(arrival, server.next_free)\n",
    "        finish = start + service_time\n",
    "        response_time = finish - arrival\n",
    "        reward = -response_time - 0.0001*service_time - 0.01 * wait        # heavier penalty for wait\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        # update server\n",
    "        server.next_free = finish\n",
    "        # next state\n",
    "        next_state = make_state(servers, arrival_rate_bucket=0)\n",
    "        # ----- Q updates (hierarchical) -----\n",
    "        # high-level update\n",
    "        qh = Q_high[state]\n",
    "        best_next_high = np.max(Q_high[next_state]) if next_state in Q_high else 0.0\n",
    "        td_high = (reward + gamma*best_next_high) - qh[group]\n",
    "        qh[group] += alpha * td_high\n",
    "        Q_high[state] = qh\n",
    "        # low-level update for (state, group)\n",
    "        ql = Q_low[(state, group)]\n",
    "        best_next_low = np.max(Q_low[(next_state, group)]) if (next_state, group) in Q_low else 0.0\n",
    "        td_low = (reward + gamma*best_next_low) - ql[low_choice]\n",
    "        ql[low_choice] += alpha * td_low\n",
    "        Q_low[(state, group)] = ql\n",
    "    avg_reward = total_reward / max(1, steps)\n",
    "    return avg_reward\n",
    "\n",
    "# ---- Load requests (chronological) and prepare training subset ----\n",
    "reqs = pd.read_csv(REQUESTS_PATH)\n",
    "reqs = reqs.sort_values('sec').reset_index(drop=True)\n",
    "total_reqs = len(reqs)\n",
    "print(\"Total requests available:\", total_reqs)\n",
    "train_n = min(max_train_requests, total_reqs)\n",
    "train_df = reqs.iloc[:train_n].copy()\n",
    "print(\"Training on:\", len(train_df), \"requests per episode\")\n",
    "\n",
    "# ---- Initialize Q structures and training loop ----\n",
    "Q_high, Q_low = make_Q_structures()\n",
    "eps = EPS_START\n",
    "train_rewards = []\n",
    "t0 = time.time()\n",
    "for ep in range(1, EPISODES+1):\n",
    "    avg_r = run_episode_and_train(train_df, eps, Q_high, Q_low, alpha=ALPHA, gamma=GAMMA)\n",
    "    train_rewards.append(avg_r)\n",
    "    eps = max(EPS_MIN, eps * EPS_DECAY)\n",
    "    print(f\"Episode {ep}/{EPISODES}  avg_reward={avg_r:.4f}  eps={eps:.3f}\")\n",
    "elapsed = time.time() - t0\n",
    "print(\"Training finished in\", round(elapsed,2), \"s\")\n",
    "\n",
    "# ---- Evaluation using learned policy (greedy) ----\n",
    "def eval_with_policy(requests_df, Q_high, Q_low):\n",
    "    servers = reset_servers(NUM_SERVERS)\n",
    "    results = []\n",
    "    for idx, row in requests_df.iterrows():\n",
    "        arrival = float(row['sec'])\n",
    "        state = make_state(servers, 0)\n",
    "        # greedy high-level\n",
    "        group = int(np.argmax(Q_high[state])) if state in Q_high else random.randrange(GROUPS)\n",
    "        ql = Q_low[(state, group)]\n",
    "        low_choice = int(np.argmax(ql)) if (state,group) in Q_low else 0\n",
    "        sid = group*SERVERS_PER_GROUP + low_choice\n",
    "        if sid >= NUM_SERVERS:\n",
    "            sid = NUM_SERVERS-1\n",
    "        server = servers[sid]\n",
    "        service_time = sample_service_time()\n",
    "        start = max(arrival, server.next_free)\n",
    "        finish = start + service_time\n",
    "        response_time = finish - arrival\n",
    "        server.next_free = finish\n",
    "        results.append({'arrival': arrival, 'server_id': sid, 'start': start, 'finish': finish, 'response_time': response_time})\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Evaluate on a held-out set (here use full requests for evaluation)\n",
    "eval_df = reqs.copy()\n",
    "df_rl = eval_with_policy(eval_df, Q_high, Q_low)\n",
    "\n",
    "# compute metrics (same as baseline)\n",
    "avg_rt = df_rl['response_time'].mean()\n",
    "p95 = df_rl['response_time'].quantile(0.95)\n",
    "throughput = len(df_rl) / ((df_rl['finish'].max() - df_rl['arrival'].min()) if len(df_rl)>0 else 1)\n",
    "sla_viol = (df_rl['response_time'] > SLA_SECONDS).mean() * 100.0\n",
    "server_loads = df_rl.groupby('server_id')['response_time'].sum().to_dict()\n",
    "loads = [server_loads.get(i, 0.0) for i in range(NUM_SERVERS)]\n",
    "\n",
    "# save results and print\n",
    "out_csv = os.path.join(OUT_DIR, 'rl_policy_results.csv')\n",
    "df_rl.to_csv(out_csv, index=False)\n",
    "print(\"\\nRL evaluation results:\")\n",
    "print(f\" Avg RT: {avg_rt:.3f} s  | 95th: {p95:.3f} s | Throughput: {throughput:.3f} req/s | SLA%: {sla_viol:.2f}%\")\n",
    "print(\" Server loads (s):\", [round(x,2) for x in loads])\n",
    "print(\"Saved RL per-request results to:\", out_csv)\n",
    "\n",
    "# Save a short summary comparing baselines vs RL (if baseline_summary exists, load and append)\n",
    "bsum_path = os.path.join(OUT_DIR, 'baseline_summary.csv')\n",
    "summary_rows = []\n",
    "if os.path.exists(bsum_path):\n",
    "    bsum = pd.read_csv(bsum_path)\n",
    "    print(\"Loaded baseline summary for comparison.\")\n",
    "    for _, r in bsum.iterrows():\n",
    "        summary_rows.append(r.to_dict())\n",
    "summary_rows.append({'policy':'rl_hier', 'avg_rt_s': avg_rt, 'p95_s': p95, 'throughput_rps': throughput, 'sla_viol_pct': sla_viol})\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(os.path.join(OUT_DIR, 'comparison_summary.csv'), index=False)\n",
    "print(\"\\nComparison summary saved to:\", os.path.join(OUT_DIR, 'comparison_summary.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce5f3a98-17f6-4561-b814-50566a1544bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wp=0.01 a=0.05 g=0.8 -> avg_rt=1.315 p95=2.367 sla%=9.73 (t=20.2s)\n",
      "wp=0.01 a=0.05 g=0.95 -> avg_rt=1.317 p95=2.372 sla%=9.76 (t=20.6s)\n",
      "wp=0.01 a=0.1 g=0.8 -> avg_rt=1.319 p95=2.387 sla%=10.01 (t=21.1s)\n",
      "wp=0.01 a=0.1 g=0.95 -> avg_rt=1.317 p95=2.373 sla%=9.97 (t=20.6s)\n",
      "wp=0.05 a=0.05 g=0.8 -> avg_rt=1.316 p95=2.351 sla%=9.86 (t=20.0s)\n",
      "wp=0.05 a=0.05 g=0.95 -> avg_rt=1.318 p95=2.352 sla%=9.87 (t=20.7s)\n",
      "wp=0.05 a=0.1 g=0.8 -> avg_rt=1.315 p95=2.353 sla%=9.80 (t=20.6s)\n",
      "wp=0.05 a=0.1 g=0.95 -> avg_rt=1.319 p95=2.375 sla%=10.06 (t=19.9s)\n",
      "wp=0.1 a=0.05 g=0.8 -> avg_rt=1.319 p95=2.361 sla%=10.06 (t=20.6s)\n",
      "wp=0.1 a=0.05 g=0.95 -> avg_rt=1.313 p95=2.344 sla%=9.76 (t=20.2s)\n",
      "wp=0.1 a=0.1 g=0.8 -> avg_rt=1.322 p95=2.370 sla%=10.05 (t=20.7s)\n",
      "wp=0.1 a=0.1 g=0.95 -> avg_rt=1.323 p95=2.393 sla%=10.31 (t=20.0s)\n",
      "Grid done in 245.2 s\n",
      "Saved tuning_results.csv -> ./anonymisedData/sim_results\\tuning_results.csv\n"
     ]
    }
   ],
   "source": [
    "# QUICK TUNING SWEEP: vary wait_penalty, alpha, gamma (fast tests)\n",
    "import os, time, random\n",
    "import numpy as np, pandas as pd\n",
    "from collections import defaultdict\n",
    "random.seed(1); np.random.seed(1)\n",
    "\n",
    "REQUESTS_PATH = './anonymisedData/requests.csv'\n",
    "OUT_DIR = './anonymisedData/sim_results'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "NUM_SERVERS = 6\n",
    "GROUPS = 2\n",
    "SERVERS_PER_GROUP = NUM_SERVERS // GROUPS\n",
    "BASE_SERVICE = 0.8\n",
    "SERVICE_EXP_SCALE = 0.5\n",
    "SLA_SECONDS = 2.0\n",
    "\n",
    "# fast training settings\n",
    "EPISODES = 6\n",
    "train_n = 20000\n",
    "eval_n = 30000\n",
    "\n",
    "# small grid\n",
    "WAIT_PENALTIES = [0.01, 0.05, 0.1]\n",
    "ALPHAS = [0.05, 0.1]\n",
    "GAMMAS = [0.8, 0.95]\n",
    "\n",
    "# helpers (simple, similar to your previous code)\n",
    "def bucket_load(load, bins=(0,5,10,20,50,100,999999)):\n",
    "    for i,b in enumerate(bins):\n",
    "        if load <= b:\n",
    "            return i\n",
    "    return len(bins)\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, sid):\n",
    "        self.id = sid\n",
    "        self.next_free = 0.0\n",
    "\n",
    "def reset_servers(num_servers):\n",
    "    return [Server(i) for i in range(num_servers)]\n",
    "\n",
    "def sample_service_time():\n",
    "    return BASE_SERVICE + np.random.exponential(SERVICE_EXP_SCALE)\n",
    "\n",
    "def make_state(servers):\n",
    "    loads = [s.next_free for s in servers]\n",
    "    avg_load = sum(loads)/len(loads) if loads else 0.0\n",
    "    max_load = max(loads) if loads else 0.0\n",
    "    imbalance = int(min(9, (max_load - avg_load)//10))\n",
    "    return (bucket_load(avg_load), imbalance)\n",
    "\n",
    "def train_config(alpha, gamma, wait_penalty, episodes, train_df):\n",
    "    # init Q\n",
    "    Q_high = defaultdict(lambda: np.zeros(GROUPS))\n",
    "    Q_low = defaultdict(lambda: np.zeros(SERVERS_PER_GROUP))\n",
    "    eps = 0.9\n",
    "    eps_min = 0.1\n",
    "    eps_decay = 0.995\n",
    "    for ep in range(episodes):\n",
    "        servers = reset_servers(NUM_SERVERS)\n",
    "        for _, row in train_df.iterrows():\n",
    "            arrival = float(row['sec'])\n",
    "            state = make_state(servers)\n",
    "            # choose actions (epsilon-greedy)\n",
    "            if random.random() < eps:\n",
    "                group = random.randrange(GROUPS)\n",
    "            else:\n",
    "                group = int(np.argmax(Q_high[state]))\n",
    "            if random.random() < eps:\n",
    "                low_choice = random.randrange(SERVERS_PER_GROUP)\n",
    "            else:\n",
    "                low_choice = int(np.argmax(Q_low[(state, group)]))\n",
    "            sid = group*SERVERS_PER_GROUP + low_choice\n",
    "            if sid >= NUM_SERVERS: sid = NUM_SERVERS-1\n",
    "            server = servers[sid]\n",
    "            service_time = sample_service_time()\n",
    "            wait = max(0.0, server.next_free - arrival)\n",
    "            start = max(arrival, server.next_free)\n",
    "            finish = start + service_time\n",
    "            response_time = finish - arrival\n",
    "            reward = -response_time - 0.0001*service_time - wait_penalty * wait\n",
    "            # update server\n",
    "            server.next_free = finish\n",
    "            next_state = make_state(servers)\n",
    "            # high update\n",
    "            qh = Q_high[state]\n",
    "            best_next_h = np.max(Q_high[next_state]) if next_state in Q_high else 0.0\n",
    "            td_h = (reward + gamma*best_next_h) - qh[group]\n",
    "            qh[group] += alpha * td_h\n",
    "            Q_high[state] = qh\n",
    "            # low update\n",
    "            ql = Q_low[(state, group)]\n",
    "            best_next_l = np.max(Q_low[(next_state, group)]) if (next_state, group) in Q_low else 0.0\n",
    "            td_l = (reward + gamma*best_next_l) - ql[low_choice]\n",
    "            ql[low_choice] += alpha * td_l\n",
    "            Q_low[(state, group)] = ql\n",
    "        eps = max(eps_min, eps * eps_decay)\n",
    "    return Q_high, Q_low\n",
    "\n",
    "def eval_policy(Q_high, Q_low, eval_df):\n",
    "    servers = reset_servers(NUM_SERVERS)\n",
    "    res = []\n",
    "    for _, row in eval_df.iterrows():\n",
    "        arrival = float(row['sec'])\n",
    "        state = make_state(servers)\n",
    "        group = int(np.argmax(Q_high[state])) if state in Q_high else random.randrange(GROUPS)\n",
    "        low_choice = int(np.argmax(Q_low[(state, group)])) if (state,group) in Q_low else 0\n",
    "        sid = group*SERVERS_PER_GROUP + low_choice\n",
    "        if sid >= NUM_SERVERS: sid = NUM_SERVERS-1\n",
    "        server = servers[sid]\n",
    "        service_time = sample_service_time()\n",
    "        start = max(arrival, server.next_free)\n",
    "        finish = start + service_time\n",
    "        response_time = finish - arrival\n",
    "        server.next_free = finish\n",
    "        res.append(response_time)\n",
    "    arr = np.array(res)\n",
    "    return arr.mean(), np.percentile(arr,95), (arr> SLA_SECONDS).mean()*100.0\n",
    "\n",
    "# prepare data slices\n",
    "reqs = pd.read_csv(REQUESTS_PATH).sort_values('sec').reset_index(drop=True)\n",
    "train_df = reqs.iloc[:train_n].copy()\n",
    "eval_df = reqs.iloc[train_n: train_n + eval_n].copy()\n",
    "\n",
    "results = []\n",
    "start_all = time.time()\n",
    "for wp in WAIT_PENALTIES:\n",
    "    for a in ALPHAS:\n",
    "        for g in GAMMAS:\n",
    "            t0 = time.time()\n",
    "            Qh, Ql = train_config(a,g, wp, EPISODES, train_df)\n",
    "            avg_rt, p95, sla = eval_policy(Qh, Ql, eval_df)\n",
    "            elapsed = time.time() - t0\n",
    "            results.append({'wait_penalty':wp, 'alpha':a, 'gamma':g, 'avg_rt':avg_rt, 'p95':p95, 'sla_pct':sla, 'time_s':elapsed})\n",
    "            print(f\"wp={wp} a={a} g={g} -> avg_rt={avg_rt:.3f} p95={p95:.3f} sla%={sla:.2f} (t={elapsed:.1f}s)\")\n",
    "            pd.DataFrame(results).to_csv(os.path.join(OUT_DIR, 'tuning_results.csv'), index=False)\n",
    "print(\"Grid done in\", round(time.time()-start_all,1),\"s\")\n",
    "print(\"Saved tuning_results.csv ->\", os.path.join(OUT_DIR, 'tuning_results.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83599054-6f79-4235-aa0c-a97b16d9c02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least-loaded | servers: 6 | requests: 199997\n",
      " Wall time: 20.22s\n",
      " Avg RT: 1.299 s | 95th: 2.291 s | Throughput: 0.008 req/s\n",
      " % SLA (> 2.0s): 9.02%\n",
      " Server busy-time (s): [43234.55, 43339.52, 43240.99, 43227.86, 43290.61, 43410.06]\n",
      "Saved per-request results to: ./anonymisedData/sim_results\\baseline_leastloaded_results.csv\n",
      "Appended least-loaded (pd.concat) to comparison_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Least-Loaded (greedy) scheduler baseline  run and compare to earlier baselines\n",
    "import os, time, numpy as np, pandas as pd\n",
    "from statistics import mean\n",
    "\n",
    "REQUESTS_PATH = './anonymisedData/requests.csv'\n",
    "OUT_DIR = './anonymisedData/sim_results'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "NUM_SERVERS = 6\n",
    "BASE_SERVICE = 0.8\n",
    "SERVICE_EXP_SCALE = 0.5\n",
    "SLA_SECONDS = 2.0\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, sid):\n",
    "        self.id = sid\n",
    "        self.next_free = 0.0\n",
    "\n",
    "def sample_service_time():\n",
    "    return BASE_SERVICE + np.random.exponential(SERVICE_EXP_SCALE)\n",
    "\n",
    "def run_least_loaded(num_servers=NUM_SERVERS):\n",
    "    reqs = pd.read_csv(REQUESTS_PATH).sort_values('sec').reset_index(drop=True)\n",
    "    reqs['arrival'] = reqs['sec'].astype(float)\n",
    "    servers = [Server(i) for i in range(num_servers)]\n",
    "    results = []\n",
    "    t0 = time.time()\n",
    "    for idx, row in reqs.iterrows():\n",
    "        arrival = float(row['arrival'])\n",
    "        # choose server with smallest next_free (least loaded)\n",
    "        sid = int(min(range(len(servers)), key=lambda i: servers[i].next_free))\n",
    "        server = servers[sid]\n",
    "        service_time = sample_service_time()\n",
    "        start = max(arrival, server.next_free)\n",
    "        finish = start + service_time\n",
    "        response_time = finish - arrival\n",
    "        server.next_free = finish\n",
    "        results.append({'request_idx': int(idx), 'arrival': arrival, 'server_id': sid,\n",
    "                        'start': start, 'finish': finish, 'service_time': service_time,\n",
    "                        'response_time': response_time})\n",
    "    duration = time.time() - t0\n",
    "    df = pd.DataFrame(results)\n",
    "    avg_rt = df['response_time'].mean()\n",
    "    p95 = df['response_time'].quantile(0.95)\n",
    "    throughput = len(df) / ((df['finish'].max() - df['arrival'].min()) if len(df)>0 else 1)\n",
    "    sla_viol = (df['response_time'] > SLA_SECONDS).mean() * 100.0\n",
    "    server_loads = df.groupby('server_id')['service_time'].sum().to_dict()\n",
    "    loads = [server_loads.get(i, 0.0) for i in range(num_servers)]\n",
    "    out_csv = os.path.join(OUT_DIR, 'baseline_leastloaded_results.csv')\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"Least-loaded | servers: {num_servers} | requests: {len(df)}\")\n",
    "    print(f\" Wall time: {duration:.2f}s\")\n",
    "    print(f\" Avg RT: {avg_rt:.3f} s | 95th: {p95:.3f} s | Throughput: {throughput:.3f} req/s\")\n",
    "    print(f\" % SLA (> {SLA_SECONDS}s): {sla_viol:.2f}%\")\n",
    "    print(\" Server busy-time (s):\", [round(x,2) for x in loads])\n",
    "    print(\"Saved per-request results to:\", out_csv)\n",
    "    return df, {'avg_rt': avg_rt, 'p95': p95, 'throughput': throughput, 'sla_viol_pct': sla_viol, 'loads': loads}\n",
    "\n",
    "df_ll, stats_ll = run_least_loaded(NUM_SERVERS)\n",
    "# append to comparison summary if exists\n",
    "comp_path = os.path.join(OUT_DIR, 'comparison_summary.csv')\n",
    "row = {'policy':'least_loaded','avg_rt_s':stats_ll['avg_rt'],'p95_s':stats_ll['p95'],\n",
    "       'throughput_rps':stats_ll['throughput'],'sla_viol_pct':stats_ll['sla_viol_pct']}\n",
    "if os.path.exists(comp_path):\n",
    "    # replace the block that used comp.append(...)\n",
    "    row_df = pd.DataFrame([row])\n",
    "    comp = pd.concat([comp, row_df], ignore_index=True)\n",
    "    comp.to_csv(comp_path, index=False)\n",
    "    print(\"Appended least-loaded (pd.concat) to comparison_summary.csv\")\n",
    "\n",
    "else:\n",
    "    pd.DataFrame([row]).to_csv(comp_path, index=False)\n",
    "    print(\"Created comparison_summary.csv with least-loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c374a3a-ba74-41a5-b9ba-95ba1576339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running least-loaded repeat 1 seed 42\n",
      " -> avg_rt: 1.3 p95: 2.294 SLA%: 9.016\n",
      "Running least-loaded repeat 2 seed 101\n",
      " -> avg_rt: 1.299 p95: 2.286 SLA%: 8.928\n",
      "Running least-loaded repeat 3 seed 202\n",
      " -> avg_rt: 1.299 p95: 2.3 SLA%: 9.018\n",
      "Running least-loaded repeat 4 seed 303\n",
      " -> avg_rt: 1.299 p95: 2.292 SLA%: 8.984\n",
      "Running least-loaded repeat 5 seed 404\n",
      " -> avg_rt: 1.3 p95: 2.301 SLA%: 9.047\n",
      "Saved repeats summary to: ./anonymisedData/sim_results\\leastloaded_repeats_summary.csv\n",
      "   run  seed    avg_rt       p95   sla_pct    rows\n",
      "0    1    42  1.300144  2.294482  9.015635  199997\n",
      "1    2   101  1.299309  2.285923  8.927634  199997\n",
      "2    3   202  1.298985  2.300488  9.018135  199997\n",
      "3    4   303  1.298751  2.291770  8.983635  199997\n",
      "4    5   404  1.299732  2.301431  9.046636  199997\n"
     ]
    }
   ],
   "source": [
    "# A: Repeat Least-Loaded 5 times (different RNG seeds), save per-run CSVs + summary\n",
    "import os, time, numpy as np, pandas as pd, random\n",
    "OUT = './anonymisedData/sim_results'\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "REQUESTS = './anonymisedData/requests.csv'\n",
    "reqs = pd.read_csv(REQUESTS).sort_values('sec').reset_index(drop=True)\n",
    "reqs['arrival'] = reqs['sec'].astype(float)\n",
    "\n",
    "NUM_RUNS = 5\n",
    "SEEDS = [42, 101, 202, 303, 404]\n",
    "NUM_SERVERS = 6\n",
    "BASE_SERVICE = 0.8\n",
    "SERVICE_EXP_SCALE = 0.5\n",
    "SLA = 2.0\n",
    "\n",
    "def do_run(seed, run_idx):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    servers = [{'id':i,'next_free':0.0} for i in range(NUM_SERVERS)]\n",
    "    rows = []\n",
    "    t0 = time.time()\n",
    "    for idx, row in reqs.iterrows():\n",
    "        arrival = float(row['arrival'])\n",
    "        # pick least-loaded server (min next_free)\n",
    "        sid = min(range(NUM_SERVERS), key=lambda i: servers[i]['next_free'])\n",
    "        server = servers[sid]\n",
    "        service_time = BASE_SERVICE + np.random.exponential(SERVICE_EXP_SCALE)\n",
    "        start = max(arrival, server['next_free'])\n",
    "        finish = start + service_time\n",
    "        response_time = finish - arrival\n",
    "        server['next_free'] = finish\n",
    "        rows.append({'request_idx': int(idx), 'arrival': arrival, 'server_id': sid,\n",
    "                     'start': start, 'finish': finish, 'service_time': service_time, 'response_time': response_time})\n",
    "    df = pd.DataFrame(rows)\n",
    "    # metrics\n",
    "    avg_rt = df['response_time'].mean()\n",
    "    p95 = df['response_time'].quantile(0.95)\n",
    "    sla_pct = (df['response_time'] > SLA).mean() * 100.0\n",
    "    out_file = os.path.join(OUT, f'leastloaded_run_{run_idx+1}.csv')\n",
    "    df.to_csv(out_file, index=False)\n",
    "    return {'run': run_idx+1, 'seed': seed, 'avg_rt': avg_rt, 'p95': p95, 'sla_pct': sla_pct, 'rows': len(df)}\n",
    "\n",
    "summary = []\n",
    "for i, s in enumerate(SEEDS[:NUM_RUNS]):\n",
    "    print(\"Running least-loaded repeat\", i+1, \"seed\", s)\n",
    "    res = do_run(s, i)\n",
    "    summary.append(res)\n",
    "    print(\" -> avg_rt:\", round(res['avg_rt'],3), \"p95:\", round(res['p95'],3), \"SLA%:\", round(res['sla_pct'],3))\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.to_csv(os.path.join(OUT, 'leastloaded_repeats_summary.csv'), index=False)\n",
    "print(\"Saved repeats summary to:\", os.path.join(OUT, 'leastloaded_repeats_summary.csv'))\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "344acdbd-1f31-4497-8318-379702ba4025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests: 199997 | training per episode: 100000 | eval: 99997\n",
      "\n",
      "=== RL run seed 42 ===\n",
      "  Ep 1/60 avg_reward=-1.3038 eps=0.9490\n",
      "  Ep 10/60 avg_reward=-1.3035 eps=0.9405\n",
      "  Ep 20/60 avg_reward=-1.3039 eps=0.9312\n",
      "  Ep 30/60 avg_reward=-1.3040 eps=0.9219\n",
      "  Ep 40/60 avg_reward=-1.3036 eps=0.9127\n",
      "  Ep 50/60 avg_reward=-1.3019 eps=0.9036\n",
      "  Ep 60/60 avg_reward=-1.3037 eps=0.8946\n",
      " -> eval avg_rt=1.309 p95=2.324 sla%=9.516  (saved ./anonymisedData\\sim_results\\rl_full_eval_seed_42.csv)\n",
      "\n",
      "=== RL run seed 101 ===\n",
      "  Ep 1/60 avg_reward=-1.3045 eps=0.9490\n",
      "  Ep 10/60 avg_reward=-1.3020 eps=0.9405\n",
      "  Ep 20/60 avg_reward=-1.3024 eps=0.9312\n",
      "  Ep 30/60 avg_reward=-1.3018 eps=0.9219\n",
      "  Ep 40/60 avg_reward=-1.3033 eps=0.9127\n",
      "  Ep 50/60 avg_reward=-1.3027 eps=0.9036\n",
      "  Ep 60/60 avg_reward=-1.3008 eps=0.8946\n",
      " -> eval avg_rt=1.311 p95=2.335 sla%=9.633  (saved ./anonymisedData\\sim_results\\rl_full_eval_seed_101.csv)\n",
      "\n",
      "=== RL run seed 202 ===\n",
      "  Ep 1/60 avg_reward=-1.3015 eps=0.9490\n",
      "  Ep 10/60 avg_reward=-1.3013 eps=0.9405\n",
      "  Ep 20/60 avg_reward=-1.3044 eps=0.9312\n",
      "  Ep 30/60 avg_reward=-1.2994 eps=0.9219\n",
      "  Ep 40/60 avg_reward=-1.3043 eps=0.9127\n",
      "  Ep 50/60 avg_reward=-1.3028 eps=0.9036\n",
      "  Ep 60/60 avg_reward=-1.3031 eps=0.8946\n",
      " -> eval avg_rt=1.300 p95=2.304 sla%=9.167  (saved ./anonymisedData\\sim_results\\rl_full_eval_seed_202.csv)\n",
      "\n",
      "=== RL run seed 303 ===\n",
      "  Ep 1/60 avg_reward=-1.3008 eps=0.9490\n",
      "  Ep 10/60 avg_reward=-1.3029 eps=0.9405\n",
      "  Ep 20/60 avg_reward=-1.3034 eps=0.9312\n",
      "  Ep 30/60 avg_reward=-1.3044 eps=0.9219\n",
      "  Ep 40/60 avg_reward=-1.3020 eps=0.9127\n",
      "  Ep 50/60 avg_reward=-1.3039 eps=0.9036\n",
      "  Ep 60/60 avg_reward=-1.3032 eps=0.8946\n",
      " -> eval avg_rt=1.305 p95=2.319 sla%=9.360  (saved ./anonymisedData\\sim_results\\rl_full_eval_seed_303.csv)\n",
      "\n",
      "=== RL run seed 404 ===\n",
      "  Ep 1/60 avg_reward=-1.3038 eps=0.9490\n",
      "  Ep 10/60 avg_reward=-1.3021 eps=0.9405\n",
      "  Ep 20/60 avg_reward=-1.3036 eps=0.9312\n",
      "  Ep 30/60 avg_reward=-1.3018 eps=0.9219\n",
      "  Ep 40/60 avg_reward=-1.3010 eps=0.9127\n",
      "  Ep 50/60 avg_reward=-1.3032 eps=0.9036\n",
      "  Ep 60/60 avg_reward=-1.3013 eps=0.8946\n",
      " -> eval avg_rt=1.308 p95=2.326 sla%=9.528  (saved ./anonymisedData\\sim_results\\rl_full_eval_seed_404.csv)\n",
      "\n",
      "Saved per-seed summary to: ./anonymisedData\\sim_results\\rl_full_summary.csv\n",
      "   seed    avg_rt       p95   sla_pct  train_time_s  eval_rows  \\\n",
      "0    42  1.308622  2.323625  9.516285   1177.783533      99997   \n",
      "1   101  1.311430  2.335176  9.633289   1142.583969      99997   \n",
      "2   202  1.300239  2.304134  9.167275   1131.099442      99997   \n",
      "3   303  1.304791  2.319008  9.360281   1213.800005      99997   \n",
      "4   404  1.308389  2.326013  9.528286   1126.840254      99997   \n",
      "\n",
      "                                           eval_file  \n",
      "0  ./anonymisedData\\sim_results\\rl_full_eval_seed...  \n",
      "1  ./anonymisedData\\sim_results\\rl_full_eval_seed...  \n",
      "2  ./anonymisedData\\sim_results\\rl_full_eval_seed...  \n",
      "3  ./anonymisedData\\sim_results\\rl_full_eval_seed...  \n",
      "4  ./anonymisedData\\sim_results\\rl_full_eval_seed...  \n"
     ]
    }
   ],
   "source": [
    "# Full RL repeated runs (strong training, 5 seeds)  copy & run as one cell\n",
    "import os, time, random\n",
    "import numpy as np, pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Paths\n",
    "ROOT = './anonymisedData'\n",
    "REQ_PATH = os.path.join(ROOT, 'requests.csv')\n",
    "OUT = os.path.join(ROOT, 'sim_results')\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# --- RL / env hyperparameters (recommended strong settings)\n",
    "NUM_SERVERS = 6\n",
    "GROUPS = 2\n",
    "SERVERS_PER_GROUP = NUM_SERVERS // GROUPS\n",
    "BASE_SERVICE = 0.8\n",
    "SERVICE_EXP_SCALE = 0.5\n",
    "SLA_SECONDS = 2.0\n",
    "\n",
    "ALPHA = 0.03\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.95\n",
    "EPS_MIN = 0.05\n",
    "EPS_DECAY = 0.999\n",
    "\n",
    "EPISODES = 60            # strong training\n",
    "TRAIN_N = 100_000        # number training requests per episode\n",
    "SEEDS = [42, 101, 202, 303, 404]   # independent repeats\n",
    "WAIT_PENALTY = 0.2       # strong wait penalty\n",
    "SAVE_PREFIX = 'rl_full'  # output prefix\n",
    "\n",
    "# --- Helpers\n",
    "def bucket_load(load, bins=(0,5,10,20,50,100,999999)):\n",
    "    for i,b in enumerate(bins):\n",
    "        if load <= b:\n",
    "            return i\n",
    "    return len(bins)\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, sid):\n",
    "        self.id = sid\n",
    "        self.next_free = 0.0\n",
    "\n",
    "def reset_servers(num_servers):\n",
    "    return [Server(i) for i in range(num_servers)]\n",
    "\n",
    "def sample_service_time(rng):\n",
    "    return BASE_SERVICE + rng.exponential(SERVICE_EXP_SCALE)\n",
    "\n",
    "def make_state(servers, last_assigned_mod=0):\n",
    "    loads = [s.next_free for s in servers]\n",
    "    avg_load = sum(loads)/len(loads) if loads else 0.0\n",
    "    max_load = max(loads) if loads else 0.0\n",
    "    imbalance = int(min(9, max(0, (max_load - avg_load)//10)))\n",
    "    # group average coarse bucket (group 0)\n",
    "    group_avgs = []\n",
    "    for g in range(GROUPS):\n",
    "        group_ids = list(range(g*SERVERS_PER_GROUP, min(NUM_SERVERS, (g+1)*SERVERS_PER_GROUP)))\n",
    "        gavg = sum(loads[i] for i in group_ids)/len(group_ids)\n",
    "        group_avgs.append(bucket_load(gavg))\n",
    "    # state = (avg_bucket, imbalance_bucket, group0_bucket, last_assigned_mod)\n",
    "    return (bucket_load(avg_load), imbalance, group_avgs[0], int(last_assigned_mod))\n",
    "\n",
    "# --- Q helpers\n",
    "def make_Q():\n",
    "    Qh = defaultdict(lambda: np.zeros(GROUPS))\n",
    "    Ql = defaultdict(lambda: np.zeros(SERVERS_PER_GROUP))\n",
    "    return Qh, Ql\n",
    "\n",
    "def choose_action_eps_greedy(state, Qh, Ql, eps, rng):\n",
    "    # high-level\n",
    "    if rng.random() < eps:\n",
    "        group = rng.integers(0, GROUPS)\n",
    "    else:\n",
    "        group = int(np.argmax(Qh[state]))\n",
    "    # low-level\n",
    "    if rng.random() < eps:\n",
    "        low_choice = rng.integers(0, SERVERS_PER_GROUP)\n",
    "    else:\n",
    "        low_choice = int(np.argmax(Ql[(state, group)]))\n",
    "    sid = group*SERVERS_PER_GROUP + low_choice\n",
    "    if sid >= NUM_SERVERS:\n",
    "        sid = NUM_SERVERS-1\n",
    "    return group, low_choice, sid\n",
    "\n",
    "# --- Load requests and create train/eval splits\n",
    "reqs = pd.read_csv(REQ_PATH).sort_values('sec').reset_index(drop=True)\n",
    "total_reqs = len(reqs)\n",
    "train_n = min(TRAIN_N, total_reqs)\n",
    "train_df = reqs.iloc[:train_n].copy()\n",
    "eval_df = reqs.iloc[train_n:].copy()\n",
    "print(\"Total requests:\", total_reqs, \"| training per episode:\", len(train_df), \"| eval:\", len(eval_df))\n",
    "\n",
    "# --- Main repeated-run loop\n",
    "summary_rows = []\n",
    "for seed in SEEDS:\n",
    "    print(\"\\n=== RL run seed\", seed, \"===\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    Q_high, Q_low = make_Q()\n",
    "    eps = EPS_START\n",
    "    last_assigned = 0\n",
    "\n",
    "    # training\n",
    "    tstart = time.time()\n",
    "    per_episode_rewards = []\n",
    "    for ep in range(1, EPISODES+1):\n",
    "        servers = reset_servers(NUM_SERVERS)\n",
    "        total_reward = 0.0\n",
    "        steps = 0\n",
    "        for _, row in train_df.iterrows():\n",
    "            arrival = float(row['sec'])\n",
    "            state = make_state(servers, last_assigned_mod=(last_assigned % SERVERS_PER_GROUP))\n",
    "            group, low_choice, sid = choose_action_eps_greedy(state, Q_high, Q_low, eps, rng)\n",
    "            # sample service\n",
    "            service_time = sample_service_time(rng)\n",
    "            server = servers[sid]\n",
    "            wait = max(0.0, server.next_free - arrival)\n",
    "            start = max(arrival, server.next_free)\n",
    "            finish = start + service_time\n",
    "            response_time = finish - arrival\n",
    "            # reward with wait penalty\n",
    "            reward = -response_time - 0.0001*service_time - WAIT_PENALTY * wait\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "            # update server\n",
    "            server.next_free = finish\n",
    "            last_assigned = sid\n",
    "            next_state = make_state(servers, last_assigned_mod=(last_assigned % SERVERS_PER_GROUP))\n",
    "            # Q updates\n",
    "            qh = Q_high[state]\n",
    "            best_next_h = np.max(Q_high[next_state]) if next_state in Q_high else 0.0\n",
    "            td_h = (reward + GAMMA * best_next_h) - qh[group]\n",
    "            qh[group] += ALPHA * td_h\n",
    "            Q_high[state] = qh\n",
    "            ql = Q_low[(state, group)]\n",
    "            best_next_l = np.max(Q_low[(next_state, group)]) if (next_state, group) in Q_low else 0.0\n",
    "            td_l = (reward + GAMMA * best_next_l) - ql[low_choice]\n",
    "            ql[low_choice] += ALPHA * td_l\n",
    "            Q_low[(state, group)] = ql\n",
    "        per_episode_rewards.append(total_reward / max(1, steps))\n",
    "        eps = max(EPS_MIN, eps * EPS_DECAY)\n",
    "        if ep % 10 == 0 or ep == 1 or ep == EPISODES:\n",
    "            print(f\"  Ep {ep}/{EPISODES} avg_reward={per_episode_rewards[-1]:.4f} eps={eps:.4f}\")\n",
    "    ttrain = time.time() - tstart\n",
    "    # save per-episode rewards\n",
    "    pd.DataFrame({'episode': list(range(1, EPISODES+1)), 'avg_reward': per_episode_rewards}).to_csv(\n",
    "        os.path.join(OUT, f'{SAVE_PREFIX}_rewards_seed_{seed}.csv'), index=False)\n",
    "\n",
    "    # evaluation (greedy)\n",
    "    servers = reset_servers(NUM_SERVERS)\n",
    "    last_assigned = 0\n",
    "    rows = []\n",
    "    for idx, row in eval_df.iterrows():\n",
    "        arrival = float(row['sec'])\n",
    "        state = make_state(servers, last_assigned_mod=(last_assigned % SERVERS_PER_GROUP))\n",
    "        # greedy selection\n",
    "        if state in Q_high:\n",
    "            group = int(np.argmax(Q_high[state]))\n",
    "        else:\n",
    "            group = rng.integers(0, GROUPS)\n",
    "        if (state, group) in Q_low:\n",
    "            low_choice = int(np.argmax(Q_low[(state, group)]))\n",
    "        else:\n",
    "            low_choice = 0\n",
    "        sid = group*SERVERS_PER_GROUP + low_choice\n",
    "        if sid >= NUM_SERVERS: sid = NUM_SERVERS-1\n",
    "        server = servers[sid]\n",
    "        service_time = sample_service_time(rng)\n",
    "        start = max(arrival, server.next_free)\n",
    "        finish = start + service_time\n",
    "        response_time = finish - arrival\n",
    "        server.next_free = finish\n",
    "        last_assigned = sid\n",
    "        rows.append({'request_idx': int(train_n + idx), 'arrival': arrival, 'server_id': sid,\n",
    "                     'start': start, 'finish': finish, 'service_time': service_time, 'response_time': response_time})\n",
    "    df_eval = pd.DataFrame(rows)\n",
    "    out_eval = os.path.join(OUT, f'{SAVE_PREFIX}_eval_seed_{seed}.csv')\n",
    "    df_eval.to_csv(out_eval, index=False)\n",
    "\n",
    "    # metrics\n",
    "    avg_rt = df_eval['response_time'].mean()\n",
    "    p95 = df_eval['response_time'].quantile(0.95)\n",
    "    sla_pct = (df_eval['response_time'] > SLA_SECONDS).mean() * 100.0\n",
    "    summary_rows.append({'seed': seed, 'avg_rt': avg_rt, 'p95': p95, 'sla_pct': sla_pct, 'train_time_s': ttrain, 'eval_rows': len(df_eval), 'eval_file': out_eval})\n",
    "    print(f\" -> eval avg_rt={avg_rt:.3f} p95={p95:.3f} sla%={sla_pct:.3f}  (saved {out_eval})\")\n",
    "\n",
    "# --- Save overall summary\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(os.path.join(OUT, f'{SAVE_PREFIX}_summary.csv'), index=False)\n",
    "print(\"\\nSaved per-seed summary to:\", os.path.join(OUT, f'{SAVE_PREFIX}_summary.csv'))\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69de9e88-5f93-4dca-864b-e0c59d29ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SJF -> ./anonymisedData\\sim_results\\sjf_results.csv\n",
      "Saved Priority -> ./anonymisedData\\sim_results\\priority_results.csv\n"
     ]
    }
   ],
   "source": [
    "# NEW BASELINES: SJF (oracle) and Priority (G3 low-first)\n",
    "import os, pandas as pd, numpy as np\n",
    "ROOT = './anonymisedData'\n",
    "SR = os.path.join(ROOT, 'sim_results'); os.makedirs(SR, exist_ok=True)\n",
    "reqs = pd.read_csv(os.path.join(ROOT,'requests.csv')).sort_values('sec').reset_index(drop=True)\n",
    "reqs['arrival'] = reqs['sec'].astype(float)\n",
    "\n",
    "NUM_SERVERS = 6\n",
    "BASE_SERVICE = 0.8\n",
    "SERVICE_EXP_SCALE = 0.5\n",
    "SLA = 2.0\n",
    "\n",
    "# helper to sample service times deterministically (use numpy RNG with seed for reproducibility)\n",
    "rng = np.random.default_rng(12345)\n",
    "service_times = BASE_SERVICE + rng.exponential(SERVICE_EXP_SCALE, size=len(reqs))\n",
    "reqs['true_service_time'] = service_times\n",
    "\n",
    "def run_sjf():\n",
    "    servers = [{'id':i,'next_free':0.0} for i in range(NUM_SERVERS)]\n",
    "    rows = []\n",
    "    # SJF oracle: at each arrival, if multiple outstanding, pick the job with smallest service_time.\n",
    "    # Simpler: as we model streaming arrivals with no queue lookahead, emulate an oracle by assigning\n",
    "    # server to the arriving request but pick server with earliest next_free as usual. To represent SJF upper-bound,\n",
    "    # we perform offline scheduling: sort all requests by service_time and assign greedily to next-free server.\n",
    "    order = np.argsort(reqs['true_service_time'].values)\n",
    "    for idx in order:\n",
    "        arrival = float(reqs.loc[idx,'arrival'])\n",
    "        sid = min(range(NUM_SERVERS), key=lambda i: servers[i]['next_free'])\n",
    "        server = servers[sid]\n",
    "        service_time = float(reqs.loc[idx,'true_service_time'])\n",
    "        start = max(arrival, server['next_free'])\n",
    "        finish = start + service_time\n",
    "        response_time = finish - arrival\n",
    "        server['next_free'] = finish\n",
    "        rows.append({'request_idx': int(idx), 'arrival': arrival, 'server_id': sid, 'start': start, 'finish': finish, 'service_time': service_time, 'response_time': response_time})\n",
    "    pd.DataFrame(rows).to_csv(os.path.join(SR,'sjf_results.csv'), index=False)\n",
    "    print(\"Saved SJF ->\", os.path.join(SR,'sjf_results.csv'))\n",
    "\n",
    "def run_priority():\n",
    "    # priority: requests with low G3 (<=10) get priority (tie-break by arrival). if G3 not present, fallback to random.\n",
    "    servers = [{'id':i,'next_free':0.0} for i in range(NUM_SERVERS)]\n",
    "    rows = []\n",
    "    if 'G3' not in reqs.columns:\n",
    "        reqs['G3'] = 10  # fallback\n",
    "    # process by arrival but maintain a small waiting queue and pop highest priority when server free\n",
    "    # For simplicity, we'll implement preemptive priority at arrival: assign directly to least-loaded, but use ordering that processes high-priority first within same arrival batch\n",
    "    grouped = reqs.groupby('arrival')\n",
    "    for arrival, group in grouped:\n",
    "        group = group.sort_values('G3')  # low G3 first\n",
    "        for _, r in group.iterrows():\n",
    "            sid = min(range(NUM_SERVERS), key=lambda i: servers[i]['next_free'])\n",
    "            server = servers[sid]\n",
    "            service_time = BASE_SERVICE + np.random.default_rng(int(r.name)%1000).exponential(SERVICE_EXP_SCALE)\n",
    "            start = max(arrival, server['next_free'])\n",
    "            finish = start + service_time\n",
    "            response_time = finish - arrival\n",
    "            server['next_free'] = finish\n",
    "            rows.append({'request_idx': int(r.name), 'arrival': arrival, 'server_id': sid, 'start': start, 'finish': finish, 'service_time': service_time, 'response_time': response_time, 'G3': r.get('G3', None)})\n",
    "    pd.DataFrame(rows).to_csv(os.path.join(SR,'priority_results.csv'), index=False)\n",
    "    print(\"Saved Priority ->\", os.path.join(SR,'priority_results.csv'))\n",
    "\n",
    "run_sjf()\n",
    "run_priority()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08c447ac-703d-48ff-90e8-1770cd057c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ablation_quick_summary.csv -> ./anonymisedData\\sim_results\\ablation_quick_summary.csv\n",
      "[{'variant': 'no_shaping', 'avg_reward': -1.2981880664613263}, {'variant': 'shaping_no_equity', 'avg_reward': -1.2981880664613263}, {'variant': 'shaping_with_equity', 'avg_reward': -1.3003777672339827}]\n"
     ]
    }
   ],
   "source": [
    "# Ablation harness: quick runs (small trace) - reward shaping vs no-shaping; equity-penalty vs none\n",
    "import os, time, numpy as np, pandas as pd, random\n",
    "ROOT = './anonymisedData'; SR = os.path.join(ROOT,'sim_results'); os.makedirs(SR,exist_ok=True)\n",
    "reqs = pd.read_csv(os.path.join(ROOT,'requests.csv')).sort_values('sec').reset_index(drop=True)\n",
    "reqs = reqs.iloc[:50000]  # small quick test\n",
    "NUM_SERVERS=6; BASE=0.8; SCALE=0.5\n",
    "\n",
    "def run_rl_variant(equity_penalty=False, wait_penalty=0.2, seed=1):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    servers = [{'id':i,'next_free':0.0} for i in range(NUM_SERVERS)]\n",
    "    Q_high = {}; Q_low = {}\n",
    "    total_reward=0; steps=0\n",
    "    # super-simplified single-episode tabular training on small set\n",
    "    for _, r in reqs.iterrows():\n",
    "        arrival = float(r['sec'])\n",
    "        sid = min(range(NUM_SERVERS), key=lambda i: servers[i]['next_free'])\n",
    "        server = servers[sid]\n",
    "        service_time = BASE + np.random.exponential(SCALE)\n",
    "        wait = max(0.0, server['next_free'] - arrival)\n",
    "        start = max(arrival, server['next_free'])\n",
    "        finish = start + service_time\n",
    "        response_time = finish - arrival\n",
    "        # reward: baseline negative response time; add equity penalty if requested (penalize for long RTs for e.g., no-internet group)\n",
    "        reward = -response_time - 0.0001*service_time - wait_penalty*wait\n",
    "        if equity_penalty and 'internet' in reqs.columns and r['internet']=='no':\n",
    "            reward -= 0.01*response_time  # small extra penalty for disadvantaging no-internet\n",
    "        total_reward += reward; steps+=1\n",
    "        server['next_free'] = finish\n",
    "    return total_reward/steps\n",
    "\n",
    "variants = [\n",
    "    {'name':'no_shaping','equity':False,'wait_penalty':0.0},\n",
    "    {'name':'shaping_no_equity','equity':False,'wait_penalty':0.2},\n",
    "    {'name':'shaping_with_equity','equity':True,'wait_penalty':0.2}\n",
    "]\n",
    "rows=[]\n",
    "for v in variants:\n",
    "    ar = run_rl_variant(equity_penalty=v['equity'], wait_penalty=v['wait_penalty'], seed=42)\n",
    "    rows.append({'variant':v['name'],'avg_reward':ar})\n",
    "pd.DataFrame(rows).to_csv(os.path.join(SR,'ablation_quick_summary.csv'), index=False)\n",
    "print(\"Saved ablation_quick_summary.csv ->\", os.path.join(SR,'ablation_quick_summary.csv'))\n",
    "print(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef0d8ff2-3028-474d-9f59-9f0aded6e758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bootstrap_summary.csv -> ./anonymisedData/sim_results\\bootstrap_summary.csv\n",
      "         policy       mean_rt    mean_rt_lo    mean_rt_hi    sla_pct  \\\n",
      "0  least_loaded  1.300144e+00  1.298008e+00  1.302354e+00   9.015635   \n",
      "1            rl  1.300239e+00  1.297138e+00  1.303421e+00   9.167275   \n",
      "2           sjf  1.492578e+07  1.489653e+07  1.495444e+07  99.965499   \n",
      "3      priority  1.309651e+00  1.307585e+00  1.311810e+00  10.000150   \n",
      "\n",
      "      sla_lo     sla_hi  \n",
      "0   8.892633   9.138162  \n",
      "1   8.989220   9.356331  \n",
      "2  99.956499  99.973000  \n",
      "3   9.865635  10.123164  \n"
     ]
    }
   ],
   "source": [
    "# Bootstrap 95% CI for mean RT and SLA% for given per-request CSVs\n",
    "import os, pandas as pd, numpy as np\n",
    "SR = './anonymisedData/sim_results'\n",
    "def bootstrap_ci(arr, statfunc=np.mean, nboot=1000, alpha=0.05):\n",
    "    n = len(arr)\n",
    "    idx = np.random.randint(0, n, size=(nboot, n))\n",
    "    stats = np.array([statfunc(arr[i]) for i in idx])\n",
    "    lo = np.percentile(stats, 100*alpha/2)\n",
    "    hi = np.percentile(stats, 100*(1-alpha/2))\n",
    "    return lo, hi\n",
    "\n",
    "policies = {'least_loaded': 'leastloaded_run_1.csv', 'rl': 'rl_full_eval_seed_202.csv', 'sjf':'sjf_results.csv','priority':'priority_results.csv'}\n",
    "summary=[]\n",
    "for name,f in policies.items():\n",
    "    path = os.path.join(SR,f)\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        arr = df['response_time'].values\n",
    "        mean = arr.mean()\n",
    "        lo,hi = bootstrap_ci(arr, np.mean, nboot=1000)\n",
    "        sla = (arr>2.0).mean()*100\n",
    "        slo,shi = bootstrap_ci((arr>2.0).astype(float)*100, np.mean, nboot=1000)\n",
    "        summary.append({'policy':name,'mean_rt':mean,'mean_rt_lo':lo,'mean_rt_hi':hi,'sla_pct':sla,'sla_lo':slo,'sla_hi':shi})\n",
    "pd.DataFrame(summary).to_csv(os.path.join(SR,'bootstrap_summary.csv'), index=False)\n",
    "print(\"Saved bootstrap_summary.csv ->\", os.path.join(SR,'bootstrap_summary.csv'))\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b68269-3268-44fd-b778-63ba9726cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected event-driven SJF (respect arrivals) + recompute bootstrap CIs\n",
    "import os, heapq, numpy as np, pandas as pd\n",
    "\n",
    "ROOT = './anonymisedData'\n",
    "SR = os.path.join(ROOT, 'sim_results'); os.makedirs(SR, exist_ok=True)\n",
    "\n",
    "reqs = pd.read_csv(os.path.join(ROOT,'requests.csv')).sort_values('sec').reset_index(drop=True)\n",
    "reqs['arrival'] = reqs['sec'].astype(float)\n",
    "N = len(reqs)\n",
    "\n",
    "NUM_SERVERS = 6\n",
    "BASE_SERVICE = 0.8\n",
    "SERVICE_EXP_SCALE = 0.5\n",
    "\n",
    "# reproducible true service times (same seed used earlier)\n",
    "rng = np.random.default_rng(12345)\n",
    "service_times = BASE_SERVICE + rng.exponential(SERVICE_EXP_SCALE, size=N)\n",
    "reqs['true_service_time'] = service_times\n",
    "\n",
    "def run_sjf_event_driven(reqs_df, out_path):\n",
    "    arrivals = list(reqs_df['arrival'].values)\n",
    "    svc = list(reqs_df['true_service_time'].values)\n",
    "    N = len(arrivals)\n",
    "    i = 0\n",
    "    current_time = arrivals[0] if N>0 else 0.0\n",
    "    wait_heap = []                      # (service_time, idx, arrival)\n",
    "    servers_next_free = [0.0]*NUM_SERVERS\n",
    "    rows = []\n",
    "    processed = 0\n",
    "\n",
    "    while processed < N:\n",
    "        # add arrivals that have occurred up to current_time\n",
    "        while i < N and arrivals[i] <= current_time:\n",
    "            heapq.heappush(wait_heap, (svc[i], i, arrivals[i]))\n",
    "            i += 1\n",
    "\n",
    "        # assign shortest waiting jobs to any free servers\n",
    "        free_servers = [sid for sid, t in enumerate(servers_next_free) if t <= current_time]\n",
    "        if free_servers and wait_heap:\n",
    "            free_servers.sort()\n",
    "            for sid in free_servers:\n",
    "                if not wait_heap:\n",
    "                    break\n",
    "                service_time, idx, arr_time = heapq.heappop(wait_heap)\n",
    "                start = max(arr_time, servers_next_free[sid], current_time)\n",
    "                finish = start + service_time\n",
    "                response_time = finish - arr_time\n",
    "                servers_next_free[sid] = finish\n",
    "                rows.append({'request_idx': int(idx), 'arrival': arr_time, 'server_id': sid,\n",
    "                             'start': start, 'finish': finish, 'service_time': service_time, 'response_time': response_time})\n",
    "                processed += 1\n",
    "            continue\n",
    "\n",
    "        # advance time to next event (arrival or next server free)\n",
    "        next_arrival = arrivals[i] if i < N else float('inf')\n",
    "        next_server_free = min(servers_next_free) if servers_next_free else float('inf')\n",
    "        nxt = min(next_arrival, next_server_free)\n",
    "        if nxt == float('inf'):\n",
    "            break\n",
    "        # advance current time (ensure progress)\n",
    "        current_time = max(current_time, nxt)\n",
    "\n",
    "    # If any requests remain unscheduled (safety), assign them greedily\n",
    "    if processed < N:\n",
    "        remaining = []\n",
    "        while i < N:\n",
    "            remaining.append((svc[i], i, arrivals[i])); i += 1\n",
    "        while wait_heap:\n",
    "            remaining.append(heapq.heappop(wait_heap))\n",
    "        remaining.sort(key=lambda x: x[0])\n",
    "        for service_time, idx, arr_time in remaining:\n",
    "            sid = int(min(range(NUM_SERVERS), key=lambda s: servers_next_free[s]))\n",
    "            start = max(arr_time, servers_next_free[sid])\n",
    "            finish = start + service_time\n",
    "            response_time = finish - arr_time\n",
    "            servers_next_free[sid] = finish\n",
    "            rows.append({'request_idx': int(idx), 'arrival': arr_time, 'server_id': sid,\n",
    "                         'start': start, 'finish': finish, 'service_time': service_time, 'response_time': response_time})\n",
    "            processed += 1\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values('request_idx').reset_index(drop=True)\n",
    "    df.to_csv(out_path, index=False)\n",
    "    return df\n",
    "\n",
    "out_sjf = os.path.join(SR, 'sjf_results_fixed.csv')\n",
    "df_sjf = run_sjf_event_driven(reqs, out_sjf)\n",
    "print(\"Saved fixed SJF ->\", out_sjf)\n",
    "\n",
    "# recompute bootstrap CIs for mean RT and SLA for main policies (1000 bootstrap samples)\n",
    "def bootstrap_ci(arr, statfunc=np.mean, nboot=1000, alpha=0.05):\n",
    "    n = len(arr)\n",
    "    idx = np.random.randint(0, n, size=(nboot, n))\n",
    "    stats = np.array([statfunc(arr[i]) for i in idx])\n",
    "    lo = np.percentile(stats, 100*alpha/2)\n",
    "    hi = np.percentile(stats, 100*(1-alpha/2))\n",
    "    return lo, hi\n",
    "\n",
    "policies = {\n",
    "    'least_loaded': os.path.join(SR, 'leastloaded_run_1.csv'),\n",
    "    'rl': os.path.join(SR, 'rl_full_eval_seed_202.csv'),\n",
    "    'sjf_fixed': out_sjf,\n",
    "    'priority': os.path.join(SR, 'priority_results.csv')\n",
    "}\n",
    "\n",
    "summary = []\n",
    "for name, path in policies.items():\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        arr = df['response_time'].values\n",
    "        mean = float(arr.mean())\n",
    "        lo, hi = bootstrap_ci(arr, np.mean, nboot=1000)\n",
    "        sla = float((arr > 2.0).mean() * 100)\n",
    "        slo, shi = bootstrap_ci((arr > 2.0).astype(float) * 100, np.mean, nboot=1000)\n",
    "        summary.append({'policy': name, 'mean_rt': mean, 'mean_rt_lo': lo, 'mean_rt_hi': hi, 'sla_pct': sla, 'sla_lo': slo, 'sla_hi': shi})\n",
    "\n",
    "out_boot = os.path.join(SR, 'bootstrap_summary_fixed.csv')\n",
    "pd.DataFrame(summary).to_csv(out_boot, index=False)\n",
    "print(\"Saved bootstrap summary ->\", out_boot)\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6a6741d-40b9-48e6-b916-c0f23c77095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sjf_fixed: MISSING -> ./anonymisedData/sim_results\\sjf_results_fixed.csv\n",
      "bootstrap_fixed: MISSING -> ./anonymisedData/sim_results\\bootstrap_summary_fixed.csv\n",
      "bootstrap_old: EXISTS -> ./anonymisedData/sim_results\\bootstrap_summary.csv | size=536 bytes | mtime=Thu Aug 14 11:42:49 2025\n",
      "\n",
      "Preview of bootstrap_summary.csv (old):\n",
      "      policy      mean_rt   mean_rt_lo   mean_rt_hi   sla_pct    sla_lo    sla_hi\n",
      "least_loaded 1.300144e+00 1.298008e+00 1.302354e+00  9.015635  8.892633  9.138162\n",
      "          rl 1.300239e+00 1.297138e+00 1.303421e+00  9.167275  8.989220  9.356331\n",
      "         sjf 1.492578e+07 1.489653e+07 1.495444e+07 99.965499 99.956499 99.973000\n",
      "    priority 1.309651e+00 1.307585e+00 1.311810e+00 10.000150  9.865635 10.123164\n"
     ]
    }
   ],
   "source": [
    "import os, time, pandas as pd\n",
    "SR = './anonymisedData/sim_results'\n",
    "files = {\n",
    "    'sjf_fixed': os.path.join(SR,'sjf_results_fixed.csv'),\n",
    "    'bootstrap_fixed': os.path.join(SR,'bootstrap_summary_fixed.csv'),\n",
    "    'bootstrap_old': os.path.join(SR,'bootstrap_summary.csv')\n",
    "}\n",
    "for k,p in files.items():\n",
    "    if os.path.exists(p):\n",
    "        st = os.stat(p)\n",
    "        print(f\"{k}: EXISTS -> {p} | size={st.st_size:,} bytes | mtime={time.ctime(st.st_mtime)}\")\n",
    "    else:\n",
    "        print(f\"{k}: MISSING -> {p}\")\n",
    "\n",
    "if os.path.exists(files['bootstrap_fixed']):\n",
    "    print(\"\\nPreview of bootstrap_summary_fixed.csv:\")\n",
    "    print(pd.read_csv(files['bootstrap_fixed']).head(20).to_string(index=False))\n",
    "elif os.path.exists(files['bootstrap_old']):\n",
    "    print(\"\\nPreview of bootstrap_summary.csv (old):\")\n",
    "    print(pd.read_csv(files['bootstrap_old']).head(20).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo bootstrap summary found yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68663fac-12d7-4871-be6b-6b2c172d8b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sjf_fixed -> MISSING | ./anonymisedData/sim_results\\sjf_results_fixed.csv\n",
      "bootstrap_fixed -> MISSING | ./anonymisedData/sim_results\\bootstrap_summary_fixed.csv\n",
      "bootstrap_old -> EXISTS | ./anonymisedData/sim_results\\bootstrap_summary.csv\n",
      "cdf_png -> MISSING | ./anonymisedData/sim_results\\response_time_cdf.png\n",
      "\n",
      "Preview bootstrap_summary.csv:\n",
      "      policy      mean_rt   mean_rt_lo   mean_rt_hi   sla_pct    sla_lo    sla_hi\n",
      "least_loaded 1.300144e+00 1.298008e+00 1.302354e+00  9.015635  8.892633  9.138162\n",
      "          rl 1.300239e+00 1.297138e+00 1.303421e+00  9.167275  8.989220  9.356331\n",
      "         sjf 1.492578e+07 1.489653e+07 1.495444e+07 99.965499 99.956499 99.973000\n",
      "    priority 1.309651e+00 1.307585e+00 1.311810e+00 10.000150  9.865635 10.123164\n"
     ]
    }
   ],
   "source": [
    "import os, time, pandas as pd\n",
    "SR = './anonymisedData/sim_results'\n",
    "files = {\n",
    "  'sjf_fixed': os.path.join(SR,'sjf_results_fixed.csv'),\n",
    "  'bootstrap_fixed': os.path.join(SR,'bootstrap_summary_fixed.csv'),\n",
    "  'bootstrap_old': os.path.join(SR,'bootstrap_summary.csv'),\n",
    "  'cdf_png': os.path.join(SR,'response_time_cdf.png')\n",
    "}\n",
    "for k,p in files.items():\n",
    "    print(k, '->', 'EXISTS' if os.path.exists(p) else 'MISSING', '|', p)\n",
    "# show old bootstrap preview if present\n",
    "if os.path.exists(files['bootstrap_old']):\n",
    "    print(\"\\nPreview bootstrap_summary.csv:\")\n",
    "    print(pd.read_csv(files['bootstrap_old']).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62ad3293-8868-4372-993a-633c86a64b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.5-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.1-cp310-cp310-win_amd64.whl.metadata (111 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\sleemteech\\anaconda3\\envs\\empiricalstudy\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sleemteech\\anaconda3\\envs\\empiricalstudy\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sleemteech\\anaconda3\\envs\\empiricalstudy\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sleemteech\\anaconda3\\envs\\empiricalstudy\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.5-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.1 MB 1.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.0/8.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.6/8.1 MB 1.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.8/8.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.4/8.1 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.9/8.1 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.4/8.1 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.9/8.1 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.7/8.1 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.2/8.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.0/8.1 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.6/8.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.1 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.1-cp310-cp310-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp310-cp310-win_amd64.whl (73 kB)\n",
      "Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.3/7.0 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.6/7.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.9/7.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.2/7.0 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----------- ---------------------------- 2/7 [kiwisolver]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------------- 7/7 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.59.1 kiwisolver-1.4.9 matplotlib-3.10.5 pillow-11.3.0 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eed41571-2d87-4502-b296-6b4a1212a57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArIAAAHqCAYAAAD4TK2HAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZKJJREFUeJzt3Qd4VFX+xvF3JpUkBAIEQu+9CggiKqIoWFhRV7GsoGKXXZW1YUP0r1gRC4oNsS7YUNeGiGIBBGkKSO9SA4T0Opn/c05MNoEEMpBwMzPfz/OM987MnZlfjnfCm3PPPdfl9Xq9AgAAAPyM2+kCAAAAgCNBkAUAAIBfIsgCAADALxFkAQAA4JcIsgAAAPBLBFkAAAD4JYIsAAAA/BJBFgAAAH4pVEEmPz9f27dvV/Xq1eVyuZwuBwAAIOB5vV6lpqaqQYMGcrsrrh816IKsCbGNGzd2ugwAAICgs3XrVjVq1KjC3i/ogqzpiTU2b96smjVrOl2OX/RgJyYmKj4+vkL/ggpUtJdvaC/f0F6+ob18Q3v5hvbyzf79+9W0adOiHFZRgi7IFg4niI2NtTcc/oualZVl24ov6uHRXr6hvXxDe/mG9vIN7eUb2sv39jIqelgnLQ8AAAC/RJAFAACAXyLIAgAAwC8F3RjZ8vJ4PMrNzVWwM2NaTDuYcUCMASpdWFiYQkJCnC4DAICgQ5AtZZ6znTt32rPrUNAeJsyaud+Yd7dsZgaMhIQEp8sAACCoEGQPUBhi69atq6ioqKAPbybI5uXlKTQ0NOjboqz2ycjI0O7du+39evXqOV0SAABBgyB7wHCCwhBbu3Ztp8upEgiyh1etWjW7NGG2Tp06TpcDAEDQYNBjMYVjYk1PLOCLwn2GcdUAABw7BNlS0PMIX7HPAABw7BFkAQAA4JcIsgh4Dz74oLp163ZU77Fp0ybb67p06dIKqwsAABwdgmyAuPLKKzVkyBDHPt+EvE8++aTCtgMAAKjSQfbHH3/U4MGD1aBBg3IHnNmzZ6t79+6KiIhQq1atNGXKlGNSKwAAAKoWR4Nsenq6unbtqokTJ5Zr+40bN+qcc85R//797SHeW2+9Vddcc41mzJhR6bX6u+XLl+uss85STEyMnev0iiuu0J49e4qe//rrr3XSSSfZif3N1GPnnnuu1q9fX/R8Tk6ORo4cqfr16ysyMlJNmzbVuHHj7HPNmjWzy/PPP9/+QVJ431fmwgsPPfSQGjVqZP9QMcMBTF3F3XXXXWrTpo2dJaBFixa6//77D5op4LHHHrM/Y/Xq1TVixAh7VbIDvfbaa2rfvr39Wdq1a6cXX3yxxPMLFizQcccdZ5/v2bOnlixZckQ/EwAACNB5ZE2wMrfymjRpkpo3b66nn37a3jdB5Oeff9YzzzyjgQMHVto8qpm5HjmhWlhIhZwNb+bGPe2002zoN22VmZlpA+HFF1+s7777ruiPilGjRqlLly5KS0vTAw88YINpYYB77rnn9Nlnn+n9999XkyZNtHXrVnszfv31Vzv37htvvKFBgwYd8eVan332Wfv/9uWXX7YhcvLkyfrb3/6mFStWqHXr1nYbE05NL7zpxV+2bJmuvfZa+9idd95pnzf1mTGx5o8jE8zffvttW7sJvYXeffdd+/O98MIL9nPMz2jeJzo6WsOHD7c/vwnyZ5xxht555x37B9Qtt9xy1P8fAABAEF8QYd68eRowYECJx0yANT2zZcnOzra3QikpKUW9f+ZWnLlvgmvhzcjIyVPHMd/ICSvGnqmocN/+FxXWXdzzzz9vA9sjjzxS9Njrr79uA+nq1attD+cFF1xQ4jXmeRNO//jjD7Vt21ZbtmyxYbJv3742XJvXFn5e4UUAatSoUXRlq9LqKF5jac8/9dRTNpAOHTq0qGf1+++/t+G7sNf+3nvvLdre9Ar/+9//1rRp03THHXfYxyZMmKCrr77a3oyHH35Y3377re2VLfzMMWPG2M8yQd0wPcgmLJsAPWzYMBt0zb5gem1Nj2yHDh1saL/pppvKrL3w8cJ96MB9C6WjvXxDe/mG9vIN7eUb2qsczL+XXo+Un6f8rIL8FdRB1lw+9sBLgJr7JpyaXsbCKywVZw5/jx079qDHExMT7eHy4swharNDmitZmZtRuHSCraOcgz8Kg3lp9ZphGCYQmp7LA61Zs8b2Vq5du9a2k+ldNUMOCr+YGzZssGOR//GPf+jss8+2odb88WDWTY/lgVdGK097lbad+X+4fft2nXDCCSWe69Onj37//feix0yPqwm1pi7Tc2oej42NLXp+5cqVtue5+Hv07t3bjq02j5meZzNkwmxz3XXXFW1jnjNB3CxNeO/cubO9mlnh+xx//PFF25X2M5rHTJvt27fPfob55eZ2cy7l4Zg2S05Opr3KifbyDe3lG9rr6NrL6/FIOdnyZmfKlZ0hT06m8nMylJudoZzsTOVkZygvN1u5OVnKzcmUJy9Hebk58uTmKC8vRx5PnvLzcpTvyZMnL0/e/LyC9/R47GNm6fV65PLkS/keec2/0/n5cv21VL4Jjea+t+BxEyLzvf9b2udlly67lH3OdcBjbvv4X88Vu+82t+L3zbq39PtG4WsK1zPyKufotl8F2SMxevRoe8i8eGBq3Lix4uPj7XjQ4kyvXWpqqg0w5mZUDwmxPaNVfWiB+RKZW2HdxWVkZNiT6kwP54HMmFfzGtMja3o4X3nlFXvY3nxBTZgzSzNUoFevXjY8fvXVV7aH87LLLrO94x988EHRe5ntSvv8A5W2XeH9A58zP7+5mcdMj7w59G+GDpgwbYLn1KlTNX78+BKvOdR7FI6XNT+nCbil1VV8+wPrK75vHFi/af9atWopLCzM7l/8Q3B4Zv8ybU17lQ/t5RvaK/Dby5PvUbYnWxkZKUrZs0NpSbuVmbxXWclJyklLUV56ijwZ6crLzpI3J8scppU3N8feZM6vyMuTq+hWEBLNzZ2XL7dZerxFtxCPFFK0lNweKdQjZf+1DDlMx2z4X7dg5S77QG3wBNmEhATt2rWrxGPmvumRK6031jAnDZlbWcHvwMcKQ0xhgDTL6Aj/+EIbpQVfM8vDRx99ZMcXlxbC9u7da4cYvPrqqzr55JPtY2bs8YHvaYLjJZdcYm8XXXSRHQ+blJRUFN4KfwmWp8YDtzPvbQL03LlzdeqppxY9bu6bEG22N0HWhO377ruv6Hkz5KF4jWbctDlRywTeQvPnzy/axuxD5nPMuFfTy1waM5TAjI01Q1LM0IID36O0n7Hw8cJ9qLT9C6WjvXxDe/mG9nKuvUxPZXpOhvZk7FdS8l6lJCUqwwbNROWkJik3LVl56WnKz0yTsjLkzcqSKztbrpwcuXNy5c7NU0huvkJyPQrN9So0z6uwXK/C7FIKz5Ui/rqF/hUizb/2B/+L7wxzRDXf3FyS56+lvV983SV5iy29Lpd93Gvvu4qWBc+7/nqscCl5Q9zF7rtMkPlrO7ddV4hbcv217g6R15zD4jbbhchlXmuX5rEQu60rJNT06shtlva5UPu8y2SHkDC5QwsfC7OPhYSGy206gP5auu0yTCH2uTC5Q8IV6g5VSFiEsjOzpVMHBXeQNYeZv/zyyxKPzZw50z4O2UMcB07Yb2YguPnmm21IvfTSS+0YVBM8161bZ3szzTjQuLg4u53ppTQ9tCYc3n333SXex/R6mgBoxtqaX3CmJ9aEwsJebTPOdNasWXYMrfnDwbxnWUyIPLBOM/7WjHM141dbtmxpZywwJ4+Z7cyY1cJtTG2mbnOo/4svvtD06dNLvI85KcvMqWtmGjC1mNea8a/FT/YyQyj+9a9/2fBswrgJrAsXLrSh3PTem95mMxbXnABmevTNxRDMmFoACBZm6NbOP9dq77b1Stm9VVn7diorea/yUpPlTUuTMjPlzsqW24bOgsAZmpOvcBM4bdj8X9A0S9MlUNAtULlM4MsOk3LCpNzQgmVeqOQJcSnfLN0ueUJdyjf3TZALdcljliEm5Jn7ofKGhkihYfKGhdqlKyxcCouQKzxcrvBIuc0toprcEVHK87oVHVdH4dWq21tYdKzCo2MUWa26IiJjFBkeoaiwcEWEhisyNFThJiSaIBmE9u/fXynvG+r0F8UEqgMDjgla5mQiEyK2bdumt956yz5/ww032DPNTRgzJ/OYM+7NmEkTaFAwx64JmsWZ6adMWJ0zZ46dqeDMM8+0wc30bJoQV9iDaMKhCXedOnWy42DNmf7Fe0bN+NonnnjCjqU1h+BNkDR/VBT+1W5mGzAh0ATmhg0b2vBXluJDPQr99NNP9vNNGDcncO3evdv2jJqZEgpnLDAzGNx22212GjDzM5ip2Mz0W2aoQSFzopgZA2v2ETOM4MILL9SNN95YYoo2Mz7WTN/15JNP2vBsZiswwygKTxo0U5T997//tfubaU9Tx+OPP27fCwD8QU5OlhJ3rNPODcttGE3f/adykvbKk5oqV3q6XJnZCsnKUWiW6e30KDzHq/BsryJypB3ZUuRfsxrG/nWrKLkhXhswc8MkT5jLrptgadbzw9zyhLqVHxYib3iovGFh5rBqQYCMjFRIZLRComIUbsJiTE2FV49TtRp1bJCMqZ2gmNr1FFG9RkFv4jFgjkKaf6vMidH0+DvH5T3U6eXHIHiZOWEPZA4LmymWTM+aCURmu+KvMWHGnJBj5hs1QcZsV15mjKzpiTO9b6WNkTVh2hyCLzykHOzM7mFOZCocO4rSFe475g8Es4/xi618+IfAN7RX8LZXZlqadmxcqV3rftP+bWuVkbhducl75U1NlTs9U2EZOYrI9CgqPV/RmVJ0VsWMScwKk7IipOxwKTvCpVx7c8sTHqL8CBM0w+SKjFBItWoKj4pRWHR1RUbXUFRsLUXH1lZsrQTFxtVVtVrxCo2Nk6taDSk0MEaKBtL+dax6ZM3RWtNhZYaEBkSPrOnxO1SOLu2qXeY1TE4PAPBnnnyvkjJylLhju7b+8aNSN/2hvJ2b5dqbKHdKmsLTsxSZnmeDafV0KfyvyVJM90vJLphDywyXMiOlrEgpJ8KtnEi3PBEh8kSGK79ahFxRUQqNiVFoTA1FxNaSNyJG9Zq2Vp0GLVW3cRtFVI8zA2crqxmA4BojCwBAVWfmH/9zX4a2bdqs/avnK/PP5fLs2SrX/j2KSE1VtbQcRaV5FJtW0HPa2Ifxn6nVpPQoKauaSzmRIcqLClV+VKRcMTEKqRGniDr1VT2hmWo3bquEll1Vs06CQs2Yz/K8Pz2M8EMEWQAAfJDnydf2vWna8ccfSlr2szI3/a78fdsUmrJfYelZqpaer5g0KSFTSijn4fvk6lJqdZcyY0KVWz1C3urRcteqpWrx9RXbpJXqN+usJs27qXr1ggvQAChAkAUA4AA5efnavCtZ25b8qn1Lv1P+lj8UnrhLkSkZiknNs72psfmHPxEqI1xKipXSY9zKqR4mT81ohdappZgGTRTfqr3qt+ujNk26KuQYnaAEBBq+OQCAoGTO0diTlqNVq9dr68KvlLt2ocJ3blHMvhTV3J+nuP1SPa9U8nqS/5MTIu2uKe2PdSk7JlSeGlEKrVNbsQ0bq17Ljkpof6JaNO6kiNCqMrMpEHgIsgCAgA+sW/ekasXCOdq7dKY8m1cqMnG3qidlqlZSvupkSHUO0aO6o7a0P86tzNqRComPU2yjJqrXtpsadOirNvEdVC209AvyAKh8BFkAQMDYm5atpQsX6M/5nyp/wzJF7klUzaQsJSR61TRXalrG6/ZVl/bVcimjdoS8CbVUvWUr1e96vBp26K/ucS2YfhCoogiyAAC/k5/v1aZdSVrzw/vat3SWQrZsVvXEdMXvyVeDTKlBGUMB9sRJKXFu5cTHKKJRfSV06KrmPQeoXfM+BZfnBOBX+NbimDDz/5rLzk6YMKFSP8f0mpjL1g4ZMqTU580FNswFL8xcxKYeAFVfckauVm3eqW1zPlbm79+r2tYtitmfpdp7vWqac3Avq5mmKjFOSq4dopz4aFVv2lRNjz9Z7U68QBE1Gzr0UwCoDATZAGGubvbmm2/adXMVLnPVs4suukgPPfSQX1ylzFz84qqrrioKo/Xq1dMpp5xiLyNrLldcURo3bqwdO3aoTh2msAGqoqxcj1as36k/Z36krBWzFLV9i2rszVLN/VJ7T+m9rDvjXUquX03uZg3UoEcfdTjpQnVMaMu8qEAQIMgGkEGDBumNN95Qbm6uFi1aZC/1a0Lh448/Ln9gLlm3evVqe2KGudzrTTfdZMP4/PnzK+wzQkJClJBQnpkdAVQ2813fkZyl5ctWas8P7yp01S+qtS1JdXd71cZT+lWq/kxwK61RjKJbtlLLXmeo3Ul/V9dqMU6UD6AK4E/UABIREWFDmul1NIfWBwwYoJkzZxY9n52drX/961+2d8L00p500kn69ddfS/SK1qxZ8uKHn3zyicLD/3dd7AcffNAekn/77bfVrFkz1ahRQ5dccolSU1OLtklPT9ewYcMUExOj+vXr6+mnny5X/SZ0m/rNa0488USNGDFCCxYsUEpKStE2L730klq2bGlratu2ra3jQKbH9ayzzlK1atXUokULffjhhyWGFpjPWbp0qb0/e/Zse3/WrFnq2bOnoqKi7GebQA2g4i/L+sfWPfrik4/13t3D9OHlvfTHBd1V//rLddw7X6rzwn1quMOrMI+0L0b6rZVL80+O1Yobjlf2a6PVbsEC/e2bFbps8nydd++76nTGlYogxAJBjR7ZALV8+XLNnTtXTZv+b/TYnXfeqY8++sgOQTCPP/HEExo4cKDWrVunWrVqlfu9169fbwPu559/rqSkJF188cV67LHH9Mgjj9jn77jjDv3www/69NNPbWi+5557tHjxYp/GpJrDgWasq+lBNTfD3L/lllvsOFsT0s3nm+EIZhhF//79i157//3323qeffZZG3RN0F62bJnat29f5ufde++9NnDHx8frhhtu0NVXX605c+aUu14ApQfX1Vt2aPOcL5Qz/1NFbNuk6N25arrHrRBvyW33Vpd2NAxTToeGatD3VLU/+R/qG8t4VgCHRpA9HK9Xys1w5rPDokw3Zbk3N8HO9ILm5eXZ3lczJuyFF14o6iU1vZmm19X0Vhqvvvqq7bF9/fXXbfgsLzPuzLxP9erV7f0rrrjC9miaIJuWlmbf75133tHpp59unzfB2YTNw0lOTrb1m8ONGRkFbW56kKOjo+36U089ZccCmyEHxqhRo/TLL7/Yx4sHWTMc4ZprrrHrDz/8sP0Zn3/+eb344otlfrapvV+/fnb97rvv1jnnnKOsrCy/GF8MVBXmu7tp2w6tmfOVMhd+prDN6xW7I1dNEt3FDv8VrO2uIe1oHKHQDi3UZOCF6t7rfEWZ33kA4AOC7OGYEPtoaRO5HAP3bJfCC0JceZgwZ8KqCa3PPPOMPenrwgsvLOpFNWNn+/btW7R9WFiYevXqpZUrV/pUlhlSUBhiDTMUwPSgFn5OTk6OevfuXfS86e01wwAOx7yn6bk1dX711Vd69913i3p5DVPnddddV+I15ucxPa/F9enT56D7hUMJytKlS5cSP49hfqaKPNEMCETJ6Tn6bdFP+nPuOwpftVi1tmap/k63HR5QPLj+WVva3iJG1bp3VbPTLlCvjv25kACAo0aQDSCm57JVq1Z2ffLkyeratavtHTVjTcvD9OCaHpXiTKg8kAnAxZkxpqaX9miZzy+s3wwDMKH4xhtvLHUcbEUr/jMVTnxeET8TEIg279yjFT9+qP3zp6ralp2qvVU6br+rRHA1QwW2tohW6PFd1HTQUJ3U7hSCK4AKR5A9HHOoy/SMOvXZRxEKzdhUc/j9sssuKzpByoz7LBw3a0KqOdnr1ltvtffN+FBz0pbp0S08nH+4nswDmc8xodDMNFDYm2nG0a5Zs6bo0H15mUP85v1uu+02de/e3YZbU7+ZjaGQud+hQ4cSrzPDDczJZsXvH3fccT59NoD/yfXk67fly7Rh5mvKWzVHsX9mqNGfLjXPM88WBNg8t7S1SYRye3dSg3MvUvduZ+gkhgoAqGQE2cMxvXM+HN6vSsxYUTP2deLEibr99ttt76a5bw71m5BpTvYyY1ELe2zNcABz1r4JwGZsqgmjhXPTlpcZ42rez3xO7dq17cle5kSqI5nD0cy+cP755+uBBx6w43/Ne5oTy0woNSd7/fe//9XHH3+sb7/9tsTrPvjgAzsDgZmVwQxPMDMfmJ5pAOWXmpWreXN/0PbvX1P02uVK2JSnzkW9rgXLpOouJXaoqzpnnK0u5wxX57h6jtYMIPgQZAOYGSM7cuRIG1hNiDVn8pvD5ebkLNPzasLejBkzFBcXZ7c3AdecpGUCozkRzJysNWbMGF1//fU+fa65iIE56Wvw4MF23Ou///1veyLXkTC9sWaMqwmjZkoxMx7WnNxlZi8wV+gy8+aaq4YVN3bsWE2dOtWeFGbGu/7nP/85qNcWwMHSs3L065yZ2vHtK4pevUb1NkmNi851dRX0ujYOl6tnJ7UacqVO6HE6FxoA4CiX98BBkQHOzElq5j41h7sPnDPVnKVuJuI3AYmz1QuY3cPMgmBCceHYURyscN8xwzbMPsaVhMqHKy853165eR4t+vlbbfvmRYVsWK3aG12qU+zvzgxzEYI2MYo980x1u2ik4uIKTob0B+xfvqG9fEN7+Wb//v2248x0bJkLIFUUemQBIAitXrlMGz5+St7fFih+nVcdMswfqq6iK2ht6lRTtc87X73Pu0k9IrnoAICqiSALAEFi7769WjL9BaXN+Vg112Wr2e7/jXlNjZS2ta2hOgPPVY+Lblb36gVDjgCgKiPIAkAAy83J1u/fTdPWmS8rYuUeNdrkVsP8/415Xd2mmqKGnKsT/36LesXUdrpcAPAJQRYAAtDGFQu0cubzylo8X/VWhahtinm0YBzf1oQQZZx2vLpfdbv+3rij06UCwBEjyAJAgMhJS9LKr17W7p/eUe76XDXe6FZofoh9Li1S2tqjkVpd80+dccJgTt4EEBAIsgDg5/Zu/kPrPvo/pSyar+g1YWqU6irqfd0dHybXFReq1z9G6fio/11aGgACAUEWAPyQNz9fa379Rlunj5NnxXY1WB+q2Pzw//W+9mmpziNuU7+epztdKgBUGoIsAPiRvNwcLfzsJe2Z9bLCV2Sr4XZ30a/yDY3C5LrgbJ30j9t1fGwdp0sFgEpHkAUAP5CWmqwFHz+jjHn/UfRyl5rvKRg+YGYeWNOtjhpfd7PO7jeUsa8AggpBFkfN/MM5ffp0ewlZABVrz65tWvbxg9r3+/eKXxymlsnuoosWbDm1nXqMGqsLm3VxukwAcATXVAsQV155pQ2U5hYWFmYvs3vnnXfaS6cC8D+b1q3Uj+OH6se7+yls8s/q8H2Y4pOllCiXNl3cRy2+m6khz01XY0IsgCBGj2wAGTRokN544w3l5uZq0aJFGj58uA22jz/+uNOlASin7du2aOUHDyh91Y+KWxyh9ilh9vHUaLcyLzxDzYfepOObt+La7gBAj2xgiYiIUEJCgho3bmwP8w8YMEAzZ860z+3du1eXXnqpGjZsqKioKHXu3Fn/+c9/Srz+1FNP1b/+9S/bk1urVi37Xg8++GCJbdauXatTTjlFkZGR6tChQ9H7F7ds2TKddtppqlatmmrXrq3rrrtOaWlpJXqPTX2PPvqo6tWrp5o1a+qhhx5SXl6e7rjjDvvZjRo1sqEcCBa79+zRly/erDlPnip9OF+tZ0eoToq0v7pbSbdeqh5zFunku8crPDrW6VIBoMqgRzZALV++XHPnzlXTpk3tfTPEoEePHrrrrrsUGxurL774QldccYVatmypXr16Fb3uzTff1KhRozR//nzNmzfPhs4TTjjB9vbm5+frggsusOHTPJ+cnKxbb721xOemp6dr4MCB6tOnj3799Vft3r1b11xzjUaOHKkpU6YUbffdd9/ZsPrjjz9qzpw5GjFihK3XhGTz3tOmTdP111+vM844w24HBKqUtFT98OE4Jf7xgWotCVWnrRH28YxIl9IuGag+/3xI4dEF87+a7yAA4H8Isofh9XqVmZfpyGdXC63m0xnIn3/+uWJiYmzPZnZ2tj30+MILL9jnTE/s7bffXrTtP//5T82YMUPvv/9+iSDbpUsXjRkzxq63bt3avt6EThNkv/32W61atcq+rkGDBnYb06t61llnFb3+vffes6H5rbfeUnR0tH3MvMfgwYPtEAcTgg3T6/rcc8/ZGtu2basnnnhCGRkZuueee+zzo0eP1mOPPaaff/5Zl1xyyVG2JFD15Obl6edPXtDGpS8pZrFbfTYU/DrODZFSBvdVjzsfU7VaTKEFAIdCkD0ME2J7v9fbkc+ef9l8RYVFlXv7/v3766WXXrK9os8884xCQ0N14YUX2uc8Ho8NnSa4btu2TTk5OTbsmmEGxZkgW1z9+vWVmJho11euXGmHLRSGWMP0vBZntunatWtRiDX69u1re5JWr15dFGQ7duxYYoyfebxTp05F90NCQuywBNOjCwTaH8c/zfpU6+eMkXd5jnovd8vtlTxuKWPQCeoy6mFFchQCAMqFIBtATHhs1aqVXZ88ebINlK+//ro9bP/kk0/q2Wef1YQJE+z4WLOtGRZgAm1xZsaD4kyPcGUcziztc47VZwNOWbfqN8355BZlrNypExa7FJlb8Hhynw7q+sBTqta8udMlAoBfIciW4/C+6Rl16rOPlOntNIfpzXjXyy67zI5DPe+88/SPf/zDPm8C4po1a+wJW+XVvn17bd26VTt27LA9tcYvv/xy0DZmLKzpFS7slTWfXTiEAAhGf27frl8+uEM71i1Q93mhqpVWMGQouVU9tX3wMbXveYLTJQKAXyLIHobpFfTl8H5VctFFF9lZACZOnGjHu3744Yf2hKq4uDiNHz9eu3bt8inImlkQ2rRpY6f1Mj28KSkpuvfee0tsc/nll9sxtmYbM+OBGZZgxuOaE8sKhxUAwSI/L1fzP3xcK5ZNUb25YRqwo+BXbmp8lBrfda/anXM+V+ICgKNAkA1gZoysmS3AnEi1ZMkSbdiwwc4oYMbFmimxzBRYZuaB8jK9quYKXmaogjlBrFmzZvaELXMiWCHz3uZksFtuuUXHH3+8vW/G6ZrgDASTTb9+ocUz79KuFXk6ZXGYHQebFeFW9Igr1POGUXKHhztdIgD4PZfXnHkQREwvYo0aNZSUlGTnLy3OnG2/ceNGe1UsM08qCk5MMbMgmFBMz1HZCvcdM92Z2cfq1q3LhPXlYIa4mBP6Aqm9MvZu06/vXq/la1eryy+hqpNa8HjaSV3U9f+eVXhCwhG/dyC2V2WivXxDe/mG9vLN/v377RFh04FmpgGtKPTIAkBFMOPOv35O835+XrXnheu0v4YRpNeOVrOHH1X70850ukIACDgEWQA4Sunb/9CSN6/WhqVJ6vlbuL1kohlGEHXNMHW/7la5IwoucgAAqFgEWQA4Up5crfn4/7Ty57dU9+dIHZ9ecHhxf7+u6vnQcwqrV9fpCgEgoBFkAeAIZG9dqt8mX6Wd8zPUZkPBmPq9tSPU7JHH1P7U/50ACQCoPARZAPBFXrb+/OJRzZ3xtlrMiVDrbLfy3NLeQb100qOTFBp55PM/AwB8Q5AFgHLK3ThPK9+5Tht+yVXn9QXjXrc3jFbbZ55X5y4lL9cMAKh8BFkAOJzcLKV//aB+/PE9xX4frbZpLtsLm3TJQJ1279NyhYQ4XSEABCWCLAAcyp612vDGUM1fnKYuS6LtjASJtcPV/PkX1Ln7yU5XBwBBjSALAGXIWTJNs9+/S2Gzq6lbUkGv65aT2qv/05MVXqPkBVUAAMcel6IIIps2bbJX51q6dGmlfYa5bO2ECROK7pvP++STTyrt84BKkZejXR/eqo9eukf1PqumhCQpqXqIvE/cp4GvfUyIBYAqgiAbIK688kobGs0tLCzMXmb3zjvvtJdO9cWpp55a9D7mZi67Fx4ebi9TCwSF1F1a/typ+uHtr9Xtx3CFe6QtnRqq+4zZ6vC3y52uDgBQDEMLAsigQYP0xhtvKDc3V4sWLdLw4cNtGH388cd9ep9rr71WDz30kF33er02xIaGsqsg8OVt+Ek/Tb5K+d+FqfM+lzwuad+VQ3TmnY/a7xIAoGohnQSQiIgIJSQk2PXGjRtrwIABmjlzps9BNioqquh9CoNsYW9tt27dSgwdGDJkiGrWrKkpU6ZU6M8CHGtpc1/TN+8+ouY/Rioyt2AoQcMJE9Sp7wCnSwMAlIEgexgmyHkzMx35bFe1akfcC7R8+XLNnTtXTZs2rfC6gIDiydWW/4zUwunfq/2Kgit0bW5VW6e8/oGi6tV3ujoAwCEQZA/DhNjV3Xs48tltFy+SKyqq3Nt//vnniomJsT2o2dnZdnzrCy+84PPnvvjii3rttddKDDUYP368z+8DVHnZqVo4cYgSP9+m9ttDlG9mJRh8ogY99gpzwwKAHyDIBpD+/fvrpZdeUnp6up555hk7rvXCCy/0+X0uv/xy3XvvvUU90iYcA4HGk7JT30wYpMivstUsyaWMCCnvobt11nnDnS4NAFBOBNlyHN43PaNOfbYvoqOj1apVK7s+efJkde3aVa+//rpGjBjh0/vUqFGj6H2Kj5E1PbzmfnHmxDLA36Rv/V3TXrxY7b5xKS5dSooNUdNXXlPDbic4XRoAwAcE2cOw01D5cHi/qjCh85577tGoUaN02WWXqZqPobg08fHx2rFjR9F9j8djx+KanmDAX2z99SN9/N5onfpNiJ1aKzEhRj3f+1hRDRo7XRoAwEfMIxvALrroIoWEhGjixIkV8n6nnXaavvjiC3tbtWqVbrzxRu3fv79C3hs4Fn7//DF9+so9GvB1QYjd3bWFTvpiNiEWAPwUQTaAmTGyI0eO1BNPPGHHzR6tq6++2s5NO2zYMPXr108tWrSgNxb+wevVT+/crMVvTtHpP7nl9kqpA0/SKe99Jnd0tNPVAQCOkMt74KDHAJeSkmLHgCYlJdn5T4szV8HauHGjvSpWZGTBNDzBrvgFEZgQvmyF+46Z7szsY3Xr1rXDO3Bo+fn52r17d+W2V16OZky6WMlfrlbnDVK+2Y1HXq2ON98hf3NM2iuA0F6+ob18Q3v5xhzBjYuLU3JysmJjY1VRGCMLIGB5s5L10bNnqfrnSeqcKOWGSDWe+D81Pcf32TwAAFUPQRZAQPKm79W7Tw9Qk8+zFJ8ipUWHqMXLr6l2T2YmAIBAQZAFEHDyU3Zo8pNnqvPneYrNlPbVjlSPqZ8psjEndQFAICHIAggo+UlbNPmxs9T9q3xVy5F2N4jViR98qbDatZ0uDQBQwQiyAAJG/t4NevPhc9RrphTmkba3rKtTp32pkBhmJgCAQOT4aXZmjtNmzZrZWQJ69+6tBQsWHHL7CRMmqG3btnaC/8aNG+u2226zZ4xXpCCbyAEVgH3GeXl71+md+85Rr68LQuymTk3Uf/pMQiwABDBHg+y0adPslafGjBmjxYsX20uqDhw40E5nUZr33ntPd999t91+5cqV9vKr5j3MFawqQlhYmF1mZGRUyPsheBTuM4X7EI6t3L3r9J/bB+v47wt+qa3u3U6Dpn0pd3i406UBAAJ1aMH48eN17bXX6qqrrrL3J02aZK8aNXnyZBtYDzR37lz17dvXXnLVMD25l156qebPn18h9ZirYJm5ZQuDdFRUVNDPnco8sodvHxNizT5j9h2zD+HYyk1co0//eZ56Li24v3xAD/39+bfZXwEgCDgWZHNycrRo0SKNHj266DEzofCAAQM0b968Ul9z4okn6p133rHDD3r16qUNGzboyy+/1BVXXFFhdSUkJNhlWb3CwRjUzKTP5v8NwaBsJsSafYchBsdWXuI6fXHTeeq4rOD+kvNO1mWPv+J0WQCAQA+ye/bskcfjUb169Uo8bu6vWrWq1NeYnljzupNOOqmop/CGG2445NCC7OxseytkrrpkmHBmbqUxNdSpU0e5ubkKdqaN9u3bp1q1anHlkjKY4QSmJ7Yw9BcucXhH016e/X9q5jWD1XZ1wf35F/fXsAdfCOi2Z//yDe3lG9rLN7SXbyqrnfxq1oLZs2fr0Ucf1YsvvmhPDFu3bp1uueUWPfzww7r//vtLfc24ceM0duzYgx5PTEy0vcI4/I6Xnp5uhxYQZMvXXubye+aXG+1Vie2VulNzx16q9qulPLf008Wn6IIbHgj4IynsX76hvXxDe/mG9vKNaauACrKmx9P0Yu3atavE4+Z+4eH9A5mwaoYRXHPNNfZ+586dbci67rrrdO+995a6I5mhC+aEsuI9sma2g/j4eHs4GIf/opohBaa9+KIeHu1V+e3lzdyvDx78h7ouLLj/6wV9dMMDLykYsH/5hvbyDe3lG9rLN+GVdPJtqJM/UI8ePTRr1iwNGTKkaKcw90eOHFnqa8xJNQfuLIUn15Q1NjEiIsLeDmTehx2vfMwXlfYqP9qr8trLm5Ou9+88XV1ne+z9307vpKv/b7KCCfuXb2gv39BevqG9yq+y2sjRoQWmp3T48OHq2bOnPXnLzBFrelgLZzEYNmyYGjZsaIcHGIMHD7YzHRx33HFFQwtML615nLPFgcDmzcvRB6NPU6fvCuaNXnlCcw194X2nywIAOMjRIDt06FA7VvWBBx7Qzp071a1bN3399ddFJ4Bt2bKlRIK/77777F8/Zrlt2zbbnW9C7COPPOLgTwGg0uXn6+P7B6j9VykK8UqrjkvQ+W98wUwaABDkXN4gmy/IjJGtUaOGkpKSGCNbDma4hzmBpm7duhw6KQfaqxLay+vV508OUf131ygqW1rdsZb+NnW23EF48Qn2L9/QXr6hvXxDe/lm//79iouLsyd9xcbGqqLQ8gCqtO8nXa/a0wpC7ObGkRr83qygDLEAgIMRZAFUWb++e79Cp/ykmunSjvhQnTx1hkIiIp0uCwBQRRBkAVRJq2a+qNRJH6hOspRY06XO73yk6Np1nS4LAFCFEGQBVDk7lnypTY89p/qJLqVESQ1fn6L4pm2cLgsAUMUQZAFUKWm71mvRvaPUdJtLGRFS+NOPq2XHXk6XBQCoggiyAKoMT3amZo08Ty03uJQTIiXd8y8d1/9vTpcFAKiiCLIAqob8fH11Y3+1WeZRvqS1V5+lAUNvdLoqAEAVRpAF4DyvV9+POU/N5yXbuwvOba2//3u801UBAKo4giwAx/3+2p2K+2Sd3F5pcZcYDX/yE6dLAgD4AYIsAEft+W2m0qZ8oYhcaWWzUA2e/I3cLn41AQAOj38tADgmY8cG7X7iEdVOcmlfjNTuhTcVGxPndFkAAD9BkAXgCG9utn656XzV3+ZSZriUPmaUOrTq7nRZAAA/QpAF4IjZ/zpbDVfnyeOSFl5zus4cfK3TJQEA/AxBFsAx9/vLo1V39na7/u3p9TTi5medLgkA4IcIsgCOqX1/zFP669PtDAULOoTpb3e9IZfL5XRZAAA/RJAFcMzkZ6Zoye0jVDPFpd01pOOemKKosGpOlwUA8FMEWQDHhterOTedrQYbvMoNkbbfdIk6tejmdFUAAD9GkAVwTCx59t+qNW+vXf/m3Ca6dPgYp0sCAPg5giyASrdz0Wzlv/ml/YUzp0uYrn/oQ6dLAgAEAIIsgEqVl5mutbffpKhMlzbXlU54+i1Vj6judFkAgABAkAVQqeZee67q7PAqI1zac9swdWrMuFgAQMUgyAKoNEsnPqr4hTvt+szzGunyIXc7XRIAIIAQZAFUiv3r/pDntbft+szjQ3Xz/R8zXywAoEIRZAFUOG9+vpaPvFxRmdLmeKnHvc+oejjjYgEAFYsgC6DCLbh1mGpvyrLzxf4x/BT1bTfA6ZIAAAGIIAugQu34YaZiZi6069PPjNI/r3rB6ZIAAAGKIAugwuRnZ2vLvbfJ7XXpl3YuXXzP2woLCXO6LABAgCLIAqgwv944VLF7PEqNlNKGn6/28R2cLgkAEMAIsgAqxKbPP1Xs3NV2/aNzYnXjeWOdLgkAEOAIsgCOWu6ePUoac49d/6GzS9f/+z2FukOdLgsAEOAIsgCO2rLr/6HI9Hz9WVvKvOp8tajV0umSAABBgC4TAEdl23tvqNqKzcpzS+//rYZeHPSg0yUBAIIEPbIAjljevn3a8+RTdv3TE1y67erJCnMzSwEA4NggyAI4YstvvVbhmfnaUkdyXfg3dWCWAgDAMcTQAgBHZP/PsxW+YIUklz4aFK2Jgx52uiQAQJChRxaAz/JzcrTx9lvkkkvfd3Zp+BXPceEDAMAxR5AF4LNVjz6gyP05SoqWNgzppb5NT3S6JABAECLIAvBJxqZN8nz4qV2f3i9UD170gtMlAQCCFEEWQLl5vV4tv2mYQvOkPxpLfa64RzHhMU6XBQAIUgRZAOW28a03VX1DonJDpJ/ObagLjrvU6ZIAAEGMIAugXPL271fys0/a9c9OcOv2Kyc7XRIAIMgRZAGUy9J/36zIjHxtqyXFXHSeGtVo4nRJAIAgR5AFcFhJi5coas5iuz79zEjdfMZYp0sCAIAgC+DwJ3ituesmuSTNae/SJVc8wZyxAIAqgSAL4JDWvfu2YrfuV06otGZgC53c8gynSwIAwCLIAihTflaW9j/3hF3/+niX7vjH606XBABAEYIsgDItHHOHYlI82hcj1bjoQsXH1HO6JAAAihBkAZQqa9s2RX7xrV2f0S9C1wwa43RJAACUQJAFUKolt12tsDxpVSPpjOvGKdQd6nRJAACUQJAFcJDE779Vzd+3KF/S3DMSdHLbs5wuCQCAgxBkARw03dbGB++067O7unTDNS87XRIAAKUiyAIoYcuUF1V9V6aywqTdZ/VWy9ptnC4JAIBSEWQBFMnPztael16061/3CtG/L33W6ZIAACgTQRZAkbWP3aWolHwlRUuRF16m2IhYp0sCAKBMBFkAlidpnzKnz7DrX/aN0MiBdzhdEgAAh0SQBWAtv+9GRWRJf9aW2l9xp8JCwpwuCQCAQyLIAlDOlg1yz/7drs/sV0OX9bzU6ZIAADgsgiwA/XbntQr1SH80ls6++im5XC6nSwIA4LAIskCQS1u6UDFLt9v1+ac31qmtTnK6JAAAyoUgCwS53x+81S5/aefS1SNecrocAADKjSALBLF9C35W3Kq99lK0G/u1U7v4lk6XBABAuRFkgSC2/P/+bZcL2rs08tpXnC4HAACfEGSBIJX44wzFr0lRvkvaNaCX6sbUcbokAAB8QpAFgtTqR0bb5S/tXbrp6uedLgcAAJ8RZIEgtP2/U1V7c6by3NK+c05XbLXqTpcEAIDPCLJAENow4TG7/LmrWyOHPeV0OQAAHBGCLBBktv33bdXelm17Y7PPPVfVwiKcLgkAAP8MshMnTlSzZs0UGRmp3r17a8GCBYfcfv/+/br55ptVv359RUREqE2bNvryyy+PWb2AP/Pm52vrE0/Y9Xmd3Lrx4oedLgkAgCMWKgdNmzZNo0aN0qRJk2yInTBhggYOHKjVq1erbt26B22fk5OjM844wz734YcfqmHDhtq8ebNq1qzpSP2Av9n61kTVSMxTRoSUftHFiggLd7okAAD8M8iOHz9e1157ra666ip73wTaL774QpMnT9bdd9990Pbm8X379mnu3LkKCwuzj5neXACH5/V4tOPVVxQr6bseofrX+QWzFgAA4K8cG1pgelcXLVqkAQMG/K8Yt9venzdvXqmv+eyzz9SnTx87tKBevXrq1KmTHn30UXk8nmNYOeCftr/zsmL35iktUnKfc5EiQumNBQD4N8d6ZPfs2WMDqAmkxZn7q1atKvU1GzZs0HfffafLL7/cjotdt26dbrrpJuXm5mrMmDGlviY7O9veCqWkpNhlfn6+veHQTBt5vV7ays/by4yN3fbySzKTbM3qEaJ/nXtnlaixqrZXVUV7+Yb28g3t5RvayzeV1U6ODi04kkYw42NfeeUVhYSEqEePHtq2bZuefPLJMoPsuHHjNHbs2IMeT0xMtL3COHybJycn2y+r6TGHf7bX/unvqPq+gt7YvFPPUUrSfhX8SeesqtpeVRXt5Rvayze0l29oL9+YtgqoIFunTh0bRnft2lXicXM/ISGh1NeYmQrM2FjzukLt27fXzp07bSgNDz/4UOno0aPtCWXFe2QbN26s+Ph4ThIr5xfV5XLZ9uKL6p/t5c3L07YpbypK0vc9QjRq6FhFVpFhBVWxvaoy2ss3tJdvaC/f0F6+KS2j+XWQNT+Q6VGdNWuWhgwZUrRTmPsjR44s9TV9+/bVe++9Z7cr3GnWrFljA25ZDWSm6DK3A5nXs+OVj/mi0l7+2147P3hHUcl5So6SMs84U1HhkapKqlp7VXW0l29oL9/QXr6hvcqvstrI0ZY3PaWvvvqq3nzzTa1cuVI33nij0tPTi2YxGDZsmO1RLWSeN7MW3HLLLTbAmhkOzMle5uQvAAczh7y2TnrOrs/q7tatQw4eZgMAgL9ydIzs0KFD7VjVBx54wA4P6Natm77++uuiE8C2bNlSIsGbIQEzZszQbbfdpi5duth5ZE2oveuuuxz8KYCqK2nGfxWTmK2sMCnnlJNUI9Kc7gUAQGBw/GQvM4ygrKEEs2fPPugxM/3WL7/8cgwqA/zfugmP2JkKZnd16Za/P+Z0OQAAVCgGdQABKn3RAlXflKI8t7TzxI6qFRXndEkAAFQogiwQoJY9WnB1vHntXbrhkmecLgcAgApHkAUCUPaGDar+xw67vqFPEzWv1cjpkgAAqHAEWSAALfu/2+X2SotaSpcMfcLpcgAAqBQEWSDA5O3Zo8j5K+36sl611K1xF6dLAgCgUhBkgQCz5rH7FOKR1taXThpyp9PlAABQaQiyQADxpKQob8YPdn32CZE6t8vfnC4JAIBKQ5AFAsimic8oLFfaEi+1HnilvXwiAACBiiALBAhvXp5SPv7Qrs/qGaJrTr7J6ZIAAKhUBFkgQCROf1+RqXlKqSbF9D1dYSFhTpcEAEClIsgCAWLLq8/a5azjXLrxrPucLgcAgEpHkAUCQMbvSxS9JUUel7SrVzvFR8c7XRIAAJWOIAsEgDVPFPTAzm/n0vDzHnS6HAAAjgmCLODn8nbvUujiDXZ9SY84da/PBRAAAMGBIAv4uY1P3a+QfGlNA6nPuaOcLgcAgGOGIAv4+ZRb6bN+tus/9IjQ0C7nOV0SAADHDEEW8GOJb7+oiHSv9kdJtfpfpFB3qNMlAQBwzBBkAT/l9Xq1bfLrdv3b7m7987SRTpcEAMAxRZAF/FTanO8VmZij7FBp10k9VSOyhtMlAQBwTBFkAT+1/tlH7PKnTi7dePY9TpcDAMAxR5AF/FDuju0KW7HNrv9xXF11rNvW6ZIAAKjaQXbYsGFKTU0tuv/bb78pNze3MuoCcAibJoyVO9+llY2kfoOYcgsAEJx8CrLvvvuuMjMzi+6ffPLJ2rp1a2XUBaAM+Tk5Sp/5k13/+bgIXdzlXKdLAgCg6gdZc5b0oe4DqHx7p76piAyv9sVINfudJ7eLEUIAgODEv4CAHzF/PP75+st2fUYPt0aefqvTJQEA4BifZ0//448/tHPnzqJ/VFetWqW0tLQS23TpwrXegcqQ9dtvityVrpxQKbFHa9WqFud0SQAA+E+QPf3000sMKTj33ILxeS6Xyz5ulh6Pp2KrBGBtevEJu/ylrUtDT7/D6XIAAPCfILtx48bKqwTAIeWnpytv3lL7pV3WuZqua3Gi0yUBAOA/QbZp06aVVwmAQ9r7yVSF5nq1s6bU9ISL7NEPAACCmc9DC4y1a9fq008/1aZNm+w/ps2bN9eQIUPUokWLiq8QgLXpndcUI2lOJ7du6T/S6XIAAPC/IDtu3Dg98MADys/PV926de242MTERN1999169NFHdfvtt1dOpUAQy9m8STEb9ytf0r6urVQ9wkRaAACCm0/Tb33//fe67777dO+992rPnj3asWOHncGgMMia248//lh51QJBauPEh+1yeTOXBg+6x+lyAADwvx7ZSZMm6ZprrtGDDz5Y4vFatWrpoYcesqH2pZde0imnnFLRdQJBy5uXp4xZ8xQpaWmnSI1r3dvpkgAA8L8e2QULFuiKK64o83nz3C+//FIRdQH4y/4vpysy3avkKKn6KX93uhwAAPwzyO7atUvNmjUr83lz0lfhxRIAVIx1rzxrlz93cumGMzjJCwCAIwqyWVlZCg8PL/P5sLAw5eTk+PKWAA4hd9cuRa/ba9e3H9dMtarFOl0SAAD+O2vBa6+9ppiY0s+YTk1NrYiaAPxly2vjZWaLXdVIOmPgXU6XAwCA/wbZJk2a6NVXXz3sNgCOnpnaLunzrxQtaVHHMD3cnpMoAQA44iBrLoAA4NjIXDhf0Um5ygqTXL36cSUvAACOZozsd999pw4dOiglJeWg55KTk9WxY0f99NNPvrwlgDKsfvExu1zQxqWrzrrb6XIAAPDvIDthwgRde+21io09+ISTGjVq6Prrr9f48eMrsj4gKHlSUxWycLVdX9e5plrUauh0SQAA+HeQ/e233zRo0KAynz/zzDO1aNGiiqgLCGp73n9LYbnSn7WllqeUPXczAADBzOd5ZM0UW2UJDQ21l6sFcHS2THvLLud0cuvKk692uhwAAPw/yDZs2FDLly8v8/nff/9d9evXr4i6gKCVtXqNYrakKN8lpXdurciwCKdLAgDA/4Ps2Wefrfvvv99eGOFAmZmZGjNmjM4999yKrA8IOltfecYuf23j0tkD/u10OQAABMb0W/fdd58+/vhjtWnTRiNHjlTbtm3t46tWrdLEiRPl8Xh07733VlatQMDz5uYq4/ufZK6ft7RjmIa3PcnpkgAACIwgW69ePc2dO1c33nijRo8ebSdsN8z8lgMHDrRh1mwD4Mikzf5e4RkeJUVLMZ1PZu5YAAAq8hK1TZs21ZdffqmkpCStW7fOhtnWrVsrLi7O17cCcICNU16UOZ1yTkeXhp92u9PlAAAQWEG2kAmuxx9/fMVWAwQxT1qaXL8VzB27tU11ta7XzOmSAAAInJO9AFSe/V/8V6F50rZaUqtug50uBwCAKo8gC1QR6997xS4XtHfpygG3OV0OAABVHkEWqALy9u1T9Jqddn1/+3qKjYx2uiQAAKo8gixQBSR+PFVur7Q+QTruhKucLgcAAL9AkAWqgC0fvGOXS9q59fcTLnO6HAAA/AJBFnBY7o4dit2cpHxJGe2bKiz0iCcTAQAgqBBkAYdtn/aWXa5qLJ3S9wanywEAwG8QZAGH7fr0A7tc3tatgd3PdbocAAD8BkEWcFD2xo2qviNdeW4pp2Mnud18JQEAKC/+1QQc9Oc7L9nl781cGtCPuWMBAPAFQRZwiNfr1b6vv7Hra9qE6tT2vZ0uCQAAv0KQBRySs369YvZm22EFro495HK5nC4JAAC/QpAFHLLprRfs8rfm0iCGFQAA4DOCLOCQ/d9/b5frW4erd+vOTpcDAIDfIcgCDsjZuFGxiTl2WIG7Yx+GFQAAcAQIsoAD1r3znF2uaCqdNWCU0+UAAOCXCLKAA5K+KxhWsKV5hHo0a+10OQAA+CWCLHCM5fz5p2rtyFa+JE9XhhUAAODXQXbixIlq1qyZIiMj1bt3by1YsKBcr5s6daoNAUOGDKn0GoGKsvbdCXa5urF01qA7nC4HAAC/5XiQnTZtmkaNGqUxY8Zo8eLF6tq1qwYOHKjdu3cf8nWbNm3S7bffrpNPPvmY1QpUhH3ffmeXm1qEq1vTFk6XAwCA33I8yI4fP17XXnutrrrqKnXo0EGTJk1SVFSUJk+eXOZrPB6PLr/8co0dO1YtWhAE4D/ydu9Wra2Zdj23S0+nywEAwK+FOvnhOTk5WrRokUaPHl30mNvt1oABAzRv3rwyX/fQQw+pbt26GjFihH766adDfkZ2dra9FUpJSbHL/Px8e8OhmTYyl1KlrSqmvda/95L963Ftfan/mbcFfbuyf/mG9vIN7eUb2ss3tJdvKqudHA2ye/bssb2r9erVK/G4ub9q1apSX/Pzzz/r9ddf19KlS8v1GePGjbM9twdKTEy0QRqH3/GSk5Ptl9X8kYGja6+dX/9Xdc30Wy1D1at6ncMOoQl07F++ob18Q3v5hvbyDe3lG9NWARdkfZWamqorrrhCr776qurUqVOu15jeXjMGt3iPbOPGjRUfH6+aNWtWYrWB80U1J9SZ9uKLenTt5dm/X7W3pNv17E4d7VGFYMf+5Rvayze0l29oL9/QXr4JDw9XwAVZE0ZDQkK0a9euEo+b+wkJCQdtv379enuS1+DBgw/qqg4NDdXq1avVsmXLEq+JiIiwtwOZnY4dr3zMF5X2Ovr22vzRWwrJlzbVlU4ZdCvt+Rf2L9/QXr6hvXxDe/mG9iq/ymojt9PpvEePHpo1a1aJYGru9+nT56Dt27Vrp2XLltlhBYW3v/3tb+rfv79dNz2tQFW19bP37XJVqxD1bXeC0+UAAOD3HB9aYA77Dx8+XD179lSvXr00YcIEpaen21kMjGHDhqlhw4Z2rKuZZ7ZTp04lXl84PODAx4GqJD89XXEbkux6RoeSRw0AAICfBtmhQ4faE68eeOAB7dy5U926ddPXX39ddALYli1b6LKH39v25YcK9Ui7akq9z7jB6XIAAAgIjgdZY+TIkfZWmtmzZx/ytVOmTKmkqoCKs/6jKTJ/mq1o6dZNXQY5XQ4AAAGBrk6gknk9HlVfvdOup7VpaE8OAAAAR48gC1SynbO/U1SmlBYpdTprhNPlAAAQMAiyQCX7Y+oLdrm8uUsDe17odDkAAAQMgixQyaotX2+XSa3jFOquEsPSAQAICARZoBLtXLZCcUke5bmlFqed53Q5AAAEFIIsUIl+n/KUXa5qIg3qf5PT5QAAEFAIskAlCluy2C53toxWZESM0+UAABBQCLJAJcnanai6O3LselzfU50uBwCAgEOQBSrJwslPy+2VNtaTzh18u9PlAAAQcAiyQCXJmDPLLre0CFfN6glOlwMAQMAhyAKVID8rS/U2phXcOa6b0+UAABCQCLJAJVj18RsKz5P2xEqnXXiX0+UAABCQCLJAJfjzi2l2ubaFW20adnC6HAAAAhJBFqhg3vx81V6daNcz2zVzuhwAAAIWQRaoYPsXz1VMhpQRLnU66wanywEAIGARZIEKtvGzN+xyTTOXTjn+HKfLAQAgYBFkgQoWs2KTXSa1rC2Xm68YAACVhX9lgQqUtnGN4vfmy+OS4k++wOlyAAAIaARZoAItevNJu1zXWBo0iPGxAABUJoIsUIE8vyyyy93NolQ9qprT5QAAENAIskAFydm3Twlbs+16WLe+TpcDAEDAI8gCFWT5By8qxCttjZdOHHSL0+UAABDwCLJABdn9zZd2ub2ZW62aciEEAAAqG0EWqADevDzVXZdk17OaN5fL5XK6JAAAAh5BFqgAf86ZoWrZUmqk1Oj4i50uBwCAoECQBSrAik8Krua1uYnUqdtpTpcDAEBQIMgCFSBk2Rq7TGtYXZFhoU6XAwBAUCDIAkcpOzlJ9bfl2vXorqc4XQ4AAEGDIAscpcUfv2Sn3dpdU+p1zj+dLgcAgKBBkAWO0q5ZX9nljiYhatKwsdPlAAAQNAiywFHwer2qu3qvXc9p1dzpcgAACCoEWeAobPt1tuJSvcoOlZoNvMbpcgAACCoEWeAo/D71Rbvc2EQ64cRznS4HAICgQpAFjkL4b6vtMqlpDYWHhThdDgAAQYUgCxyhnP1JStheMO1WZM9+TpcDAEDQIcgCR+i3j1+1027tqCX1P+dfTpcDAEDQIcgCR2jnrC/scluTENVPaOh0OQAABB2CLHCE027VXpto13NbEGIBAHACQRY4AsnrVykuxas8t9T0lKFOlwMAQFAiyAJHYOF/nrfLTQ2kk/pf5nQ5AAAEJYIscASyF/5ql3sbRygiItLpcgAACEoEWcBHXo9H9Tan2fWQdh2cLgcAgKBFkAV8tHHeTEVnSRkRUvezb3S6HAAAghZBFvDRHx+/ZpebG0kdOvZ1uhwAAIIWQRbwUcjytXaZ2riGXG6+QgAAOIV/hQEf5KSnquG2HLte47iTnC4HAICgRpAFfPDbF28qzCPtqy71Ovdmp8sBACCoEWQBH2z75hO73N7IpQYNmztdDgAAQY0gC/ig+toddpnZLMHpUgAACHoEWaCc0nZvU8KufLteu8+5TpcDAEDQI8gC5bT4w0n2C7O9jtT3zBFOlwMAQNAjyALllPTz93a5q1GIatas4XQ5AAAEPYIsUE611++zy5yWTZ0uBQAAEGSB8tm3boVqJ3uV55aa9xvqdDkAAIAgC5TPkvcn2eXmBlLvUy5yuhwAAECQBcon95f5drmnUbgiI6s5XQ4AACDIAofn9XhUd3OqXc9r28rpcgAAwF8IssBh7PttkaplSxkRUtt+lzpdDgAA+AtBFjiM3z553S43NpRO7HWe0+UAAIC/EGSBw8hdusQuk+qHKyQ0zOlyAADAXwiywCF48/NVe0vB+FhX69ZOlwMAAIohyAKHsOf3JYrOkrLCpI6n/cPpcgAAQDEEWeAQfpv+ml1uNPPH9jjX6XIAAEAxBFngELKXFY6PjZA7JNTpcgAAQDEEWaAMXq9Xtbem2HV3i2ZOlwMAAA5AkAXKkLp6pWqkepUTIrU8lcvSAgBQ1VSJIDtx4kQ1a9ZMkZGR6t27txYsWFDmtq+++qpOPvlkxcXF2duAAQMOuT1wpBZ//L/xsX37EGQBAKhqHA+y06ZN06hRozRmzBgtXrxYXbt21cCBA7V79+5St589e7YuvfRSff/995o3b54aN26sM888U9u2bTvmtSOwpS+Zb5f76ocqJCzc6XIAAEBVC7Ljx4/Xtddeq6uuukodOnTQpEmTFBUVpcmTJ5e6/bvvvqubbrpJ3bp1U7t27fTaa68pPz9fs2bNOua1I7DFbUmyy/zmjZ0uBQAAVLUgm5OTo0WLFtnhAUUFud32vultLY+MjAzl5uaqVq1alVgpgk3ali2KS/Yq3yU168u0WwAAVEWOzie0Z88eeTwe1atXr8Tj5v6qVavK9R533XWXGjRoUCIMF5ednW1vhVJSCs5CN7245oZDM21kzt4Ptrb69YNXlCBpcz3ptL6Xl/vnD9b2OlK0l29oL9/QXr6hvXxDe/mmstrJryfGfOyxxzR16lQ7btacKFaacePGaezYsQc9npiYaHuEcfgdLzk52X5ZTW95sEid/4MNsrsbhmh/aqZkbuUQrO11pGgv39BevqG9fEN7+Yb28o1pq4ALsnXq1FFISIh27dpV4nFzPyHBxIiyPfXUUzbIfvvtt+rSpUuZ240ePdqeTFa8R9acIBYfH6+aNWtWwE8R+F9Ul8tl2yuYvqhxf+6zS0+z+qpbt265Xxes7XWkaC/f0F6+ob18Q3v5hvbyTXh4eOAFWfND9ejRw56oNWTIEPtY4YlbI0eOLPN1TzzxhB555BHNmDFDPXv2PORnRERE2NuBzE7Hjlc+5osaTO2VlZioOvsKDoE0OWGgzz93sLXX0aK9fEN7+Yb28g3t5Rvaq/wqq40cH1pgekuHDx9uA2mvXr00YcIEpaen21kMjGHDhqlhw4Z2iIDx+OOP64EHHtB7771n557duXOnfTwmJsbegKO18KPXVVvSttrSyf0L9kMAAFD1OB5khw4dasermnBqQqmZVuvrr78uOgFsy5YtJVL8Sy+9ZMe2/v3vfy/xPmYe2gcffPCY14/Ak/TzNzbIbm8cosgYswYAAKoix4OsYYYRlDWUwJzIVdymTZuOUVUIVtU3F1yMI6dJvNOlAACAQ2BQB1CMJy1N8Xs8dj2+e3+nywEAAIdAkAWK+e2r9+T2SnurSyefeZ3T5QAAgEMgyALFbJ31iV1ub+hSrVqHngIOAAA4iyALFFNt3Z92mdqYSx4DAFDVEWSBv3iys5WwI9eux3Q90elyAADAYRBkgb+s+f5jhXmk5Cip18DrnS4HAAAcBkEW+MvamR/a5fb6UvPGLZ0uBwAAHAZBFviLe/UGu0xtEOt0KQAAoBwIsoAkr9erutuy7HpE2y5OlwMAAMqBIAtI2rxktqpnSjmhUocBI5wuBwAAlANBFpC07LM37XJbgtSxcy+nywEAAOVAkAUk5f6xwi6T61dTSAhfCwAA/AH/YgOS4ral26WrWSunSwEAAOVEkEXQ27tjvRL2eu16o5MucrocAABQTgRZBL0ln71ml4lxUvd+f3O6HAAAUE4EWQS9pIXz7DKxXqiiIiOcLgcAAJQTQRZBL3rTHrvMapzgdCkAAMAHBFkEtbycbDXY6bHrscf1c7ocAADgA4IsgtryHz9SRK6UES51P+tqp8sBAAA+IMgiqK2b9Yld7kxwqWH9Bk6XAwAAfECQRVBzrV1vl6kJ0U6XAgAAfESQRVCL/zPDLkPbtHO6FAAA4COCLILWrk2rFL9fyndJbQdc4nQ5AADARwRZBK0l01+3yx11pI49BzpdDgAA8BFBFkErffECu9zbIFTu0FCnywEAAD4iyCJoVf9zr13mNarndCkAAOAIEGQRlPKyMlV/V8GFEOK7n+J0OQAA4AgQZBGUln47XaH5UnKU1OvMK50uBwAAHAGCLILS5tmFF0KQasY3cbocAABwBAiyCEqhf10IIaM+F0IAAMBfEWQRlGrvKLgQQmTrNk6XAgAAjhBBFkFn+6Y1qp0i5Utqf8rFTpcDAACOEEEWQWfhf9+wy111pHa9znK6HAAAcIQIsgg66Uvn2+X+eiFyhUY4XQ4AADhCBFkEndgtiXaZ26iO06UAAICjQJBFUMnPy1ODnXl2Pa5Lb6fLAQAAR4Egi6CyfO5MReZKmeFSj4HDnS4HAAAcBYIsgsqGWR/Y5Y66Uu2G7Z0uBwAAHAWCLIJK/qqVdpmcECG5XE6XAwAAjgJBFkGl5vaUgpWmjZwuBQAAHCWCLIJGblqq6u4xl0GQGvQ6w+lyAADAUSLIImgs+XqaQrzSvhip94ArnC4HAAAcJYIsgsb2uV/b5a56LlWLruV0OQAA4CgRZBE0XJs22mV63WinSwEAABWAIIugEbcz0y7dLVs5XQoAAKgABFkEhYw9u1V7n9euNznpPKfLAQAAFYAgi6Cw9PMpdmffXUPq3fcCp8sBAAAVgCCLoJD46w92ubueW+Fh4U6XAwAAKgBBFkEhZOt2u0xPiHW6FAAAUEEIsggKtXZm2WVY63ZOlwIAACoIQRYBL2XbFsX9dWXa1v3+7nQ5AACgghBkERQnehk746SePQY5XQ4AAKggBFkEvL1L59plYr0QuUNCnC4HAABUEIIsAl7Ylh12mVG/ptOlAACACkSQRcCrvTvHLiPbdHK6FAAAUIEIsgho+zavU81UKV9Sh9MudrocAABQgQiyCGhLv3jTLnfVkjp16ud0OQAAoAIRZBHQ9v823y731OVELwAAAg1BFgEt/M9ddpnZIM7pUgAAQAUjyCKg1d5VcKJXVNsuTpcCAAAqGEEWAStxw2rVTCs40avj6Zc4XQ4AAKhgBFkErMVfFFzRa3ctqX2Hvk6XAwAAKhhBFgErZdmCohO9XG52dQAAAg3/uiNgRW9JtMusRnWcLgUAAFQCgiwCktfrVfyuXLse3am70+UAAIBKQJBFQNq6fKFiMiWPSzruzCucLgcAAFQCgiwC0vJv37PLXbWl5i2Oc7ocAAAQqEF24sSJatasmSIjI9W7d28tWFBwkk5ZPvjgA7Vr185u37lzZ3355ZfHrFb4h9RVv9nl/jqhTpcCAAACNchOmzZNo0aN0pgxY7R48WJ17dpVAwcO1O7du0vdfu7cubr00ks1YsQILVmyREOGDLG35cuXH/PaUXVFbN9jlzn1aztdCgAACNQgO378eF177bW66qqr1KFDB02aNElRUVGaPHlyqds/++yzGjRokO644w61b99eDz/8sLp3764XXnjhmNeOqqvOXyd6VW/PiV4AAAQqR4+75uTkaNGiRRo9enTRY263WwMGDNC8efNKfY153PTgFmd6cD/55JNSt8/Ozra3QikpKXaZn59vbzg000ZmBgB/aqsta5eqdsH/ZnUZdMUxrd0f28tJtJdvaC/f0F6+ob18Q3v5prLaydEgu2fPHnk8HtWrV6/E4+b+qlWrSn3Nzp07S93ePF6acePGaezYsQc9npiYaIM0Dr/jJScn2y+r+SPDHyz67HV1MPtXDSkutn6Zw1Qqgz+2l5NoL9/QXr6hvXxDe/mG9vKNaavKEPBnwpje3uI9uKZHtnHjxoqPj1fNmjUdrc1fvqgul8u2l798Ubufe5UWZacrPztbfevWPaaf7Y/t5STayze0l29oL9/QXr6hvXwTHh6ugAuyderUUUhIiHbt2lXicXM/ISGh1NeYx33ZPiIiwt4OZHY6drzyMV9Uf2qv5u17qvl9Uxz7fH9rL6fRXr6hvXxDe/mG9vIN7VV+ldVGbqfTeY8ePTRr1qwSf+GY+3369Cn1Nebx4tsbM2fOLHN7AAAABCbHhxaYw/7Dhw9Xz5491atXL02YMEHp6el2FgNj2LBhatiwoR3ratxyyy3q16+fnn76aZ1zzjmaOnWqFi5cqFdeecXhnwQAAABBFWSHDh1qT7x64IEH7Alb3bp109dff110QteWLVtKdEefeOKJeu+993TffffpnnvuUevWre2MBZ06dXLwpwAAAEDQBVlj5MiR9laa2bNnH/TYRRddZG8AAAAIXoxOBgAAgF8iyAIAAMAvEWQBAADglwiyAAAA8EsEWQAAAPglgiwAAAD8EkEWAAAAfokgCwAAAL9EkAUAAIBfIsgCAADALxFkAQAA4JcIsgAAAPBLoQoyXq/XLlNSUuR2k+MPJz8/X6mpqYqMjKS9yoH28g3t5Rvayze0l29oL9/QXr4xuat4DqsoQRdk9+7da5dNmzZ1uhQAAICgy2E1atSosPcLuiBbq1Ytu9yyZUuFNmQg/wXVuHFjbd26VbGxsU6XU+XRXr6hvXxDe/mG9vIN7eUb2ss3ycnJatKkSVEOqyhBF2QLu/9NiGXHKz/TVrRX+dFevqG9fEN7+Yb28g3t5RvayzcVPQyDQR0AAADwSwRZAAAA+KWgC7IREREaM2aMXeLwaC/f0F6+ob18Q3v5hvbyDe3lG9qrarSXy1vR8yAAAAAAx0DQ9cgCAAAgMBBkAQAA4JcIsgAAAPBLARlkJ06cqGbNmtnLxvXu3VsLFiw45PYffPCB2rVrZ7fv3LmzvvzySwUTX9prypQpcrlcJW7mdcHixx9/1ODBg9WgQQP7s3/yySeHfc3s2bPVvXt3O8C9VatWtg2Dha/tZdrqwP3L3Hbu3KlAN27cOB1//PGqXr266tatqyFDhmj16tWHfV2w/v46kvYK5t9fL730krp06VI052mfPn301VdfHfI1wbpvHUl7BfO+VZrHHnvMtsGtt96qyt7HAi7ITps2TaNGjbJnxi1evFhdu3bVwIEDtXv37lK3nzt3ri699FKNGDFCS5Yssb8MzW358uUKBr62l2G+1Dt27Ci6bd68WcEiPT3dtpEJ/+WxceNGnXPOOerfv7+WLl1qv9TXXHONZsyYoWDga3sVMoGk+D5mgkqg++GHH3TzzTfrl19+0cyZM5Wbm6szzzzTtmFZgvn315G0VzD//mrUqJENF4sWLdLChQt12mmn6bzzztOKFStK3T6Y960jaa9g3rcO9Ouvv+rll1+2fwgcSoXtY94A06tXL+/NN99cdN/j8XgbNGjgHTduXKnbX3zxxd5zzjmnxGO9e/f2Xn/99d5g4Gt7vfHGG94aNWocwwqrLvP1mT59+iG3ufPOO70dO3Ys8djQoUO9AwcO9Aab8rTX999/b7dLSkryBrvdu3fbtvjhhx/K3CbYf3/52l78/iopLi7O+9prr5X6HPuWb+3FvlUgNTXV27p1a+/MmTO9/fr1895yyy3eslTUPhZQPbI5OTn2r6cBAwaUuBSauT9v3rxSX2MeL769YXoky9o+2NvLSEtLU9OmTe01pg/3F2qwC+b962h069ZN9evX1xlnnKE5c+YoWK9LbhzquuTsX761l8HvL8nj8Wjq1Km299ocMi8N+5Zv7WWwb8keJTFHIQ/cdypzHwuoILtnzx67w9WrV6/E4+Z+WWPszOO+bB/s7dW2bVtNnjxZn376qd555x3l5+frxBNP1J9//nmMqvYvZe1fKSkpyszMdKyuqsqE10mTJumjjz6yN/MPwqmnnmqHvQQT870yw1D69u2rTp06lbldMP/+OpL2CvbfX8uWLVNMTIwdr3/DDTdo+vTp6tChQ6nbsm/51l7Bvm8ZJuyb39Vm/Hp5VNQ+FurT1gh65q/R4n+Rmi9q+/bt7XiYhx9+2NHa4P/MPwbmVnz/Wr9+vZ555hm9/fbbCqZeDTNO7Oeff3a6lIBqr2D//WW+W2asvum9/vDDDzV8+HA71riscBbsfGmvYN+3tm7dqltuucWOVz/WJ7kFVJCtU6eOQkJCtGvXrhKPm/sJCQmlvsY87sv2wd5eBwoLC9Nxxx2ndevWVVKV/q2s/cucFFCtWjXH6vInvXr1CqpAN3LkSH3++ed2xgdzwsmhBPPvryNpr2D//RUeHm5nTjF69OhhT8p59tlnbdg6EPuWb+0V7PvWokWL7EniZoaeQuaIr/levvDCC8rOzrZ5ozL2MXeg7XRmZ5s1a1bRY6Z739wva1yLebz49ob5i+JQ42CCub0OZHZUc/jFHBLGwYJ5/6oopkckGPYvcz6cCWXm8OV3332n5s2bH/Y1wbx/HUl7HSjYf3+Z3/cmYJQmmPetI2mvYN+3Tj/9dPvzmt/XhbeePXvq8ssvt+sHhtgK3ce8AWbq1KneiIgI75QpU7x//PGH97rrrvPWrFnTu3PnTvv8FVdc4b377ruLtp8zZ443NDTU+9RTT3lXrlzpHTNmjDcsLMy7bNkybzDwtb3Gjh3rnTFjhnf9+vXeRYsWeS+55BJvZGSkd8WKFd5gOSNzyZIl9ma+PuPHj7frmzdvts+btjJtVmjDhg3eqKgo7x133GH3r4kTJ3pDQkK8X3/9tTcY+NpezzzzjPeTTz7xrl271n4HzRmvbrfb++2333oD3Y033mjPep49e7Z3x44dRbeMjIyibfj9dXTtFcy/v0w7mBkdNm7c6P3999/tfZfL5f3mm2/s8+xbR9dewbxvleXAWQsqax8LuCBrPP/8894mTZp4w8PD7fRSv/zyS4mGHT58eInt33//fW+bNm3s9maqpC+++MIbTHxpr1tvvbVo23r16nnPPvts7+LFi73BonB6qANvhW1klqbNDnxNt27dbJu1aNHCTtMSLHxtr8cff9zbsmVL+w9ArVq1vKeeeqr3u+++8waD0trJ3IrvL/z+Orr2CubfX1dffbW3adOm9mePj4/3nn766UWhzGDfOrr2CuZ9q7xBtrL2MZf5z9F2KQMAAADHWkCNkQUAAEDwIMgCAADALxFkAQAA4JcIsgAAAPBLBFkAAAD4JYIsAAAA/BJBFgAAAH6JIAsAAAC/RJAFgCDx4IMPqlu3bo59/v3336/rrruuXNvefffd+uc//1npNQHwb1zZC4DfuvLKK/Xmm2/a9dDQUDVq1EgXXXSRHnroIUVGRiqYuVwuTZ8+XUOGDCl6LC0tTdnZ2apdu/Yxr2fnzp1q06aNli1bpqZNmx52+z179qhFixZaunSpXQJAaeiRBeDXBg0apB07dmjDhg165pln9PLLL2vMmDFOl1UlxcTEOBJijddee00nnnhiuUKsUadOHQ0cOFAvvfRSpdcGwH8RZAH4tYiICCUkJKhx48a293HAgAGaOXNm0fP5+fkaN26cmjdvrmrVqqlr16768MMPi55PSkrS5Zdfrvj4ePt869at9cYbb9jnNm3aZHs2p06dakOY6eXt1KmTfvjhhxI1mPu9evWytdSvX98eFs/Lyyt6/tRTT9W//vUv3XnnnapVq5at1xzmL2QOjJn7TZo0se/RoEEDu30h04t6++23q2HDhoqOjlbv3r01e/bsMtukWbNmdnn++efb+gvvHzi0wPRomzZ79NFHVa9ePdWsWdP2Zpva77jjDlur6eUubI9CW7du1cUXX2y3N9ucd955tq0OxbTh4MGDSzxm/j907tzZtrsJ2Ob/XXp6etHzZnvzOgAoC0EWQMBYvny55s6dq/Dw8KLHTIh96623NGnSJK1YsUK33Xab/vGPfxSFUTNu848//tBXX32llStX2h5A0xtYnAl1//73v7VkyRL16dPHBqy9e/fa57Zt26azzz5bxx9/vH777Tf7+tdff13/93//V+I9zBAIE0Lnz5+vJ554wgbGwsD90UcfFfUmr127Vp988okNeIVGjhypefPm2VD3+++/2+ETpifabFuaX3/91S5NADW91YX3S/Pdd99p+/bt+vHHHzV+/Hjbm33uuecqLi7O1nrDDTfo+uuv159//mm3z83NtT2l1atX108//aQ5c+bYnl5TT05OTqmfsW/fPtvGPXv2LHrM1HXppZfq6quvtu1ugvkFF1xgQ30h88eB+dzDhWQAQcyMkQUAfzR8+HBvSEiINzo62hsREWESkNftdns//PBD+3xWVpY3KirKO3fu3BKvGzFihPfSSy+164MHD/ZeddVVpb7/xo0b7Xs+9thjRY/l5uZ6GzVq5H388cft/Xvuucfbtm1bb35+ftE2EydO9MbExHg9Ho+9369fP+9JJ51U4r2PP/5471133WXXn376aW+bNm28OTk5B9WwefNm+zNu27atxOOnn366d/To0WW2jal7+vTpJR4bM2aMt2vXriXar2nTpkV1GuZnOfnkk4vu5+Xl2fb9z3/+Y++//fbbB/282dnZ3mrVqnlnzJhRai1Lliyx9WzZsqXosUWLFtnHNm3aVObPkJycbLeZPXt2mdsACG6hTgdpADga/fv3t72g5pC06dU0J31deOGF9rl169YpIyNDZ5xxRonXmJ7D4447zq7feOONdvvFixfrzDPPtIfazTCC4kwvbCHz/qZn0fQiGmZpnjeH8Av17dvXnlhlehPNcAGjS5cuJd7TDEHYvXu3XTc9rBMmTLAnNZmeTdPDa3p9zWeZk6M8Ho89Uaq4ijppq2PHjnK7/3dwzgwxMMMnCoWEhNjPKazV9DqbdjU9ssVlZWVp/fr1pX5GZmamXRY/Ac8M8Tj99NNtz7Pp4TVt//e//932BBcyQw4M8/8QAEpDkAXg18zh+latWtn1yZMn24BkDu2PGDHChknjiy++sONLizNjUY2zzjpLmzdv1pdffmkP9ZtwdfPNN+upp56q0DrDwsJK3DfB14zfNcz43tWrV+vbb7+1Ndx000168skn7fAH8zOYMLlo0SK7LM4c0q+Mug5Vq6mnR48eevfddw96LzPOuDSFQzXMeOTCbczPYn5WMxTkm2++0fPPP697773XDmcw45kLhyQc6n0BgDGyAAKG6Vm85557dN9999lewA4dOtjAumXLFht2i99MeCxkgtLw4cP1zjvv2J7RV155pcT7/vLLL0Xr5kQoEyrbt29v75ulGb9afGynGTdqeizNiVLlZXofTS/sc889Z8eLmvc0vbGm59j0yJoe0QN/BnPSWFlMGDWvq2jdu3e3Y3Pr1q17UD01atQo9TUtW7ZUbGysHSd7YEA2vddjx46144/N2GYzZVjxMc/m5zC9xgBQGoIsgIBiDtOb3r6JEyfaMGnO9jcneJmTrcyhbzOEwPT+Fc4/+8ADD+jTTz+1h8vNyWCff/55UUgtZN7LBKxVq1bZ3lrTs2hOUjJM76k5i99M3m+eN+9lTpgaNWpUiUP2hzJlyhTbi2yCm5lGzARqE2zNVFVmSIGZVWHYsGH6+OOPtXHjRi1YsMCexGZ6mstiZiqYNWuWnb/V1FtRTC2mh9XMVGBO9jL1mOBtZlkoPCHsQKYdzIwEP//8c9FjpufVzJawcOFC+4eG+dkSExNLtL15/5NPPrloiAEAHIggCyCgmHGl5ix/MzOAGTf78MMP25kJTPAzIcmMQTUBsPDwtekFHD16tB3Desopp9gQfOCUT4899pi9mWELJox99tlnRYfLzZAFMyzBhEvzvDnL3wxrML3C5WWmsXr11Vdt76Spwwwx+O9//1s0BtbMPmCCrJk5oW3btnYcr5mJoHD8bWmefvppe+je9DwXjgeuCFFRUXaGA/PZZpYB06bm5zVjZE2va1muueYa266FQxTMtuZ9zHhgE9ZNe5mazVCPQmb7a6+9tsJqBxB4uLIXAJTBTPtkAq857O3kpV0Dgfmnxsx/a3rHzbRbh2OmQzPB3Uw3Zv44AYDS0CMLAKh0ZjysGXtc/EIRh2J6001PNCEWwKHQIwsAZaBHFgCqNoIsAAAA/BJDCwAAAOCXCLIAAADwSwRZAAAA+CWCLAAAAPwSQRYAAAB+iSALAAAAv0SQBQAAgF8iyAIAAMAvEWQBAAAgf/T/Lz6HevBCbMMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./anonymisedData/sim_results\\response_time_cdf.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot response-time CDF for policies (one cell)\n",
    "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "SR = './anonymisedData/sim_results'\n",
    "files = {\n",
    "  'least_loaded': os.path.join(SR,'leastloaded_run_1.csv'),\n",
    "  'round_robin': os.path.join(SR,'baseline_roundrobin_results.csv'),\n",
    "  'random': os.path.join(SR,'baseline_random_results.csv'),\n",
    "  'rl_full': os.path.join(SR,'rl_full_eval_seed_202.csv')\n",
    "}\n",
    "plt.figure(figsize=(7,5))\n",
    "found = False\n",
    "for name,path in files.items():\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        vals = np.sort(df['response_time'].values)\n",
    "        cdf = np.arange(1,len(vals)+1)/len(vals)\n",
    "        plt.plot(vals, cdf, label=name.replace('_',' ').title())\n",
    "        found = True\n",
    "if not found:\n",
    "    print(\"No per-request files found to plot CDF. Check sim_results folder.\")\n",
    "else:\n",
    "    plt.xlabel('Response time (s)')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.xlim(0,4)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    out = os.path.join(SR,'response_time_cdf.png')\n",
    "    plt.tight_layout(); plt.savefig(out, dpi=200); plt.show()\n",
    "    print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "670fde28-97a0-4fec-8024-90cb7612d210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least_loaded: FOUND | rows=199997 | col='response_time' | mean=1.300144 | p95=2.294482\n",
      "round_robin: FOUND | rows=199997 | col='response_time' | mean=1.299915 | p95=2.298005\n",
      "random: FOUND | rows=199997 | col='response_time' | mean=1.301273 | p95=2.305846\n",
      "rl_full: FOUND | rows=99997 | col='response_time' | mean=1.300239 | p95=2.304134\n",
      "\n",
      "If only one FOUND above, the plot will show one line. If multiple found but curves overlap, proceed to the next cell to create a clearer plot.\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd, numpy as np\n",
    "SR = './anonymisedData/sim_results'\n",
    "files = {\n",
    "  'least_loaded': os.path.join(SR,'leastloaded_run_1.csv'),\n",
    "  'round_robin': os.path.join(SR,'baseline_roundrobin_results.csv'),\n",
    "  'random': os.path.join(SR,'baseline_random_results.csv'),\n",
    "  'rl_full': os.path.join(SR,'rl_full_eval_seed_202.csv')\n",
    "}\n",
    "found = {}\n",
    "for name,path in files.items():\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        cnt = len(df)\n",
    "        col = 'response_time' if 'response_time' in df.columns else df.columns[0]\n",
    "        arr = df['response_time'].values if 'response_time' in df.columns else df[col].values\n",
    "        print(f\"{name}: FOUND | rows={cnt} | col='{col}' | mean={arr.mean():.6f} | p95={np.percentile(arr,95):.6f}\")\n",
    "        found[name] = path\n",
    "    else:\n",
    "        print(f\"{name}: MISSING -> {path}\")\n",
    "print(\"\\nIf only one FOUND above, the plot will show one line. If multiple found but curves overlap, proceed to the next cell to create a clearer plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f275795d-7051-42a3-97a4-7f3cb7f41754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./anonymisedData/sim_results\\response_time_cdf.png\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "SR = './anonymisedData/sim_results'\n",
    "files = {\n",
    "  'Least-Loaded': os.path.join(SR,'leastloaded_run_1.csv'),\n",
    "  'Round-Robin': os.path.join(SR,'baseline_roundrobin_results.csv'),\n",
    "  'Random': os.path.join(SR,'baseline_random_results.csv'),\n",
    "  'RL (seed202)': os.path.join(SR,'rl_full_eval_seed_202.csv')\n",
    "}\n",
    "colors = ['tab:blue','tab:orange','tab:green','tab:red']\n",
    "plt.figure(figsize=(8,5))\n",
    "plotted = 0\n",
    "for (label,path),c in zip(files.items(), colors):\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        if 'response_time' not in df.columns:\n",
    "            print(\"Warning:\", path, \"has no 'response_time' column  skipping.\")\n",
    "            continue\n",
    "        arr = np.sort(df['response_time'].values)\n",
    "        # downsample for plotting if very large\n",
    "        if len(arr) > 200000:\n",
    "            idx = np.linspace(0, len(arr)-1, 200000).astype(int)\n",
    "            arr = arr[idx]\n",
    "        cdf = np.arange(1, len(arr)+1) / len(arr)\n",
    "        plt.plot(arr, cdf, label=f\"{label} (n={len(df):,})\", color=c, linewidth=2)\n",
    "        # add a few markers at deciles to make overlapping visible\n",
    "        dec_idx = (np.linspace(0, len(arr)-1, 10).astype(int))\n",
    "        plt.plot(arr[dec_idx], cdf[dec_idx], marker='o', linestyle='', color=c, markersize=4, alpha=0.7)\n",
    "        plotted += 1\n",
    "    else:\n",
    "        print(\"Missing file for\", label, \"->\", path)\n",
    "\n",
    "if plotted == 0:\n",
    "    print(\"No per-request files found to plot CDF. Check sim_results folder.\")\n",
    "else:\n",
    "    plt.xlabel('Response time (s)')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.xlim(0, 4)\n",
    "    plt.ylim(0,1)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(loc='lower right', fontsize='small')\n",
    "    out = os.path.join(SR,'response_time_cdf.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out, dpi=200)\n",
    "    plt.show()\n",
    "    print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2660efb3-9ace-4499-9b91-3a89bb51afca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing: ./anonymisedData/sim_results\n",
      "ablation_quick_summary.csv | size: 132 bytes\n",
      "baseline_leastloaded_results.csv | size: 17272493 bytes\n",
      "baseline_random_results.csv | size: 17275266 bytes\n",
      "baseline_roundrobin_results.csv | size: 17272566 bytes\n",
      "baseline_summary.csv | size: 222 bytes\n",
      "bootstrap_summary.csv | size: 536 bytes\n",
      "comparison_summary.csv | size: 389 bytes\n",
      "leastloaded_repeats_summary.csv | size: 381 bytes\n",
      "leastloaded_run_1.csv | size: 17272324 bytes\n",
      "leastloaded_run_2.csv | size: 17272540 bytes\n",
      "leastloaded_run_3.csv | size: 17272594 bytes\n",
      "leastloaded_run_4.csv | size: 17272583 bytes\n",
      "leastloaded_run_5.csv | size: 17271948 bytes\n",
      "priority_results.csv | size: 17809849 bytes\n",
      "response_time_cdf.png | size: 74818 bytes\n",
      "rl_full_eval_seed_101.csv | size: 8822715 bytes\n",
      "rl_full_eval_seed_202.csv | size: 8816654 bytes\n",
      "rl_full_eval_seed_303.csv | size: 8823183 bytes\n",
      "rl_full_eval_seed_404.csv | size: 8823857 bytes\n",
      "rl_full_eval_seed_42.csv | size: 8823348 bytes\n",
      "rl_full_rewards_seed_101.csv | size: 1438 bytes\n",
      "rl_full_rewards_seed_202.csv | size: 1438 bytes\n",
      "rl_full_rewards_seed_303.csv | size: 1438 bytes\n",
      "rl_full_rewards_seed_404.csv | size: 1431 bytes\n",
      "rl_full_rewards_seed_42.csv | size: 1435 bytes\n",
      "rl_full_summary.csv | size: 754 bytes\n",
      "rl_policy_results.csv | size: 12250294 bytes\n",
      "sjf_results.csv | size: 18870796 bytes\n",
      "tuning_results.csv | size: 1041 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "SR = './anonymisedData/sim_results'\n",
    "print(\"Listing:\", SR)\n",
    "for p in sorted(os.listdir(SR)):\n",
    "    fp = os.path.join(SR,p)\n",
    "    try:\n",
    "        print(p, \"| size:\", os.path.getsize(fp), \"bytes\")\n",
    "    except:\n",
    "        print(p, \"| (could not stat)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa25bb58-b00b-447a-ae1d-d83fdcd4c589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./anonymisedData/sim_results\\equity_by_group_leastloaded.csv\n",
      "      policy group_col sex  mean_rt      n   p95_rt  sla_pct internet  Medu  Fedu famsize address\n",
      "least_loaded       sex   F 1.301506 105662 2.294504 9.079896      NaN   NaN   NaN     NaN     NaN\n",
      "least_loaded       sex   M 1.298619  94335 2.294123 8.943658      NaN   NaN   NaN     NaN     NaN\n",
      "least_loaded  internet NaN 1.299708  33581 2.277618 8.885977       no   NaN   NaN     NaN     NaN\n",
      "least_loaded  internet NaN 1.300232 166416 2.297830 9.041799      yes   NaN   NaN     NaN     NaN\n",
      "least_loaded      Medu NaN 1.271927   1570 2.176806 7.261146      NaN   0.0   NaN     NaN     NaN\n",
      "least_loaded      Medu NaN 1.300126  29719 2.284653 8.970692      NaN   1.0   NaN     NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# -> create equity_by_group_leastloaded.csv\n",
    "import os, pandas as pd, numpy as np\n",
    "SR = './anonymisedData/sim_results'\n",
    "REQ = './anonymisedData/requests.csv'\n",
    "ll_file = os.path.join(SR,'leastloaded_run_1.csv')\n",
    "\n",
    "if not os.path.exists(ll_file):\n",
    "    raise FileNotFoundError(\"Missing leastloaded_run_1.csv in sim_results. Cannot compute equity.\")\n",
    "\n",
    "reqs = pd.read_csv(REQ).sort_values('sec').reset_index(drop=True)\n",
    "reqs['request_idx'] = reqs.index\n",
    "pres = pd.read_csv(ll_file)\n",
    "if 'request_idx' not in pres.columns:\n",
    "    pres = pres.reset_index().rename(columns={'index':'request_idx'})\n",
    "pres['request_idx'] = pres['request_idx'].astype(int)\n",
    "\n",
    "merged = pres.merge(reqs, on='request_idx', how='left')\n",
    "group_cols = [c for c in ['sex','internet','Medu','Fedu','famsize','address'] if c in merged.columns]\n",
    "out_frames = []\n",
    "for col in group_cols:\n",
    "    g = merged.groupby(col)['response_time'].agg(['mean','count', lambda x: np.percentile(x,95), lambda x: (x>2.0).mean()*100.0])\n",
    "    g.columns = ['mean_rt','n','p95_rt','sla_pct']\n",
    "    g = g.reset_index()\n",
    "    g.insert(0,'policy','least_loaded')\n",
    "    g.insert(1,'group_col',col)\n",
    "    out_frames.append(g)\n",
    "\n",
    "if out_frames:\n",
    "    df_out = pd.concat(out_frames, ignore_index=True)\n",
    "    outp = os.path.join(SR,'equity_by_group_leastloaded.csv')\n",
    "    df_out.to_csv(outp, index=False)\n",
    "    print(\"Saved:\", outp)\n",
    "    print(df_out.head(6).to_string(index=False))\n",
    "else:\n",
    "    print(\"No demographic columns found in requests.csv to analyze.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e26d8c6-daf7-4a31-abd7-1605527a0955",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest_idx\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 48\u001b[0m df_test \u001b[38;5;241m=\u001b[39m \u001b[43mrun_sjf_event_driven_small\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m outp \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(SR,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msjf_results_debug.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m df_test\u001b[38;5;241m.\u001b[39mto_csv(outp, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[44], line 24\u001b[0m, in \u001b[0;36mrun_sjf_event_driven_small\u001b[1;34m(reqs_df, num_servers)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m N \u001b[38;5;129;01mand\u001b[39;00m arrivals[i] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m current_time:\n\u001b[0;32m     23\u001b[0m     heapq\u001b[38;5;241m.\u001b[39mheappush(wait_heap, (svc[i], i, arrivals[i])); i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 24\u001b[0m free_servers \u001b[38;5;241m=\u001b[39m [sid \u001b[38;5;28;01mfor\u001b[39;00m sid,t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(servers_next_free) \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m current_time]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m free_servers \u001b[38;5;129;01mand\u001b[39;00m wait_heap:\n\u001b[0;32m     26\u001b[0m     free_servers\u001b[38;5;241m.\u001b[39msort()\n",
      "Cell \u001b[1;32mIn[44], line 24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m N \u001b[38;5;129;01mand\u001b[39;00m arrivals[i] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m current_time:\n\u001b[0;32m     23\u001b[0m     heapq\u001b[38;5;241m.\u001b[39mheappush(wait_heap, (svc[i], i, arrivals[i])); i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 24\u001b[0m free_servers \u001b[38;5;241m=\u001b[39m [sid \u001b[38;5;28;01mfor\u001b[39;00m sid,t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(servers_next_free) \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m current_time]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m free_servers \u001b[38;5;129;01mand\u001b[39;00m wait_heap:\n\u001b[0;32m     26\u001b[0m     free_servers\u001b[38;5;241m.\u001b[39msort()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Debug SJF on small subset (quick)  run in your notebook\n",
    "import os, heapq, numpy as np, pandas as pd, time\n",
    "\n",
    "ROOT = './anonymisedData'\n",
    "SR = os.path.join(ROOT, 'sim_results')\n",
    "os.makedirs(SR, exist_ok=True)\n",
    "\n",
    "reqs = pd.read_csv(os.path.join(ROOT,'requests.csv')).sort_values('sec').reset_index(drop=True).iloc[:10000].copy()\n",
    "reqs['arrival'] = reqs['sec'].astype(float)\n",
    "rng = np.random.default_rng(12345)\n",
    "service_times = 0.8 + rng.exponential(0.5, size=len(reqs))\n",
    "reqs['true_service_time'] = service_times\n",
    "\n",
    "def run_sjf_event_driven_small(reqs_df, num_servers=6):\n",
    "    arrivals = list(reqs_df['arrival'].values)\n",
    "    svc = list(reqs_df['true_service_time'].values)\n",
    "    N = len(arrivals)\n",
    "    i = 0; current_time = arrivals[0] if N>0 else 0.0\n",
    "    wait_heap = []; servers_next_free = [0.0]*num_servers; rows=[]; processed=0\n",
    "    last_report = time.time()\n",
    "    while processed < N:\n",
    "        while i < N and arrivals[i] <= current_time:\n",
    "            heapq.heappush(wait_heap, (svc[i], i, arrivals[i])); i += 1\n",
    "        free_servers = [sid for sid,t in enumerate(servers_next_free) if t <= current_time]\n",
    "        if free_servers and wait_heap:\n",
    "            free_servers.sort()\n",
    "            for sid in free_servers:\n",
    "                if not wait_heap: break\n",
    "                service_time, idx, arr_time = heapq.heappop(wait_heap)\n",
    "                start = max(arr_time, servers_next_free[sid], current_time)\n",
    "                finish = start + service_time\n",
    "                response_time = finish - arr_time\n",
    "                servers_next_free[sid] = finish\n",
    "                rows.append({'request_idx':int(idx),'arrival':arr_time,'server_id':sid,'start':start,'finish':finish,'service_time':service_time,'response_time':response_time})\n",
    "                processed += 1\n",
    "            if time.time() - last_report > 5:\n",
    "                print(f\"Debug progress: processed {processed}/{N} ...\"); last_report = time.time()\n",
    "            continue\n",
    "        next_arrival = arrivals[i] if i < N else float('inf')\n",
    "        next_server_free = min(servers_next_free) if servers_next_free else float('inf')\n",
    "        nxt = min(next_arrival, next_server_free)\n",
    "        if nxt == float('inf'):\n",
    "            break\n",
    "        current_time = max(current_time, nxt)\n",
    "    df = pd.DataFrame(rows).sort_values('request_idx').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_test = run_sjf_event_driven_small(reqs)\n",
    "outp = os.path.join(SR,'sjf_results_debug.csv')\n",
    "df_test.to_csv(outp, index=False)\n",
    "print(\"Debug SJF done. Saved:\", outp, \"| rows:\", len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1946d9e-2fb5-46e9-8d9b-e3445f4a6b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug SJF done. Saved: ./anonymisedData\\sim_results\\sjf_results_debug_safe.csv | rows: 10000 | time: 0.08s\n"
     ]
    }
   ],
   "source": [
    "# Corrected FAST SJF debug (10k requests)  paste and run in your notebook\n",
    "import os, heapq, numpy as np, pandas as pd, time\n",
    "ROOT = './anonymisedData'\n",
    "SR = os.path.join(ROOT,'sim_results')\n",
    "os.makedirs(SR, exist_ok=True)\n",
    "\n",
    "reqs = pd.read_csv(os.path.join(ROOT,'requests.csv')).sort_values('sec').reset_index(drop=True).iloc[:10000].copy()\n",
    "reqs['arrival'] = reqs['sec'].astype(float)\n",
    "arrivals = reqs['arrival'].values.tolist()\n",
    "N = len(arrivals)\n",
    "rng = np.random.default_rng(12345)\n",
    "svc = (0.8 + rng.exponential(0.5, size=N)).tolist()\n",
    "\n",
    "def run_sjf_safe(arrivals, svc, num_servers=6):\n",
    "    INF = float('inf')\n",
    "    # servers heap: (next_free_time, server_id)\n",
    "    servers = [(0.0, s) for s in range(num_servers)]\n",
    "    heapq.heapify(servers)\n",
    "    # waiting jobs heap: (service_time, idx, arrival)\n",
    "    wait_heap = []\n",
    "    rows = []\n",
    "    i = 0\n",
    "    last_report = time.time()\n",
    "    while i < N or wait_heap:\n",
    "        next_arrival = arrivals[i] if i < N else INF\n",
    "        next_server_free = servers[0][0] if servers else INF\n",
    "\n",
    "        # Advance time: if no waiting jobs, jump to next arrival (avoid stuck at 0.0).\n",
    "        if not wait_heap:\n",
    "            current_time = next_arrival\n",
    "        else:\n",
    "            # there are waiting jobs: consider either next arrival or next server becoming free\n",
    "            current_time = min(next_arrival, next_server_free)\n",
    "\n",
    "        # push arrivals that occur at or before current_time\n",
    "        while i < N and arrivals[i] <= current_time:\n",
    "            heapq.heappush(wait_heap, (svc[i], i, arrivals[i]))\n",
    "            i += 1\n",
    "\n",
    "        # assign while a server is free at/before current_time and we have waiting jobs\n",
    "        while wait_heap and servers and servers[0][0] <= current_time:\n",
    "            server_free, sid = heapq.heappop(servers)\n",
    "            service_time, idx, arr_time = heapq.heappop(wait_heap)\n",
    "            start = max(arr_time, server_free)\n",
    "            finish = start + service_time\n",
    "            response_time = finish - arr_time\n",
    "            heapq.heappush(servers, (finish, sid))\n",
    "            rows.append({'request_idx':int(idx),'arrival':arr_time,'server_id':sid,'start':start,'finish':finish,'service_time':service_time,'response_time':response_time})\n",
    "\n",
    "        # progress print occasionally\n",
    "        if time.time() - last_report > 5:\n",
    "            print(f\"Debug SJF progress: arrivals processed {i}/{N}, scheduled {len(rows)} ...\")\n",
    "            last_report = time.time()\n",
    "\n",
    "        # If no waiting jobs and next_arrival==INF, loop will exit because i>=N and wait_heap empty\n",
    "    df = pd.DataFrame(rows).sort_values('request_idx').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "t0 = time.time()\n",
    "df_debug = run_sjf_safe(arrivals, svc, num_servers=6)\n",
    "t1 = time.time()\n",
    "out = os.path.join(SR, 'sjf_results_debug_safe.csv')\n",
    "df_debug.to_csv(out, index=False)\n",
    "print(f\"Debug SJF done. Saved: {out} | rows: {len(df_debug)} | time: {t1-t0:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3be64edb-6a1d-4458-ab33-946ff3a2a63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJF run: N = 199997 | SAMPLE_CAP = 200000\n",
      "SJF finished. Saved: ./anonymisedData\\sim_results\\sjf_results_fixed_fast.csv | rows: 199997 | time: 1.2s\n",
      "Computing bootstrap CIs (this may take a short while)...\n",
      "Saved updated bootstrap summary -> ./anonymisedData\\sim_results\\bootstrap_summary_fixed_fast.csv\n",
      "      policy  mean_rt  mean_rt_lo  mean_rt_hi   sla_pct   sla_lo    sla_hi\n",
      "least_loaded 1.300144    1.297843    1.302237  9.015635 8.885133  9.149175\n",
      "          rl 1.300239    1.297171    1.303339  9.167275 8.998270  9.334380\n",
      "   sjf_fixed 1.298521    1.296196    1.300600  8.996135 8.883608  9.123662\n",
      "    priority 1.309651    1.307462    1.311779 10.000150 9.869636 10.133665\n"
     ]
    }
   ],
   "source": [
    "# FULL fast SJF + bootstrap (heap-based)  run this cell (SAMPLE_CAP = 200000)\n",
    "import os, heapq, numpy as np, pandas as pd, time\n",
    "ROOT = './anonymisedData'\n",
    "SR = os.path.join(ROOT,'sim_results'); os.makedirs(SR, exist_ok=True)\n",
    "\n",
    "# USER CHOICE: cap the trace for speed\n",
    "SAMPLE_CAP = 200000   # <-- you chose this\n",
    "\n",
    "reqs_all = pd.read_csv(os.path.join(ROOT,'requests.csv')).sort_values('sec').reset_index(drop=True)\n",
    "if SAMPLE_CAP:\n",
    "    reqs = reqs_all.iloc[:SAMPLE_CAP].copy()\n",
    "else:\n",
    "    reqs = reqs_all.copy()\n",
    "reqs['arrival'] = reqs['sec'].astype(float)\n",
    "N = len(reqs)\n",
    "print(\"SJF run: N =\", N, \"| SAMPLE_CAP =\", SAMPLE_CAP)\n",
    "\n",
    "rng = np.random.default_rng(12345)\n",
    "svc = (0.8 + rng.exponential(0.5, size=N)).tolist()\n",
    "\n",
    "def run_sjf_fast(arrivals, svc, num_servers=6):\n",
    "    servers = [(0.0, s) for s in range(num_servers)]\n",
    "    heapq.heapify(servers)\n",
    "    wait_heap = []\n",
    "    rows = []\n",
    "    i = 0\n",
    "    Nloc = len(arrivals)\n",
    "    INF = float('inf')\n",
    "    last_report = time.time()\n",
    "    while i < Nloc or wait_heap:\n",
    "        next_arrival = arrivals[i] if i < Nloc else INF\n",
    "        next_server_free = servers[0][0] if servers else INF\n",
    "        if not wait_heap:\n",
    "            current_time = next_arrival\n",
    "        else:\n",
    "            current_time = min(next_arrival, next_server_free)\n",
    "        while i < Nloc and arrivals[i] <= current_time:\n",
    "            heapq.heappush(wait_heap, (svc[i], i, arrivals[i])); i += 1\n",
    "        while wait_heap and servers and servers[0][0] <= current_time:\n",
    "            server_free, sid = heapq.heappop(servers)\n",
    "            service_time, idx, arr_time = heapq.heappop(wait_heap)\n",
    "            start = max(arr_time, server_free)\n",
    "            finish = start + service_time\n",
    "            response_time = finish - arr_time\n",
    "            heapq.heappush(servers, (finish, sid))\n",
    "            rows.append({'request_idx':int(idx),'arrival':arr_time,'server_id':sid,'start':start,'finish':finish,'service_time':service_time,'response_time':response_time})\n",
    "        if time.time() - last_report > 10:\n",
    "            processed = i + len(rows)\n",
    "            pct = processed / Nloc * 100\n",
    "            print(f\"SJF progress  {processed}/{Nloc} ({pct:.1f}%)\")\n",
    "            last_report = time.time()\n",
    "    df = pd.DataFrame(rows).sort_values('request_idx').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Run SJF and save\n",
    "out_sjf = os.path.join(SR, 'sjf_results_fixed_fast.csv')\n",
    "t0 = time.time()\n",
    "df_sjf = run_sjf_fast(reqs['arrival'].values.tolist(), svc, num_servers=6)\n",
    "t1 = time.time()\n",
    "df_sjf.to_csv(out_sjf, index=False)\n",
    "print(f\"SJF finished. Saved: {out_sjf} | rows: {len(df_sjf)} | time: {t1-t0:.1f}s\")\n",
    "\n",
    "# Bootstrap summary (1000 resamples)\n",
    "def bootstrap_ci(arr, statfunc=np.mean, nboot=1000, alpha=0.05):\n",
    "    n = len(arr)\n",
    "    idx = np.random.randint(0, n, size=(nboot, n))\n",
    "    stats = np.array([statfunc(arr[i]) for i in idx])\n",
    "    lo = np.percentile(stats, 100*alpha/2)\n",
    "    hi = np.percentile(stats, 100*(1-alpha/2))\n",
    "    return lo, hi\n",
    "\n",
    "policies = {\n",
    "    'least_loaded': os.path.join(SR,'leastloaded_run_1.csv'),\n",
    "    'rl': os.path.join(SR,'rl_full_eval_seed_202.csv'),\n",
    "    'sjf_fixed': out_sjf,\n",
    "    'priority': os.path.join(SR,'priority_results.csv')\n",
    "}\n",
    "summary = []\n",
    "print(\"Computing bootstrap CIs (this may take a short while)...\")\n",
    "for name,path in policies.items():\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        if 'response_time' not in df.columns:\n",
    "            print(f\"Skipping {name}: no response_time column in {path}\")\n",
    "            continue\n",
    "        arr = df['response_time'].values\n",
    "        mean = float(np.mean(arr)); lo,hi = bootstrap_ci(arr, np.mean, nboot=1000)\n",
    "        sla = float((arr>2.0).mean()*100); slo,shi = bootstrap_ci((arr>2.0).astype(float)*100, np.mean, nboot=1000)\n",
    "        summary.append({'policy':name,'mean_rt':mean,'mean_rt_lo':lo,'mean_rt_hi':hi,'sla_pct':sla,'sla_lo':slo,'sla_hi':shi})\n",
    "summary_df = pd.DataFrame(summary)\n",
    "out_boot = os.path.join(SR,'bootstrap_summary_fixed_fast.csv')\n",
    "summary_df.to_csv(out_boot, index=False)\n",
    "print(\"Saved updated bootstrap summary ->\", out_boot)\n",
    "print(summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d70c152-3c16-498f-8b53-8ea667dbc871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting lxml>=3.1.0 (from python-docx)\n",
      "  Downloading lxml-6.0.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\sleemteech\\anaconda3\\envs\\empiricalstudy\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Downloading lxml-6.0.0-cp310-cp310-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.8/4.0 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.4/4.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 6.3 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml, python-docx\n",
      "\n",
      "   ---------------------------------------- 0/2 [lxml]\n",
      "   ---------------------------------------- 0/2 [lxml]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   ---------------------------------------- 2/2 [python-docx]\n",
      "\n",
      "Successfully installed lxml-6.0.0 python-docx-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ed13d15-2306-49e3-a398-f5b2c55698c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reportlab\n",
      "  Downloading reportlab-4.4.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\sleemteech\\anaconda3\\envs\\empiricalstudy\\lib\\site-packages (from reportlab) (11.3.0)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\sleemteech\\anaconda3\\envs\\empiricalstudy\\lib\\site-packages (from reportlab) (3.3.2)\n",
      "Downloading reportlab-4.4.3-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: reportlab\n",
      "Successfully installed reportlab-4.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install reportlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ece5d84-5b4f-4746-b46f-7d6a4fc923c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Word doc: empirical_study_final_post_sjf.docx\n",
      "Saved PDF summary: empirical_study_summary_post_sjf.pdf\n",
      "Saved CSV: bootstrap_summary_final_post_sjf.csv\n"
     ]
    }
   ],
   "source": [
    "# Create updated Word doc + 1-page PDF using the final SJF/bootstrap numbers you ran\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "import pandas as pd, os\n",
    "\n",
    "# Final numbers (paste exactly the outputs you produced)\n",
    "bootstrap_rows = [\n",
    "    {'policy':'least_loaded','mean_rt':1.300144,'mean_rt_lo':1.297843,'mean_rt_hi':1.302237,'sla_pct':9.015635,'sla_lo':8.885133,'sla_hi':9.149175},\n",
    "    {'policy':'rl','mean_rt':1.300239,'mean_rt_lo':1.297171,'mean_rt_hi':1.303339,'sla_pct':9.167275,'sla_lo':8.998270,'sla_hi':9.334380},\n",
    "    {'policy':'sjf_fixed','mean_rt':1.298521,'mean_rt_lo':1.296196,'mean_rt_hi':1.300600,'sla_pct':8.996135,'sla_lo':8.883608,'sla_hi':9.123662},\n",
    "    {'policy':'priority','mean_rt':1.309651,'mean_rt_lo':1.307462,'mean_rt_hi':1.311779,'sla_pct':10.000150,'sla_lo':9.869636,'sla_hi':10.133665}\n",
    "]\n",
    "\n",
    "# Build Word doc\n",
    "doc = Document()\n",
    "doc.styles['Normal'].font.name = 'Times New Roman'; doc.styles['Normal'].font.size = Pt(11)\n",
    "doc.add_heading('Artificial Intelligence in Educational Management Information Systems in an Urban and Non-Profit Learning Context', level=1).alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "doc.add_paragraph('')\n",
    "\n",
    "doc.add_heading('Abstract', level=2)\n",
    "doc.add_paragraph(\"We compare practical heuristics and an exploratory hierarchical tabular RL agent on an EMIS-derived workload (OULAD + UCI). Key metrics: mean RT, p95, throughput, and %SLA. SJF (event-driven) was added as an oracle baseline and bootstrap 95% CIs computed (1000 resamples).\")\n",
    "\n",
    "doc.add_heading('Key results (post-SJF)', level=2)\n",
    "t = doc.add_table(rows=1, cols=7); hdr = t.rows[0].cells\n",
    "for i,h in enumerate(['Policy','Mean RT (s)','95% CI low','95% CI high','% SLA','SLA low','SLA high']): hdr[i].text = h\n",
    "for r in bootstrap_rows:\n",
    "    rc = t.add_row().cells\n",
    "    rc[0].text = r['policy']\n",
    "    rc[1].text = f\"{r['mean_rt']:.6f}\"\n",
    "    rc[2].text = f\"{r['mean_rt_lo']:.6f}\"\n",
    "    rc[3].text = f\"{r['mean_rt_hi']:.6f}\"\n",
    "    rc[4].text = f\"{r['sla_pct']:.6f}\"\n",
    "    rc[5].text = f\"{r['sla_lo']:.6f}\"\n",
    "    rc[6].text = f\"{r['sla_hi']:.6f}\"\n",
    "\n",
    "doc.add_heading('Interpretation (short)', level=2)\n",
    "doc.add_paragraph(\n",
    "    \"SJF is the oracle-best baseline (mean RT = 1.298521 s). Least-Loaded is nearly identical (1.300144 s) and is recommended as the practical scheduler. The hierarchical tabular RL agent did not beat the heuristic under the tested settings.\"\n",
    ")\n",
    "\n",
    "# Save Word doc\n",
    "out_docx = 'empirical_study_final_post_sjf.docx'\n",
    "doc.save(out_docx)\n",
    "print(\"Saved Word doc:\", out_docx)\n",
    "\n",
    "# Create 1-page PDF summary\n",
    "out_pdf = 'empirical_study_summary_post_sjf.pdf'\n",
    "c = canvas.Canvas(out_pdf, pagesize=letter)\n",
    "w,h = letter\n",
    "y = h - 72\n",
    "c.setFont(\"Helvetica-Bold\", 14); c.drawCentredString(w/2, y, \"Empirical study  updated results (post-SJF)\")\n",
    "y -= 28\n",
    "c.setFont(\"Helvetica\", 10)\n",
    "for r in bootstrap_rows:\n",
    "    txt = f\"{r['policy']}: mean={r['mean_rt']:.6f}s (95%CI {r['mean_rt_lo']:.6f}-{r['mean_rt_hi']:.6f}); SLA%={r['sla_pct']:.4f} (CI {r['sla_lo']:.4f}-{r['sla_hi']:.4f})\"\n",
    "    c.drawString(72, y, txt); y -= 14\n",
    "    if y < 72:\n",
    "        c.showPage(); y = h - 72\n",
    "c.save()\n",
    "print(\"Saved PDF summary:\", out_pdf)\n",
    "\n",
    "# Also save CSV bootstrap table for reproducibility\n",
    "import csv\n",
    "csv_path = 'bootstrap_summary_final_post_sjf.csv'\n",
    "with open(csv_path, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['policy','mean_rt','mean_rt_lo','mean_rt_hi','sla_pct','sla_lo','sla_hi'])\n",
    "    for r in bootstrap_rows:\n",
    "        writer.writerow([r['policy'], r['mean_rt'], r['mean_rt_lo'], r['mean_rt_hi'], r['sla_pct'], r['sla_lo'], r['sla_hi']])\n",
    "print(\"Saved CSV:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae32e42-de03-4af2-955b-8d33c0b8c64f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
